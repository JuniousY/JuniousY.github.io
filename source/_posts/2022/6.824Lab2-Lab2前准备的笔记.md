---
title: MIT 6.824 Lab2 - Raft - Lab2前准备的笔记
date: 
categories: Lab
tags: 
- distributed system
---

做lab前先整理一下要点和课前提醒，做一个笔记记录，可跳过，主要在实现时对照着看。

<!-- more -->

# Raft概述
Raft是一个用来实现分布式一致的协议。Raft is a protocol for implementing distributed consensus.
```text
Raft is a consensus algorithm that is designed to be easy to understand. 
It’s equivalent to Paxos in fault-tolerance and performance. 
The difference is that it’s decomposed into relatively independent subproblems, and it cleanly addresses all major pieces needed for practical systems. 
We hope Raft will make consensus available to a wider audience, and that this wider audience will be able to develop a variety of higher quality consensus-based systems than are available today.
```

主要分为Lead Election和Log Replication阶段

#### Log Replication 阶段流程概述：
- 为了commit the log entry，leader node首先向follower nodes复制自己
- leader等待大部分node写入entry
- entry 提交，leader status改变
- leader 通知followers entry已经提交了
- cluster 的系统状态成为一致(consensus)

#### Lead Election 阶段流程概述：
- election timeout：时间结束后，follower变为candidate，发起election，发送request vote
- candidate 被大部分note vote后，变为leader
- leader向followers发送Append Entries，按 heartbeat timeout 间歇发送
- follower也向leaderAppend Entries，作为心跳检测
- 同时有两个candidate，就重新进入election timeout等待，重新发起election

# Raft精要
内容是论文中的Figure 2。

![](raft.png)

### 1. State
关于服务器状态的实现
#### 所有服务器 - 持久化状态
在进行RPC回复前进行持久化
- **currentTerm** 最近server看到的term （0开始，单调增）
- **voteFor** 当前term下被推举的candidate Id
- **log[]** log entries （记录条目）。每个entry包含状态机指令，和收到leader发出的entry时的term（起始值为1）

#### 所有服务器 - 可变状态
- **commitIndex** 最近一次被提交的log entry序号（0开始，单调增）
- **lastApplied** 最近一次被应用的log entry序号（0开始，单调增）

#### leaders - 可变状态
选举后重新初始化
- **nextIndex[]** 对每个server，最近发送的log entry序号（原index+1）
- **matchIndex[]** 对每个server，最近知晓的复制成功的log entry序号

### 2. AppendEntries RPC
功能为复制log entries和心跳检测
#### 参数
- **term** leader的term
- **leaderId** 
- **prevLogIndex** 
- **prevLogTerm**
- **entries** 要存的log entries （空为心跳；可能一次传多个）
- **leaderCommit** leader的commitIndex

#### 结果
- **term** currentTerm，leader用来更新自己
- **success** 成功时，表示follower包含符合prevLogIndex和prevLogTerm的entry

#### Receiver实现
1. 如果 term < currentTerm , 返回false
2. 如果 prevLogIndex处的entry不匹配prevLogTerm，返回false
3. 如果现有的entry和新的冲突（index一样但是term不一样），从这个entry开始删除到最新。
4. 插入新的entries
5. 如果 leaderCommit > commitIndex，设置 commitIndex = min(leaderCommit, 最新entry的序号)


### 3. RequestVote RPC
candidate收集选票时触发
#### 参数
- **term** candidate的term
- **candidateId** 
- **lastLogIndex** candidate最后一个log entry的序号
- **lastLogTerm** candidate最后一个log entry的term

#### 结果
- **term** 当前term
- **voteGranted** true表示投一票

#### Receiver实现
1. 如果term < currentTerm 返回false
2. 如果votedFor是空或者是candidateId，然后candidate的log和receiver的log比不滞后，就投票同意

### 4. Servers的实现规则
#### 所有servers
- 如果 commitIndex > lastApplied：lastApplied+1，将log[lastApplied]应用到状态机中
- 如果RPC请求或返回包含 term T > currentTerm：将currentTerm设为T，自己转为follower

#### Followers
- 向candidates和leaders的RPC回复
- 如果election timeout到了之后，没有收到leader的AppendEntries RPC或收到candidate的投票请求，就自己转为candidate

#### Candidates
- 转变成candidate，发起选举
    - currentTerm + 1
    - 投自己一票
    - 重设election timer
    - 向所有其他服务发送RequestVote RPC
- 如果得到大部分服务的投票，成为leader
- 如果收到新leader的AppendEntries RPC，成为follower
- 如果election timeout到了，开始新选举

#### Leaders
- 选举一旦完成，向各服务发送新的初始化空AppendEntries RPC（心跳），空闲时也重复发送
- 如果收到client的命令：在本地log中新增entry，在状态机上应用entry后返回
- 如果最近的log序号 >= nextIndex，发送AppendExtries RPC时用nextIndex
    - 如果成功：为follower更新nextIndex和matchIndex
    - 如果失败，那么原因为log不一致，降低nextIndex重试
- 如果存在 N，N > commitIndex，大部分matchIndex[i] >= N，log[N].term == currentTerm，那么，就设置commitIndex = N


# 注意要点
课程提醒的实现中需要注意的点，一个是Figure 2上的要点要逐一实现，如接受非heart beat AppendEntries 时也要进行相应的检查等；第二个是归纳了四种常见的bug。

#### Bugs
##### 1. live locks - 活锁
1. 需要妥善处理好重设election timer。如果AppendEntries已经过时了，就不要重设计时器。开始发起选举时要重设。给其他节点投票时要重设，而不是每次收到投票请求时重设(这样有更多最近记录的节点更有可能选上)。
2. 如果是candidate正在发起选举，但是自己的election timer到时间了，那么就应该开始新的一次选举
3. 如果已经给出投票，然后有新的RequestVote RPC有更高的term，那应该启用这个term，然后处理RPC

##### 2. Incorrect RPC handlers - 错误的PRC处理
- Figure 2要点中说的“返回false”，意思是立即返回
- 如果一个AppendEntries RPC的prevLogIndex比最近的log index要早，那该当做有这个entry但是term不匹配来处理（如返回false）
- 对prevLogIndex的检查处理，在leader没有送出entries时也要处理
- leader的commit index大过自身commit index时，要更新为min(leaderCommit, 最新entry的序号)。如果直接改为leaderCommit，会遇到应用错误的entries的情况。
- 严格按照要求处理“up-to-date log”。Raft判断的两个log哪个最up-to-date，是通过比较Index和logs中最后的entries的term。如果term最新，那么有最新term的log最up-to-date。如果term一样，那么哪个log的长度（entries的数量）最长就算最up-to-date。

##### 3. Failure to follow The Rules - 没有正确遵守规则
Figure 2. 外补充的要点
- 任何时候发现commitIndex > lastApplied，应该应用一条log entry到状态机。apply要保证只有一个地方去执行。具体来说，要么有一个专门的applier，要么在apply时加锁。
- 检查commitIndex > lastApplied要么周期性，要么在commitIndex更新之后。
- 如果leader发出AppendEntries RPC被拒绝时，如果不是因为log不一致，那么应该立即退出，不更新nextIndex。
- leader 不能让其他节点在过时的term中更新commitIndex。因此要判断log[N].term == currentTerm。
- matchIndex和nextIndex的关系不单纯是matchIndex = nextIndex - 1。nextIndex只是一种乐观的猜测。matchIndex是安全保障，用来做判断。

##### 4. Term Confusion - term混乱
在收到旧term的RPC返回时，只在当前term和请求时的term一致时，处理该PRC返回。

更新matchIndex正确的操作是设置为prevLogIndex + len(entries[])，这里面的参数是发起请求时的值。


#### 额外的功能
这门课除了核心功能，还要求实现log压缩（section 7），快速log回溯（第8页左上方）。

##### log压缩
主要看Figure 13。

![](raft-lc.png)

leader发送表示一个snapshot的多个chunk的方式

#### 参数
- **term** leader的term
- **leaderId**
- **lastIncludedIndex** 
- **lastIncludedTerm**
- **offset** chunk在snapshot文件中的byte位置偏移量
- **data[]** snapshot chunk 的原始数据，从offset开始
- **done** true表示为最后一个chunk

#### 结果
- **term** 当前term

#### Receiver Implementation
1. 如果 term < currentTerm，立即返回
2. 第一个chunk时新建snapshot文件
3. 在给的offset处写入文件
4. 如果done是false，返回并等待更多chunk
5. 保存snapshot文件，其他snapshot文件如果有更小的index，就丢弃
6. 如果已有的log entry和snapshot的最后一个entry有同样的index和term，保留这之后的log entries
7. 丢弃整个log
8. 用snapshot内容重设状态机

注意事项：
- 在做snapshot时，应用的状态应该对设计raft log中已经有index应用过的状态。也就是说，要么知道snapshot对应的index，要么raft在完成snapshot前不应用新的log entries。
- 状态和snapshot提交是分开的，所以在此两者之间的崩溃会导致问题，因为此时被snapshot覆盖的log已经丢弃了。解决办法是记录真实的Raft持久化日志第一条内容的index。
 
##### 快速log回溯
- 如果follower在log中没有prevLogIndex，那么应该返回conflictIndex = len(log)和conflictTerm = None
- 如果follower在log中有prevLogIndex，但是term对不上，那么返回值conflictTerm = log[prevLogIndex].Term，然后找第一个entry的term等于conflictTerm，回溯到这个index
- 收到冲突返回时，leader应该在log中搜索conflictTerm。如果找到了，就把nextIndex设为这个term最后的index之前的那个index。（这句话没看懂，原文If it finds an entry in its log with that term, it should set nextIndex to be the one beyond the index of the last entry in that term in its log.）
- 接上条，如果没有找到，设置nextIndex = conflictIndex

#### 应用Raft时的注意点
##### Applying client operations - 应用操作
服务应该被设计为一个状态机。需要有一个循环去接受用户的操作，和将用户的操作按顺序应用到状态机。这个循环是唯一一处能接触到状态机的地方。

如何知道用户的请求已经完成？在用户操作时，记录当前log的index，一旦在那个index处的操作被标记为已应用，看该处的操作是不是当时的操作，是表示操作成功，否表示操作失败。

##### Duplicate detection - 重复检测
防止应用两次：每个client有一个id，每次请求有一个单调增id。如果相同clinet的相同请求id已经处理过了，就忽略。

##### 其他问题
重复Index，死锁




# 附录：
- [In Search of an Understandable Consensus Algorithm
(Extended Version)](http://nil.csail.mit.edu/6.824/2020/papers/raft-extended.pdf)
- [Students' Guide to Raft](https://thesquareplanet.com/blog/students-guide-to-raft/)