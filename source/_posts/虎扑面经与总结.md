---
title: 虎扑面经
date: 2019-06-23 21:51:06
categories: 开发
tags: 面经
---
这周去虎扑进行了一次面试，一轮技术面一轮HR面，可惜没有拿到offer。我不太清楚是因为什么原因没有过。技术面中有几个问题我感觉我答得不是很好，打算回顾一下。因此本文一是分享面试经历，二是回顾总结。

<!-- more -->

## 计算机网络
计算机网络部分笔试部分问了一些关于socket和http的问题。有几个印象里比较深的小点记一下。一个是http能不能用udp。这个是不可以的，udp无法提供可靠传输，不过除了TCP也可以用可靠传输的SCTP（流控制传输协议, Stream Control Transmission Protocol）。还有一个是socket属于计算机网络中的哪一层。socket是抽象层，因此不属于计算机网络分层中的任意一层。

面试中还问了https和http的区别。
https和http区别主要在于利用SSL/TLS加密数据包。HTTP的URL是由"http://"起始，默认使用端口80，而HTTPS的URL则是由“https://”起始，默认使用端口443。
面试官会进一步发问，具体谈一下https怎么加密的？
1. 客户端向服务器端索要并验证公钥。
2. 双方协商生成"对话密钥"。（session key）
3. 双方采用"对话密钥"进行加密通信。
加密基本思路是采用公钥加密法。客户端先向服务器端索要公钥，然后用公钥加密信息，服务器收到密文后，用自己的私钥解密。公钥放在数字证书中。只要证书是可信的，公钥就是可信的。
在开始的握手阶段，加密方式为非对称加密，有公钥私钥之分，客户端不知道服务器私钥。而在传输数据时，加密方式为对称加密，只使用一个session key加密数据。

----

## Java
Java问的基本都是JDK8。（我说我最常用的是JDK8）
#### lambda 原理
这个我之前只知道lambda不是语法糖，会影响性能。
Lambda实际上是设计来替代匿名类的。匿名内部类的频繁生成会造成性能问题。
	Lambda的实现与Java7中引入的invokedynamic 字节码指令有关。将 Lambda 表达式转化成字节码只需要如下两步：1. 生成一个 invokedynamic 调用点，也叫做 Lambda 工厂( lambda factory)。当调用时返回一个 Lambda 表达式转化成的函数式接口实例。	2. 将 Lambda 表达式的方法体转换成方法供 invokedynamic 指令调用。
Lambda 表达式转化成方法字节码的第二步取决于 Lambda 表达式是否为对变量捕获。变量捕获指表达式需要访问外部的变量。
对于不进行变量捕获的Lambda的表达式，表达式会转成一个具有相同签名的静态方法中去，这个静态方法和Lambda位于同一个类。
对于进行变量捕获的Lambda的表达式，同样转为静态方法，不过被捕获的变量会作为额外的参数传入方法中。
可以参考[Java 8 Lambdas - A Peek Under the Hood
](https://www.infoq.com/articles/Java-8-Lambdas-A-Peek-Under-the-Hood/)和其译文[深入探索 Java 8 Lambda 表达式](https://www.infoq.cn/article/Java-8-Lambdas-A-Peek-Under-the-Hood)。

#### stream
笔试里考了一下stream的api用法。当时我忘记怎么去重了。常见api如下:
- 构造流的几种常见方法：`Stream.of()//参数为值或者容器`、`list.stream()`。
- 流转换为其它数据结构：`toArray(String[]::new)`、`stream.collect(Collectors.toList());`、`stream.collect(Collectors.toCollection(ArrayList::new))`、`stream.collect(Collectors.joining()).toString()`
- map/flatMap 元素映射为另一个元素 `map(n -> n * n)`
- filter 对原始 Stream 进行某项测试，通过测试的元素被留下来生成一个新 Stream `filter(n -> n%2 == 0)//剩下偶数`
- forEach 在 Stream 的每一个元素上执行该表达式。需要注意，forEach 是 terminal 操作，因此它执行后，Stream 的元素就被“消费”掉了，你无法对一个 Stream 进行两次 terminal 运算。有相似功能的 intermediate 操作 peek 可以达到上述目的。forEach 不能修改自己包含的本地变量值，也不能用 break/return 之类的关键字提前结束循环。
- findFirst 这是一个 termimal 兼 short-circuiting 操作，它总是返回 Stream 的第一个元素，或者空。返回值类型是Optional
- reduce 把 Stream 元素组合起来。它提供一个起始值（种子），然后依照运算规则（BinaryOperator），和前面 Stream 的第一个、第二个、第 n 个元素组合。例子：`Stream.of("A", "B", "C", "D").reduce("", String::concat);`
- limit/skip limit 返回 Stream 的前面 n 个元素；skip 则是扔掉前 n 个元素（它是由一个叫 subStream 的方法改名而来）。
- sorted 排序
- min/max/distinct min 和 max 复杂度为O(n)。 distinct 去重。
- Match allMatch anyMatch noneMatch 匹配
- 自己生成流是通过实现 Supplier 接口，自己控制流的生成，需要limit。Stream.iterate是迭代生成数据


对于基本数值型，目前有三种对应的包装类型 Stream：IntStream、LongStream、DoubleStream。

推荐[Java 8 中的 Streams API 详解](https://www.ibm.com/developerworks/cn/java/j-lo-java8streamapi/index.html)

其他问了些创建线程方式之类的常规问题。

---

## spring 
#### spring boot 启动机制。
这个问题我当时答得不太好，有点乱，这里重新整理一下（可以略过贴源码的部分）。

看`SpringApplication`的`run`方法：
```java
public static void main(String[] args) throws Exception {
    SpringApplication.run(new Class<?>[0], args);//调用以下run
}
//
public static ConfigurableApplicationContext run(Class<?>[] primarySources,
                                                 String[] args) {
    return new SpringApplication(primarySources).run(args);//实例化SpringApplication，调用以下run
}
//
public ConfigurableApplicationContext run(String... args) {
    StopWatch stopWatch = new StopWatch();  // 构造任务执行观察器
    stopWatch.start(); // 开始执行，记录开始时间
    ConfigurableApplicationContext context = null;
    Collection<SpringBootExceptionReporter> exceptionReporters = new ArrayList<>();
    configureHeadlessProperty();
    SpringApplicationRunListeners listeners = getRunListeners(args); // 获取SpringApplicationRunListeners，内部只有一个EventPublishingRunListener
    listeners.starting();
    try {
        ApplicationArguments applicationArguments = new DefaultApplicationArguments(
            args);   // 构造应用程序参数持有类
        ConfigurableEnvironment environment = prepareEnvironment(listeners,
                                                                 applicationArguments); // 创建environment
        configureIgnoreBeanInfo(environment);
        Banner printedBanner = printBanner(environment);
        context = createApplicationContext(); // 创建Spring容器
        exceptionReporters = getSpringFactoriesInstances(
            SpringBootExceptionReporter.class,
            new Class[] { ConfigurableApplicationContext.class }, context);
        prepareContext(context, environment, listeners, applicationArguments,
                       printedBanner);
        refreshContext(context); // 完成Spring容器创建
        afterRefresh(context, applicationArguments);
        stopWatch.stop(); // 执行结束，记录执行时间
        if (this.logStartupInfo) {
            new StartupInfoLogger(this.mainApplicationClass)
                .logStarted(getApplicationLog(), stopWatch);
        }
        listeners.started(context);
        callRunners(context, applicationArguments);
    }
    catch (Throwable ex) {
        handleRunFailure(context, ex, exceptionReporters, listeners);
        throw new IllegalStateException(ex);
    }

    try {
        listeners.running(context);
    }
    catch (Throwable ex) {
        handleRunFailure(context, ex, exceptionReporters, null);
        throw new IllegalStateException(ex);
    }
    return context;
}
```
`SpringApplication`类的实例化：
```java
public SpringApplication(ResourceLoader resourceLoader, Class<?>... primarySources) {
    this.resourceLoader = resourceLoader;
    Assert.notNull(primarySources, "PrimarySources must not be null");
    this.primarySources = new LinkedHashSet<>(Arrays.asList(primarySources));
    this.webApplicationType = WebApplicationType.deduceFromClasspath();
    setInitializers((Collection) getSpringFactoriesInstances(
        ApplicationContextInitializer.class));
    setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class));
    this.mainApplicationClass = deduceMainApplicationClass();
}
```
总结一下：
- 首先要创建一个`SpringApplication`对象实例，然后调用这个创建好的`SpringApplication`的实例方法。从配置的primary source中导入beans。此时确定`webApplicationType`(Web应用使用的ApplicationContext类型)，使用`SpringFactoriesLoader`在应用的classpath中查找并加载所有可用的`ApplicationContextInitializer`和`ApplicationListener`。
- 实例初始化后执行`run`方法。
- `run`方法首先遍历执行所有通过`SpringFactoriesLoader`可以查找到并加载的`SpringApplicationRunListener`，调用它们的`started()`方法，通知它们SpringBoot应用要开始执行。
- 创建并配置当前Spring Boot应用将要使用的Environment（包括配置要使用的PropertySource以及Profile）。通知`SpringApplicationRunListener`们，调用它们的`environmentPrepared`，通知SpringBoot应用使用的Environment准备好。
- 然后创建`ApplicationContext`。看是否是web环境，是的话构造`AnnotationConfigEmbeddedWebApplicationContext`，否则构造`AnnotationConfigApplicationContext`
- 调用`prepareContext`。这时，将之前准备好的Environment设置给创建好的`ApplicationContext`使用。遍历调用所有`SpringApplicationRunListener`的`contextPrepared()`方法。最核心的一步，将之前通过`@EnableAutoConfiguration`获取的所有配置以及其他形式的IoC容器配置加载到已经准备完毕的`ApplicationContext`中去，方法为用`ApplicationContext`的`beanFactory`的设置Bean的方法。然后调用所有`SpringApplicationRunListener`的`contextLoaded()`方法。
- 调用`refreshContext`。调用ApplicationContext的refresh()方法，完成bean的解析、各种processor接口的执行、条件注解的解析等等。
- 从Spring容器中找出ApplicationRunner和CommandLineRunner接口的实现类并排序后依次执行
- 收尾工作 调用`SpringApplicationRunListener`的`started`、`running`方法

推荐[SpringBoot源码分析之SpringBoot的启动过程](https://fangjian0423.github.io/2017/04/30/springboot-startup-analysis/)

#### BeanFactory是什么。这个问题可能是因为我上一个问题答得不是很好，所以回过头来问这个。
BeanFactory是什么是一个工厂类(接口)， 它负责生产和管理bean。是IOC容器的核心接口，它的职责包括：实例化、定位、配置应用程序中的对象及建立这些对象间的依赖。为其他具体的IOC容器提供了最基本的规范，例如DefaultListableBeanFactory,XmlBeanFactory,ApplicationContext 等具体的容器都是实现了BeanFactory。`getBean`方法取得bean的实例，方法还有`getType`、`isSingleton`、`containsBean`、`getAliases`。


还问了常见注释什么的。

----
## Dubbo Zookeeper
####  Dubbo框架
![](http://dubbo.apache.org/docs/zh-cn/user/sources/images/dubbo-architecture.jpg)
把这张图说一下

#### 为什么需要注册中，将该象封装到 Runnable 实现类对象中，并将 Runnable 放入线程池中执行后续的调用逻辑心（这个问题我当时答得不好）
注册中心解决了**服务发现**的问题，服务发现是指 consumer 查找 provider 地址（IP + port）的过程。对于云服务来说，服务不再部署在物理机上，每次新创建的实例，其 IP 很可能与上次不同，因此需要更加灵活的服务发现机制。服务发现是 SOA 架构（service oriented architecture）、微服务架构的核心组件，必须提供以下 3 个功能：服务注册（Registration），服务目录（Directory），服务查找（Lookup）。复杂系统中，服务的元数据非常复杂，因此 lookup 非常重要，这里的查找不仅仅指查找到服务的元数据（地址、配置等），还包括服务的部署状态，并提供集中管理服务实例的能力。
Dubbo中注册中心通过长连接感知服务提供者的存在，服务提供者宕机或者有变更，注册中心将立即推送事件通知消费者。

#### Zookeeper怎么实现注册中心的
服务提供者启动时: 向 /dubbo/com.foo.BarService/providers 目录下写入自己的 URL 地址
服务消费者启动时: 订阅 /dubbo/com.foo.BarService/providers 目录下的提供者 URL 地址。并向 /dubbo/com.foo.BarService/consumers 目录下写入自己的 URL 地址
监控中心启动时: 订阅 /dubbo/com.foo.BarService 目录下的所有提供者和消费者 URL 地址。

#### Zookeeper的集群节点数目是怎样？架构是怎么样的？怎么选出Leader？
zookeeper集群的数目，一般为奇数个。节点主要分为leader和follower，observer类似follower但不参与选举，leader负责进行投票的发起和决议，更新系统状态。
服务器启动时期的Leader选举： 每个Server发出一个投票，投票包含所推举的服务器的myid和ZXID。接受来自各个服务器的投票。针对每一个投票，优先检查ZXID，如果ZXID相同，那么就比较myid。统计投票，有过半机器接受到相同的投票信息则选举完成。 改变服务器状态。
服务器运行时期的Leader选举：follower节点变更状态，进入选举。每个Server会发出一个投票。其余类似。

#### 从请求一个服务开始的完整流程
这个当时答得不好。简单回答的话：
![](http://dubbo.apache.org/docs/zh-cn/source_code_guide/sources/images/send-request-process.jpg)

- 服务消费方发送请求
生成代理类Proxy发起远程调用，接着通过网络客户端 Client 将编码后的请求发送给服务提供方的网络层上。默认情况下，Dubbo 使用 Netty 作为底层的通信框架向消费者发送请求。
- 服务提供方接收请求
请求解码，得到了一个 Request 对象。将解码后的请求发送至分发器 Dispatcher，再由分发器将请求派发到指定的线程池上调用服务。Dubbo 会在运行时通过 Javassist 框架为 Wrapper 生成实现类，并实现 invokeMethod 方法，该方法最终会根据调用信息调用具体的服务。
- 服务提供方返回调用结果
- 服务消费方接收调用结果
响应数据解码。向用户线程传递调用结果。

----

## Mysql
Mysql有印象的问题是问了聚簇索引，然后引申问了InnoDB和MyISAM的数据分布区别。
聚簇索引是一种数据存储方式，InnoDB的聚簇索引在同一个结构中保存了B-Tree索引和数据行。聚簇表示数据行和相邻的键值紧凑地存储在一起。非聚集索引中索引是指向表中行的位置的指针，这些指针本身是有序的，通过这些指针可以在表中快速定位数据。
MyISAM按照数据插入的顺序存储在磁盘上。InnoDB聚簇索引就是表，每一个叶子节点都包含了主键值、事务ID、回滚指针以及剩余列。

----
## Kafka
#### Kafka的架构，解释如comsumer和group
Broker：Kafka 集群包含一个或多个服务器，这种服务器被称为 broker。一台kafka服务器就是一个broker。一个集群由多个broker组成。一个broker可以容纳多个topic。 
Topic：每条发布到 Kafka 集群的消息都有一个类别，这个类别被称为 Topic。（物理上不同 Topic 的消息分开存储，逻辑上一个 Topic 的消息虽然保存于一个或多个 broker 上，但用户只需指定消息的 Topic 即可生产或消费数据而不必关心数据存于何处）。
Partition：Partition 是物理上的概念，每个 Topic 包含一个或多个 Partition。
Producer：负责发布消息到 Kafka broker。
Consumer：消息消费者，向 Kafka broker 读取消息的客户端。
Consumer Group：每个 Consumer 属于一个特定的 Consumer Group（可为每个 Consumer 指定 group name，若不指定 group name 则属于默认的 group）。

属于某一个消费者群组的消费者订阅了一个主题，通过该订阅消费者可以跨节点地接收所有与该主题相关的消息，每一个消息只会发送给群组中的一个消费者，所有拥有相同键值的消息都会被确保发给这一个消费者。
Kafka 设计中将每一个主题分区（Partition）当作一个具有顺序排列的日志。同处于一个分区中的消息都被设置了一个唯一的偏移量。Kafka 只会保持跟踪未读消息，一旦消息被置为已读状态，Kafka 就不会再去管理它了。

#### 怎么保证高性能
参考别人的blog，可以有以下几点：利用 Partition 实现并行处理；磁盘顺序写；零拷贝。这一点我暂时了解得不多。

----
## 其他问题
Nginx启动需要配哪些
最近看的Github库
平时怎么学习

