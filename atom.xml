<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>JuniousY的博客</title>
  <icon>https://www.gravatar.com/avatar/f7f552067d5d738d5b1802fa58ce5759</icon>
  <subtitle>倾听Ghost的低语</subtitle>
  <link href="https://juniousy.github.io/atom.xml" rel="self"/>
  
  <link href="https://juniousy.github.io/"/>
  <updated>2022-05-30T09:06:50.985Z</updated>
  <id>https://juniousy.github.io/</id>
  
  <author>
    <name>JuniousY</name>
    <email>chengjy42@gmail.com</email>
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>本科后至今（一年半）的一点点感想</title>
    <link href="https://juniousy.github.io/2021/01/29/%E6%9C%AC%E7%A7%91%E5%90%8E%E8%87%B3%E4%BB%8A%EF%BC%88%E4%B8%80%E5%B9%B4%E5%8D%8A%EF%BC%89%E7%9A%84%E4%B8%80%E7%82%B9%E7%82%B9%E6%84%9F%E6%83%B3/"/>
    <id>https://juniousy.github.io/2021/01/29/%E6%9C%AC%E7%A7%91%E5%90%8E%E8%87%B3%E4%BB%8A%EF%BC%88%E4%B8%80%E5%B9%B4%E5%8D%8A%EF%BC%89%E7%9A%84%E4%B8%80%E7%82%B9%E7%82%B9%E6%84%9F%E6%83%B3/</id>
    <published>2021-01-29T13:00:00.000Z</published>
    <updated>2022-05-30T09:06:50.985Z</updated>
    
    <content type="html"><![CDATA[<p>我从不认为我是个成熟的人，也常常会低估自己的价值。这段时间以来，与其说是我变得相对来说更成熟一些，不如说是看问题的角度和方法有了变化。然后，由于这种变化，我的价值观也发生了变化。</p><a id="more"></a><p>首先不得不提一下2020年S1知名的草台论，适用于2020年的各种事件，也非常符合我的心里路程变化。</p><p><img src="/images/2021/1.jpg"></p><p>学生时期对外界事物总有认识不到位的地方，这时候不少大学生都会用更理想化的角度进行自我解释。但是完美的事物是不存在的，光鲜的背后是更有质感的现实。但，反过来说，一些同龄人可能由于各种各样的条件、背景，更早地认识到“草台”，或者说，了解到社会背后运行的规则和潜规则。然后，他们可能很早就通过父辈或者在自我实践中学会了运用这些机制，尤其是同龄人所不了解的机制。当然，可能有个更好的词叫“世故”。但我想讲的不是世故，因为实际上很多世故的人也会对不了解的事物、被粉饰的事物产生不切实际的幻想。我觉得这种迷信可以发生在任何阶段、任何场景，同样，对此的祛魅也会发生在任何阶段、任何场景。</p><p>我不是一个善于社交的人。以能够游走多方势力的人物的社交能力设为90，我觉得我顶多60-70，勉强够平均分。但我觉得这种不擅长更多地是一种个人特质，而不是缺点。但除开这种特质，我觉得之前在了解人与人之间的关系，和人与事之间的关系上是过于懒惰了。首先，了解人情世故是必要的，许多规则和潜规则是社会实际运行的齿轮。也许找不到一项相关的社会心理学研究去帮助我理解和运用一些微妙的波动，但依然可以去总结和分析平时遇到的事件和人物。然后，了解之后是要学会应用。但再次强调一点，我不是一个善于社交的人。我觉得这种运用更多地是避免踩坑，或者是解决周围人之间的矛盾。</p><p>2020年是个必定被写进历史书的一年。以我的视角，我看到了潮水褪去之后的裸露基岩。有的人必定会在这样的危机中抓住机会，但大家的问题是，谁才是这样的人。我不知道谁会是这样的人，但我变得开始相信这样的一点，那就是原则、底线、真理是可以生存的，最惨也能通过智慧在夹缝中等待时机。我可能在这点上要求不高，我已经满足于这些东西能够真切地存在着。当然，这都是我一些非常感性的想法。</p><p>走出校门以后，就必须学会承担。能逃避那是假的，必须得学会。但是被动地承担是一种消极的、低效的做法。有时候主动出击反而有效得多。一句被说烂的话，“人总是会有惰性的”，我觉得有时候不如主动规划一个懒惰时间，提前行动和做好预案。同样的，在可控范围内，主动地戳破纸，主动地排除危机，在结果上会更好看，在生活上会更有安全感。</p><p>原本的2020计划是，年底提交N份美研申请，争取一个在美国工作的机会。这个计划被废弃了。也许依然可以通过各种方法达成这个目标，但我考虑过自身的风险承担能力和各项成本之后，感觉对我来说是没有必要坚持。我多少还是有些羡慕那些有理想有明确长远目标追求的人。尤其是那些聪明的人，如果还坚持着梦想，那我的看法是他们都比较幸福。所谓书到用时方恨少，毕业之后，真的觉得自己本科时候学得太少，想得太少，实践得太少。但好在人生不是短跑。这个时代也许并不坏，有没有突破人生既定路线的运气是另一回事，在获得运气之前，首先要学会自力更生。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;我从不认为我是个成熟的人，也常常会低估自己的价值。这段时间以来，与其说是我变得相对来说更成熟一些，不如说是看问题的角度和方法有了变化。然后，由于这种变化，我的价值观也发生了变化。&lt;/p&gt;</summary>
    
    
    
    <category term="杂谈" scheme="https://juniousy.github.io/categories/%E6%9D%82%E8%B0%88/"/>
    
    
    <category term="杂谈" scheme="https://juniousy.github.io/tags/%E6%9D%82%E8%B0%88/"/>
    
  </entry>
  
  <entry>
    <title>【本科时期文章】虎扑面经</title>
    <link href="https://juniousy.github.io/2019/06/23/%E8%99%8E%E6%89%91%E9%9D%A2%E7%BB%8F%E4%B8%8E%E6%80%BB%E7%BB%93/"/>
    <id>https://juniousy.github.io/2019/06/23/%E8%99%8E%E6%89%91%E9%9D%A2%E7%BB%8F%E4%B8%8E%E6%80%BB%E7%BB%93/</id>
    <published>2019-06-23T13:51:06.000Z</published>
    <updated>2022-05-30T09:06:50.986Z</updated>
    
    <content type="html"><![CDATA[<p>这周去虎扑进行了一次面试，一轮技术面一轮HR面，可惜没有拿到offer。我不太清楚是因为什么原因没有过。技术面中有几个问题我感觉我答得不是很好，打算回顾一下。因此本文一是分享面试经历，二是回顾总结。</p><a id="more"></a><h2 id="计算机网络"><a href="#计算机网络" class="headerlink" title="计算机网络"></a>计算机网络</h2><p>计算机网络部分笔试部分问了一些关于socket和http的问题。有几个印象里比较深的小点记一下。一个是http能不能用udp。这个是不可以的，udp无法提供可靠传输，不过除了TCP也可以用可靠传输的SCTP（流控制传输协议, Stream Control Transmission Protocol）。还有一个是socket属于计算机网络中的哪一层。socket是抽象层，因此不属于计算机网络分层中的任意一层。</p><p>面试中还问了https和http的区别。<br>https和http区别主要在于利用SSL/TLS加密数据包。HTTP的URL是由”http://“起始，默认使用端口80，而HTTPS的URL则是由“https://”起始，默认使用端口443。<br>面试官会进一步发问，具体谈一下https怎么加密的？</p><ol><li>客户端向服务器端索要并验证公钥。</li><li>双方协商生成”对话密钥”。（session key）</li><li>双方采用”对话密钥”进行加密通信。<br>加密基本思路是采用公钥加密法。客户端先向服务器端索要公钥，然后用公钥加密信息，服务器收到密文后，用自己的私钥解密。公钥放在数字证书中。只要证书是可信的，公钥就是可信的。<br>在开始的握手阶段，加密方式为非对称加密，有公钥私钥之分，客户端不知道服务器私钥。而在传输数据时，加密方式为对称加密，只使用一个session key加密数据。</li></ol><hr><h2 id="Java"><a href="#Java" class="headerlink" title="Java"></a>Java</h2><p>Java问的基本都是JDK8。（我说我最常用的是JDK8）</p><h4 id="lambda-原理"><a href="#lambda-原理" class="headerlink" title="lambda 原理"></a>lambda 原理</h4><p>这个我之前只知道lambda不是语法糖，会影响性能。<br>Lambda实际上是设计来替代匿名类的。匿名内部类的频繁生成会造成性能问题。<br>    Lambda的实现与Java7中引入的invokedynamic 字节码指令有关。将 Lambda 表达式转化成字节码只需要如下两步：1. 生成一个 invokedynamic 调用点，也叫做 Lambda 工厂( lambda factory)。当调用时返回一个 Lambda 表达式转化成的函数式接口实例。    2. 将 Lambda 表达式的方法体转换成方法供 invokedynamic 指令调用。<br>Lambda 表达式转化成方法字节码的第二步取决于 Lambda 表达式是否为对变量捕获。变量捕获指表达式需要访问外部的变量。<br>对于不进行变量捕获的Lambda的表达式，表达式会转成一个具有相同签名的静态方法中去，这个静态方法和Lambda位于同一个类。<br>对于进行变量捕获的Lambda的表达式，同样转为静态方法，不过被捕获的变量会作为额外的参数传入方法中。<br>可以参考<a href="https://www.infoq.com/articles/Java-8-Lambdas-A-Peek-Under-the-Hood/">Java 8 Lambdas - A Peek Under the Hood</a>和其译文<a href="https://www.infoq.cn/article/Java-8-Lambdas-A-Peek-Under-the-Hood">深入探索 Java 8 Lambda 表达式</a>。</p><h4 id="stream"><a href="#stream" class="headerlink" title="stream"></a>stream</h4><p>笔试里考了一下stream的api用法。当时我忘记怎么去重了。常见api如下:</p><ul><li>构造流的几种常见方法：<code>Stream.of()//参数为值或者容器</code>、<code>list.stream()</code>。</li><li>流转换为其它数据结构：<code>toArray(String[]::new)</code>、<code>stream.collect(Collectors.toList());</code>、<code>stream.collect(Collectors.toCollection(ArrayList::new))</code>、<code>stream.collect(Collectors.joining()).toString()</code></li><li>map/flatMap 元素映射为另一个元素 <code>map(n -&gt; n * n)</code></li><li>filter 对原始 Stream 进行某项测试，通过测试的元素被留下来生成一个新 Stream <code>filter(n -&gt; n%2 == 0)//剩下偶数</code></li><li>forEach 在 Stream 的每一个元素上执行该表达式。需要注意，forEach 是 terminal 操作，因此它执行后，Stream 的元素就被“消费”掉了，你无法对一个 Stream 进行两次 terminal 运算。有相似功能的 intermediate 操作 peek 可以达到上述目的。forEach 不能修改自己包含的本地变量值，也不能用 break/return 之类的关键字提前结束循环。</li><li>findFirst 这是一个 termimal 兼 short-circuiting 操作，它总是返回 Stream 的第一个元素，或者空。返回值类型是Optional</li><li>reduce 把 Stream 元素组合起来。它提供一个起始值（种子），然后依照运算规则（BinaryOperator），和前面 Stream 的第一个、第二个、第 n 个元素组合。例子：<code>Stream.of(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;).reduce(&quot;&quot;, String::concat);</code></li><li>limit/skip limit 返回 Stream 的前面 n 个元素；skip 则是扔掉前 n 个元素（它是由一个叫 subStream 的方法改名而来）。</li><li>sorted 排序</li><li>min/max/distinct min 和 max 复杂度为O(n)。 distinct 去重。</li><li>Match allMatch anyMatch noneMatch 匹配</li><li>自己生成流是通过实现 Supplier 接口，自己控制流的生成，需要limit。Stream.iterate是迭代生成数据</li></ul><p>对于基本数值型，目前有三种对应的包装类型 Stream：IntStream、LongStream、DoubleStream。</p><p>推荐<a href="https://www.ibm.com/developerworks/cn/java/j-lo-java8streamapi/index.html">Java 8 中的 Streams API 详解</a></p><p>其他问了些创建线程方式之类的常规问题。</p><hr><h2 id="spring"><a href="#spring" class="headerlink" title="spring"></a>spring</h2><h4 id="spring-boot-启动机制。"><a href="#spring-boot-启动机制。" class="headerlink" title="spring boot 启动机制。"></a>spring boot 启动机制。</h4><p>这个问题我当时答得不太好，有点乱，这里重新整理一下（可以略过贴源码的部分）。</p><p>看<code>SpringApplication</code>的<code>run</code>方法：</p><pre><code class="java">public static void main(String[] args) throws Exception &#123;    SpringApplication.run(new Class&lt;?&gt;[0], args);//调用以下run&#125;//public static ConfigurableApplicationContext run(Class&lt;?&gt;[] primarySources,                                                 String[] args) &#123;    return new SpringApplication(primarySources).run(args);//实例化SpringApplication，调用以下run&#125;//public ConfigurableApplicationContext run(String... args) &#123;    StopWatch stopWatch = new StopWatch();  // 构造任务执行观察器    stopWatch.start(); // 开始执行，记录开始时间    ConfigurableApplicationContext context = null;    Collection&lt;SpringBootExceptionReporter&gt; exceptionReporters = new ArrayList&lt;&gt;();    configureHeadlessProperty();    SpringApplicationRunListeners listeners = getRunListeners(args); // 获取SpringApplicationRunListeners，内部只有一个EventPublishingRunListener    listeners.starting();    try &#123;        ApplicationArguments applicationArguments = new DefaultApplicationArguments(            args);   // 构造应用程序参数持有类        ConfigurableEnvironment environment = prepareEnvironment(listeners,                                                                 applicationArguments); // 创建environment        configureIgnoreBeanInfo(environment);        Banner printedBanner = printBanner(environment);        context = createApplicationContext(); // 创建Spring容器        exceptionReporters = getSpringFactoriesInstances(            SpringBootExceptionReporter.class,            new Class[] &#123; ConfigurableApplicationContext.class &#125;, context);        prepareContext(context, environment, listeners, applicationArguments,                       printedBanner);        refreshContext(context); // 完成Spring容器创建        afterRefresh(context, applicationArguments);        stopWatch.stop(); // 执行结束，记录执行时间        if (this.logStartupInfo) &#123;            new StartupInfoLogger(this.mainApplicationClass)                .logStarted(getApplicationLog(), stopWatch);        &#125;        listeners.started(context);        callRunners(context, applicationArguments);    &#125;    catch (Throwable ex) &#123;        handleRunFailure(context, ex, exceptionReporters, listeners);        throw new IllegalStateException(ex);    &#125;    try &#123;        listeners.running(context);    &#125;    catch (Throwable ex) &#123;        handleRunFailure(context, ex, exceptionReporters, null);        throw new IllegalStateException(ex);    &#125;    return context;&#125;</code></pre><p><code>SpringApplication</code>类的实例化：</p><pre><code class="java">public SpringApplication(ResourceLoader resourceLoader, Class&lt;?&gt;... primarySources) &#123;    this.resourceLoader = resourceLoader;    Assert.notNull(primarySources, &quot;PrimarySources must not be null&quot;);    this.primarySources = new LinkedHashSet&lt;&gt;(Arrays.asList(primarySources));    this.webApplicationType = WebApplicationType.deduceFromClasspath();    setInitializers((Collection) getSpringFactoriesInstances(        ApplicationContextInitializer.class));    setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class));    this.mainApplicationClass = deduceMainApplicationClass();&#125;</code></pre><p>总结一下：</p><ul><li>首先要创建一个<code>SpringApplication</code>对象实例，然后调用这个创建好的<code>SpringApplication</code>的实例方法。从配置的primary source中导入beans。此时确定<code>webApplicationType</code>(Web应用使用的ApplicationContext类型)，使用<code>SpringFactoriesLoader</code>在应用的classpath中查找并加载所有可用的<code>ApplicationContextInitializer</code>和<code>ApplicationListener</code>。</li><li>实例初始化后执行<code>run</code>方法。</li><li><code>run</code>方法首先遍历执行所有通过<code>SpringFactoriesLoader</code>可以查找到并加载的<code>SpringApplicationRunListener</code>，调用它们的<code>started()</code>方法，通知它们SpringBoot应用要开始执行。</li><li>创建并配置当前Spring Boot应用将要使用的Environment（包括配置要使用的PropertySource以及Profile）。通知<code>SpringApplicationRunListener</code>们，调用它们的<code>environmentPrepared</code>，通知SpringBoot应用使用的Environment准备好。</li><li>然后创建<code>ApplicationContext</code>。看是否是web环境，是的话构造<code>AnnotationConfigEmbeddedWebApplicationContext</code>，否则构造<code>AnnotationConfigApplicationContext</code></li><li>调用<code>prepareContext</code>。这时，将之前准备好的Environment设置给创建好的<code>ApplicationContext</code>使用。遍历调用所有<code>SpringApplicationRunListener</code>的<code>contextPrepared()</code>方法。最核心的一步，将之前通过<code>@EnableAutoConfiguration</code>获取的所有配置以及其他形式的IoC容器配置加载到已经准备完毕的<code>ApplicationContext</code>中去，方法为用<code>ApplicationContext</code>的<code>beanFactory</code>的设置Bean的方法。然后调用所有<code>SpringApplicationRunListener</code>的<code>contextLoaded()</code>方法。</li><li>调用<code>refreshContext</code>。调用ApplicationContext的refresh()方法，完成bean的解析、各种processor接口的执行、条件注解的解析等等。</li><li>从Spring容器中找出ApplicationRunner和CommandLineRunner接口的实现类并排序后依次执行</li><li>收尾工作 调用<code>SpringApplicationRunListener</code>的<code>started</code>、<code>running</code>方法</li></ul><p>推荐<a href="https://fangjian0423.github.io/2017/04/30/springboot-startup-analysis/">SpringBoot源码分析之SpringBoot的启动过程</a></p><h4 id="BeanFactory是什么。这个问题可能是因为我上一个问题答得不是很好，所以回过头来问这个。"><a href="#BeanFactory是什么。这个问题可能是因为我上一个问题答得不是很好，所以回过头来问这个。" class="headerlink" title="BeanFactory是什么。这个问题可能是因为我上一个问题答得不是很好，所以回过头来问这个。"></a>BeanFactory是什么。这个问题可能是因为我上一个问题答得不是很好，所以回过头来问这个。</h4><p>BeanFactory是什么是一个工厂类(接口)， 它负责生产和管理bean。是IOC容器的核心接口，它的职责包括：实例化、定位、配置应用程序中的对象及建立这些对象间的依赖。为其他具体的IOC容器提供了最基本的规范，例如DefaultListableBeanFactory,XmlBeanFactory,ApplicationContext 等具体的容器都是实现了BeanFactory。<code>getBean</code>方法取得bean的实例，方法还有<code>getType</code>、<code>isSingleton</code>、<code>containsBean</code>、<code>getAliases</code>。</p><p>还问了常见注释什么的。</p><hr><h2 id="Dubbo-Zookeeper"><a href="#Dubbo-Zookeeper" class="headerlink" title="Dubbo Zookeeper"></a>Dubbo Zookeeper</h2><h4 id="Dubbo框架"><a href="#Dubbo框架" class="headerlink" title="Dubbo框架"></a>Dubbo框架</h4><p><img src="http://dubbo.apache.org/docs/zh-cn/user/sources/images/dubbo-architecture.jpg"><br>把这张图说一下</p><h4 id="为什么需要注册中，将该象封装到-Runnable-实现类对象中，并将-Runnable-放入线程池中执行后续的调用逻辑心（这个问题我当时答得不好）"><a href="#为什么需要注册中，将该象封装到-Runnable-实现类对象中，并将-Runnable-放入线程池中执行后续的调用逻辑心（这个问题我当时答得不好）" class="headerlink" title="为什么需要注册中，将该象封装到 Runnable 实现类对象中，并将 Runnable 放入线程池中执行后续的调用逻辑心（这个问题我当时答得不好）"></a>为什么需要注册中，将该象封装到 Runnable 实现类对象中，并将 Runnable 放入线程池中执行后续的调用逻辑心（这个问题我当时答得不好）</h4><p>注册中心解决了<strong>服务发现</strong>的问题，服务发现是指 consumer 查找 provider 地址（IP + port）的过程。对于云服务来说，服务不再部署在物理机上，每次新创建的实例，其 IP 很可能与上次不同，因此需要更加灵活的服务发现机制。服务发现是 SOA 架构（service oriented architecture）、微服务架构的核心组件，必须提供以下 3 个功能：服务注册（Registration），服务目录（Directory），服务查找（Lookup）。复杂系统中，服务的元数据非常复杂，因此 lookup 非常重要，这里的查找不仅仅指查找到服务的元数据（地址、配置等），还包括服务的部署状态，并提供集中管理服务实例的能力。<br>Dubbo中注册中心通过长连接感知服务提供者的存在，服务提供者宕机或者有变更，注册中心将立即推送事件通知消费者。</p><h4 id="Zookeeper怎么实现注册中心的"><a href="#Zookeeper怎么实现注册中心的" class="headerlink" title="Zookeeper怎么实现注册中心的"></a>Zookeeper怎么实现注册中心的</h4><p>服务提供者启动时: 向 /dubbo/com.foo.BarService/providers 目录下写入自己的 URL 地址<br>服务消费者启动时: 订阅 /dubbo/com.foo.BarService/providers 目录下的提供者 URL 地址。并向 /dubbo/com.foo.BarService/consumers 目录下写入自己的 URL 地址<br>监控中心启动时: 订阅 /dubbo/com.foo.BarService 目录下的所有提供者和消费者 URL 地址。</p><h4 id="Zookeeper的集群节点数目是怎样？架构是怎么样的？怎么选出Leader？"><a href="#Zookeeper的集群节点数目是怎样？架构是怎么样的？怎么选出Leader？" class="headerlink" title="Zookeeper的集群节点数目是怎样？架构是怎么样的？怎么选出Leader？"></a>Zookeeper的集群节点数目是怎样？架构是怎么样的？怎么选出Leader？</h4><p>zookeeper集群的数目，一般为奇数个。节点主要分为leader和follower，observer类似follower但不参与选举，leader负责进行投票的发起和决议，更新系统状态。<br>服务器启动时期的Leader选举： 每个Server发出一个投票，投票包含所推举的服务器的myid和ZXID。接受来自各个服务器的投票。针对每一个投票，优先检查ZXID，如果ZXID相同，那么就比较myid。统计投票，有过半机器接受到相同的投票信息则选举完成。 改变服务器状态。<br>服务器运行时期的Leader选举：follower节点变更状态，进入选举。每个Server会发出一个投票。其余类似。</p><h4 id="从请求一个服务开始的完整流程"><a href="#从请求一个服务开始的完整流程" class="headerlink" title="从请求一个服务开始的完整流程"></a>从请求一个服务开始的完整流程</h4><p>这个当时答得不好。简单回答的话：<br><img src="http://dubbo.apache.org/docs/zh-cn/source_code_guide/sources/images/send-request-process.jpg"></p><ul><li>服务消费方发送请求<br>生成代理类Proxy发起远程调用，接着通过网络客户端 Client 将编码后的请求发送给服务提供方的网络层上。默认情况下，Dubbo 使用 Netty 作为底层的通信框架向消费者发送请求。</li><li>服务提供方接收请求<br>请求解码，得到了一个 Request 对象。将解码后的请求发送至分发器 Dispatcher，再由分发器将请求派发到指定的线程池上调用服务。Dubbo 会在运行时通过 Javassist 框架为 Wrapper 生成实现类，并实现 invokeMethod 方法，该方法最终会根据调用信息调用具体的服务。</li><li>服务提供方返回调用结果</li><li>服务消费方接收调用结果<br>响应数据解码。向用户线程传递调用结果。</li></ul><hr><h2 id="Mysql"><a href="#Mysql" class="headerlink" title="Mysql"></a>Mysql</h2><p>Mysql有印象的问题是问了聚簇索引，然后引申问了InnoDB和MyISAM的数据分布区别。<br>聚簇索引是一种数据存储方式，InnoDB的聚簇索引在同一个结构中保存了B-Tree索引和数据行。聚簇表示数据行和相邻的键值紧凑地存储在一起。非聚集索引中索引是指向表中行的位置的指针，这些指针本身是有序的，通过这些指针可以在表中快速定位数据。<br>MyISAM按照数据插入的顺序存储在磁盘上。InnoDB聚簇索引就是表，每一个叶子节点都包含了主键值、事务ID、回滚指针以及剩余列。</p><hr><h2 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h2><h4 id="Kafka的架构，解释如comsumer和group"><a href="#Kafka的架构，解释如comsumer和group" class="headerlink" title="Kafka的架构，解释如comsumer和group"></a>Kafka的架构，解释如comsumer和group</h4><p>Broker：Kafka 集群包含一个或多个服务器，这种服务器被称为 broker。一台kafka服务器就是一个broker。一个集群由多个broker组成。一个broker可以容纳多个topic。<br>Topic：每条发布到 Kafka 集群的消息都有一个类别，这个类别被称为 Topic。（物理上不同 Topic 的消息分开存储，逻辑上一个 Topic 的消息虽然保存于一个或多个 broker 上，但用户只需指定消息的 Topic 即可生产或消费数据而不必关心数据存于何处）。<br>Partition：Partition 是物理上的概念，每个 Topic 包含一个或多个 Partition。<br>Producer：负责发布消息到 Kafka broker。<br>Consumer：消息消费者，向 Kafka broker 读取消息的客户端。<br>Consumer Group：每个 Consumer 属于一个特定的 Consumer Group（可为每个 Consumer 指定 group name，若不指定 group name 则属于默认的 group）。</p><p>属于某一个消费者群组的消费者订阅了一个主题，通过该订阅消费者可以跨节点地接收所有与该主题相关的消息，每一个消息只会发送给群组中的一个消费者，所有拥有相同键值的消息都会被确保发给这一个消费者。<br>Kafka 设计中将每一个主题分区（Partition）当作一个具有顺序排列的日志。同处于一个分区中的消息都被设置了一个唯一的偏移量。Kafka 只会保持跟踪未读消息，一旦消息被置为已读状态，Kafka 就不会再去管理它了。</p><h4 id="怎么保证高性能"><a href="#怎么保证高性能" class="headerlink" title="怎么保证高性能"></a>怎么保证高性能</h4><p>参考别人的blog，可以有以下几点：利用 Partition 实现并行处理；磁盘顺序写；零拷贝。这一点我暂时了解得不多。</p><hr><h2 id="其他问题"><a href="#其他问题" class="headerlink" title="其他问题"></a>其他问题</h2><p>Nginx启动需要配哪些<br>最近看的Github库<br>平时怎么学习</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;这周去虎扑进行了一次面试，一轮技术面一轮HR面，可惜没有拿到offer。我不太清楚是因为什么原因没有过。技术面中有几个问题我感觉我答得不是很好，打算回顾一下。因此本文一是分享面试经历，二是回顾总结。&lt;/p&gt;</summary>
    
    
    
    <category term="开发" scheme="https://juniousy.github.io/categories/%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="面经" scheme="https://juniousy.github.io/tags/%E9%9D%A2%E7%BB%8F/"/>
    
  </entry>
  
  <entry>
    <title>【本科时期文章】Java 同步器核心AQS</title>
    <link href="https://juniousy.github.io/2019/06/14/Java-%E5%90%8C%E6%AD%A5%E5%99%A8%E6%A0%B8%E5%BF%83AQS/"/>
    <id>https://juniousy.github.io/2019/06/14/Java-%E5%90%8C%E6%AD%A5%E5%99%A8%E6%A0%B8%E5%BF%83AQS/</id>
    <published>2019-06-14T03:27:12.000Z</published>
    <updated>2022-05-30T09:06:50.980Z</updated>
    
    <content type="html"><![CDATA[<p>juc(java.util.concurrent) 基于 AQS （ AbstractQueuedSynchronizer ）框架构建锁机制。本文将介绍AQS是如何实现共享状态同步功能，并在此基础上如何实现同步锁机制。</p><a id="more"></a><h2 id="AbstractQueuedSynchronizer"><a href="#AbstractQueuedSynchronizer" class="headerlink" title="AbstractQueuedSynchronizer"></a>AbstractQueuedSynchronizer</h2><h3 id="CLH同步队列"><a href="#CLH同步队列" class="headerlink" title="CLH同步队列"></a>CLH同步队列</h3><p>AQS如其名所示，使用了队列。当共享资源（即多个线程竞争的资源）被某个线程占有时，其他请求该资源的线程将会阻塞，进入CLH同步队列。</p><p>队列的节点为AQS内部类Node。Node持有前驱和后继，因此队列为双向队列。有如下状态：</p><ul><li>SIGNAL 后继节点阻塞(park)或即将阻塞。当前节点完成任务后要唤醒(unpark)后继节点。</li><li>CANCELLED 节点从同步队列中取消</li><li>CONDITION 当前节点进入等待队列中</li><li>PROPAGATE 表示下一次共享式同步状态获取将会无条件传播下去</li><li>0 其他</li></ul><p>AQS通过头尾指针来管理同步队列，同时实现包括获取锁失败的线程进行入队，释放锁时唤醒对同步队列中的线程。未获取到锁的线程会创建节点线程安全（compareAndSetTail）的加入队列尾部。同步队列遵循FIFO，首节点是获取同步状态成功的节点。</p><h3 id="获取锁"><a href="#获取锁" class="headerlink" title="获取锁"></a>获取锁</h3><p>未获取到锁（tryAcquire失败）的线程将创建一个节点，设置到尾节点。</p><pre><code class="java">public final void acquire(int arg) &#123;    if (!tryAcquire(arg) &amp;&amp;    acquireQueued(addWaiter(Node.EXCLUSIVE), arg))        selfInterrupt();&#125;//创建节点至尾节点private Node addWaiter(Node mode) &#123;    Node node = new Node(Thread.currentThread(), mode);    // Try the fast path of enq; backup to full enq on failure    Node pred = tail;    if (pred != null) &#123;        node.prev = pred;        if (compareAndSetTail(pred, node)) &#123;            pred.next = node;            return node;        &#125;    &#125;    // 如果compareAndSetTail失败或者队列里没有节点    enq(node);    return node;&#125;</code></pre><p>enq是一个CAS的入队方法：</p><pre><code class="java">private Node enq(final Node node) &#123;    for (;;) &#123;        Node t = tail;        if (t == null) &#123; // Must initialize            if (compareAndSetHead(new Node()))                tail = head;        &#125; else &#123;            node.prev = t;            if (compareAndSetTail(t, node)) &#123;                t.next = node;                return t;            &#125;        &#125;    &#125;</code></pre><p>acquireQueued方法的作用是获取锁。</p><pre><code class="java">final boolean acquireQueued(final Node node, int arg) &#123;    boolean failed = true;    try &#123;        boolean interrupted = false;        for (;;) &#123;            final Node p = node.predecessor();            // 获取锁成功            if (p == head &amp;&amp; tryAcquire(arg)) &#123;                setHead(node);                p.next = null; // help GC                failed = false;                return interrupted;            &#125;            // 获取失败则阻塞            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;                parkAndCheckInterrupt())                interrupted = true;        &#125;    &#125; finally &#123;        if (failed)            cancelAcquire(node);    &#125;&#125;</code></pre><h3 id="释放锁"><a href="#释放锁" class="headerlink" title="释放锁"></a>释放锁</h3><p>首节点的线程在释放锁时，将会唤醒后继节点。而后继节点将会在获取锁成功时将自己设置为首节点。</p><pre><code class="java">public final boolean release(int arg) &#123;    if (tryRelease(arg)) &#123;        Node h = head;        if (h != null &amp;&amp; h.waitStatus != 0)            // 唤醒后继节点            unparkSuccessor(h);        return true;    &#125;    return false;&#125;</code></pre><h3 id="响应中断式获取锁"><a href="#响应中断式获取锁" class="headerlink" title="响应中断式获取锁"></a>响应中断式获取锁</h3><p>可响应中断式锁可调用方法lock.lockInterruptibly();而该方法其底层会调用AQS的acquireInterruptibly方法。</p><pre><code class="java">public final void acquireInterruptibly(int arg)    throws InterruptedException &#123;    if (Thread.interrupted())        throw new InterruptedException();    if (!tryAcquire(arg))        doAcquireInterruptibly(arg);&#125;private void doAcquireInterruptibly(int arg)    throws InterruptedException &#123;    final Node node = addWaiter(Node.EXCLUSIVE);    boolean failed = true;    try &#123;        for (;;) &#123;            final Node p = node.predecessor();            if (p == head &amp;&amp; tryAcquire(arg)) &#123;                setHead(node);                p.next = null; // help GC                failed = false;                return;            &#125;            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;                parkAndCheckInterrupt())                // 唯一的区别是当parkAndCheckInterrupt返回true时即线程阻塞时该线程被中断，代码抛出被中断异常。                throw new InterruptedException();        &#125;    &#125; finally &#123;        if (failed)            cancelAcquire(node);    &#125;&#125;</code></pre><h3 id="超时等待获取锁"><a href="#超时等待获取锁" class="headerlink" title="超时等待获取锁"></a>超时等待获取锁</h3><p>通过调用lock.tryLock(timeout,TimeUnit)方式达到超时等待获取锁的效果，调用AQS的方法tryAcquireNanos()。</p><pre><code class="java">public final boolean tryAcquireNanos(int arg, long nanosTimeout)    throws InterruptedException &#123;    if (Thread.interrupted())        throw new InterruptedException();    return tryAcquire(arg) ||        doAcquireNanos(arg, nanosTimeout);&#125;tongbuqiprivate boolean doAcquireNanos(int arg, long nanosTimeout)    throws InterruptedException &#123;    if (nanosTimeout &lt;= 0L)        return false;    final long deadline = System.nanoTime() + nanosTimeout;    final Node node = addWaiter(Node.EXCLUSIVE);    boolean failed = true;    try &#123;        for (;;) &#123;            final Node p = node.predecessor();            if (p == head &amp;&amp; tryAcquire(arg)) &#123;                setHead(node);                p.next = null; // help GC                failed = false;                return true;            &#125;            // 计算等待时间            nanosTimeout = deadline - System.nanoTime();            if (nanosTimeout &lt;= 0L)                return false;            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;                nanosTimeout &gt; spinForTimeoutThreshold)                LockSupport.parkNanos(this, nanosTimeout);            if (Thread.interrupted())                throw new InterruptedException();        &#125;    &#125; finally &#123;        if (failed)            cancelAcquire(node);    &#125;    &#125;</code></pre><h3 id="共享锁的获取"><a href="#共享锁的获取" class="headerlink" title="共享锁的获取"></a>共享锁的获取</h3><p>最后看下共享锁的获取。</p><pre><code class="java">public final void acquireShared(int arg) &#123;    if (tryAcquireShared(arg) &lt; 0)        //获取锁失败时调用        doAcquireShared(arg);&#125;private void doAcquireShared(int arg) &#123;    final Node node = addWaiter(Node.SHARED);    boolean failed = true;    try &#123;        boolean interrupted = false;        for (;;) &#123;            final Node p = node.predecessor();            if (p == head) &#123;                int r = tryAcquireShared(arg);                // 当tryAcquireShared返回值&gt;=0时取得锁                if (r &gt;= 0) &#123;                    setHeadAndPropagate(node, r);                    p.next = null; // help GC                    if (interrupted)                        selfInterrupt();                    failed = false;                    return;                &#125;            &#125;            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;                parkAndCheckInterrupt())                interrupted = true;        &#125;    &#125; finally &#123;        if (failed)            cancelAcquire(node);    &#125;&#125;</code></pre><h3 id="队列外成员变量"><a href="#队列外成员变量" class="headerlink" title="队列外成员变量"></a>队列外成员变量</h3><p>AQ还有<code>state</code>成员变量，volatile int类型，用于同步线程之间的共享状态。当state&gt;0时表示已经获取了锁，对于重入锁来说state值即重入数，当state = 0时表示释放了锁。具体说明见下面各同步器的实现。</p><h2 id="实现同步器"><a href="#实现同步器" class="headerlink" title="实现同步器"></a>实现同步器</h2><p>每一种同步器都通过实现<code>tryacquire</code>（包括如<code>tryAcquireShared</code>之类的方法）、<code>tryRelease</code>来实现同步功能。</p><h3 id="ReentrantLock"><a href="#ReentrantLock" class="headerlink" title="ReentrantLock"></a>ReentrantLock</h3><p>主要看获取锁的过程<br>非公平锁获取锁：</p><pre><code class="java">final boolean nonfairTryAcquire(int acquires) &#123;    final Thread current = Thread.currentThread();    int c = getState();    //如果当前重进入数为0,说明有机会取得锁    if (c == 0) &#123;        //抢占式获取锁 compareAndSetState是原子方法        if (compareAndSetState(0, acquires)) &#123;            setExclusiveOwnerThread(current);            return true;        &#125;    &#125;    //如果当前线程本身就持有锁，那么叠加重进入数，并且继续获得锁    else if (current == getExclusiveOwnerThread()) &#123;        int nextc = c + acquires;        if (nextc &lt; 0) // overflow            throw new Error(&quot;Maximum lock count exceeded&quot;);        setState(nextc);        return true;    &#125;    //以上条件都不满足，那么线程进入等待队列。    return false;&#125;</code></pre><p>公平锁获取锁类似：</p><pre><code class="java">protected final boolean tryAcquire(int acquires) &#123;    final Thread current = Thread.currentThread();    int c = getState();    if (c == 0) &#123;    // 区别之处，非抢占式        if (!hasQueuedPredecessors() &amp;&amp;            compareAndSetState(0, acquires)) &#123;            setExclusiveOwnerThread(current);            return true;        &#125;    &#125;    else if (current == getExclusiveOwnerThread()) &#123;        int nextc = c + acquires;        if (nextc &lt; 0)            throw new Error(&quot;Maximum lock count exceeded&quot;);        setState(nextc);        return true;    &#125;    return false;&#125;</code></pre><h3 id="Semaphore"><a href="#Semaphore" class="headerlink" title="Semaphore"></a>Semaphore</h3><p>以<code>state</code>作为信号量使用，例子：</p><pre><code class="java">final int nonfairTryAcquireShared(int acquires) &#123;    for (;;) &#123;        int available = getState();        int remaining = available - acquires; //剩下多少许可资源        if (remaining &lt; 0 ||            compareAndSetState(available, remaining))            return remaining;    &#125;&#125;</code></pre><h3 id="CountDownLatch"><a href="#CountDownLatch" class="headerlink" title="CountDownLatch"></a>CountDownLatch</h3><p>以<code>state</code>作为计数器，<code>state</code>为0时等待结束：</p><pre><code class="java">public void await() throws InterruptedException &#123;    //阻塞直到state为0    sync.acquireSharedInterruptibly(1);&#125;</code></pre><p>用同步器方法减少state</p><pre><code class="java">public void countDown() &#123;    sync.releaseShared(1);&#125;</code></pre><pre><code class="java">protected boolean tryReleaseShared(int releases) &#123;    // Decrement count; signal when transition to zero    for (;;) &#123;        int c = getState();        if (c == 0)            return false;        int nextc = c-1;        if (compareAndSetState(c, nextc))            return nextc == 0;    &#125;&#125;</code></pre>]]></content>
    
    
    <summary type="html">&lt;p&gt;juc(java.util.concurrent) 基于 AQS （ AbstractQueuedSynchronizer ）框架构建锁机制。本文将介绍AQS是如何实现共享状态同步功能，并在此基础上如何实现同步锁机制。&lt;/p&gt;</summary>
    
    
    
    <category term="开发" scheme="https://juniousy.github.io/categories/%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="Java" scheme="https://juniousy.github.io/tags/Java/"/>
    
    <category term="并发" scheme="https://juniousy.github.io/tags/%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>【本科时期文章】Redis的数据结构与编码</title>
    <link href="https://juniousy.github.io/2019/06/05/Redis%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%BC%96%E7%A0%81/"/>
    <id>https://juniousy.github.io/2019/06/05/Redis%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%BC%96%E7%A0%81/</id>
    <published>2019-06-05T07:42:40.000Z</published>
    <updated>2022-05-30T09:06:50.982Z</updated>
    
    <content type="html"><![CDATA[<table><thead><tr><th align="center">类型</th><th align="center">编码方式</th><th align="center">数据结构</th></tr></thead><tbody><tr><td align="center">string</td><td align="center">raw</td><td align="center">动态字符串编码</td></tr><tr><td align="center"></td><td align="center">embstr</td><td align="center">优化内存分配的字符串编码</td></tr><tr><td align="center"></td><td align="center">int</td><td align="center">整数编码</td></tr><tr><td align="center">hash</td><td align="center">hashtable</td><td align="center">散列表编码</td></tr><tr><td align="center"></td><td align="center">ziplist</td><td align="center">压缩列表编码</td></tr><tr><td align="center">list</td><td align="center">linkedlist</td><td align="center">双向链表编码</td></tr><tr><td align="center"></td><td align="center">ziplist</td><td align="center">压缩列表编码</td></tr><tr><td align="center"></td><td align="center">quicklist</td><td align="center">3.2版本新的列表编码</td></tr><tr><td align="center">set</td><td align="center">hashtable</td><td align="center">散列表编码</td></tr><tr><td align="center"></td><td align="center">intset</td><td align="center">整数集合编码</td></tr><tr><td align="center">zset</td><td align="center">skiplist</td><td align="center">跳跃表编码</td></tr><tr><td align="center"></td><td align="center">ziplist</td><td align="center">压缩列表编码</td></tr></tbody></table><a id="more"></a><h3 id="字符串结构"><a href="#字符串结构" class="headerlink" title="字符串结构"></a>字符串结构</h3><p>Redis没有采用原生C语言的字符串类型，而是自己实现了字符串结构，内部简单动态字符串(simple dynamic string，SDS)。特点如下：</p><ul><li>O(1)时间复杂度获取字符串长度、已用长度、未用长度</li><li>可用于保存字节数组，支持安全的二进制数据存储</li><li>内部实现空间预分配机制，降低内存内存再分配次数</li><li>惰性删除机制，字符串缩减后的空间不释放，作为预分配空间保留</li></ul><p>对于string，</p><ul><li>int：8个字节的长整型</li><li>embstr：小于等于39个字节的字符串</li><li>raw：大于39个字节的字符串，即用简单动态字符串（SDS）存储</li></ul><p>embstr 编码的优化之处在于将创建字符串对象所需的内存分配次数从 raw 编码的两次降低为一次，mbstr 编码的字符串对象的所有数据都保存在一块连续的内存里面，redisObject 结构(type, encoding…)和 sdshdr 结构(free, len, buf)都放在一起<br>embstr 编码的字符串对象实际上是只读的： 当我们对 embstr 编码的字符串对象执行任何修改命令时， 程序会先将对象的编码从 embstr 转换成 raw ， 然后再执行修改命令； 因为这个原因， embstr 编码的字符串对象在执行修改命令之后， 总会变成一个 raw 编码的字符串对象。</p><h3 id="ziplist-压缩列表"><a href="#ziplist-压缩列表" class="headerlink" title="ziplist 压缩列表"></a>ziplist 压缩列表</h3><p>hash、list、zset中，如果所有值小于hash_max_ziplist_value （默认值为 64 ），且元素个数小于 hash_max_ziplist_entries （默认值为 512 ）时使用ziplist编码。</p><p>ziplist编码的主要目的是为了节约内存，因此所有数据都是采用线性连续的内存结构。结构字段含义：</p><ol><li>zlbytes：整个压缩列表所占字节长度。int-32，长度4字节。</li><li>zltail：距离尾节点的偏移量。int-32，长度4字节。</li><li>zllen：int-16，长度2字节。</li><li>entry：具体的节点：<ol><li>prev_entry_bytes_length：记录前一个节点所占空间</li><li>encoding：标示当前节点编码和长度</li><li>contents：保存节点的值</li></ol></li><li>zlend：记录列表结尾，占一个字节</li></ol><p>从上可以看出存在双向链表结构，以O(1)时间复杂度入队和出队。而新增删除操作涉及内存重新分配和释放。</p><h3 id="hashtable"><a href="#hashtable" class="headerlink" title="hashtable"></a>hashtable</h3><p>Redis 使用的hash算法是 MurmurHash2 ，解决冲突的方式是链地址法。程序总是将新节点添加到链表的表头位置（复杂度为 O(1)）， 排在其他已有节点的前面。按2的幂rehash。</p><h3 id="linkedlist"><a href="#linkedlist" class="headerlink" title="linkedlist"></a>linkedlist</h3><p><a href="http://redisbook.com/preview/adlist/implementation.html">Redis 的链表实现的特性可以总结如下</a>：</p><ul><li>双端： langfei链表节点带有 prev 和 next 指针， 获取某个节点的前置节点和后置节点的复杂度都是 O(1) 。</li><li>无环： 表头节点的 prev 指针和表尾节点的 next 指针都指向 NULL ， 对链表的访问以 NULL 为终点。</li><li>带表头指针和表尾指针： 通过 list 结构的 head 指针和 tail 指针， 程序获取链表的表头节点和表尾节点的复杂度为 O(1) 。</li><li>带链表长度计数器： 程序使用 list 结构的 len 属性来对 list 持有的链表节点进行计数， 程序获取链表中节点数量的复杂度为 O(1) 。</li><li>多态： 链表节点使用 void* 指针来保存节点值， 并且可以通过 list 结构的 dup 、 free 、 match 三个属性为节点值设置类型特定函数， 所以链表可以用于保存各种不同类型的值。</li></ul><h3 id="intset"><a href="#intset" class="headerlink" title="intset"></a>intset</h3><p>存储有序、不重复的整数集。集合只包含整数且长度不超过set-max-intset-entries</p><p>intset对写入整数进行排序，通过O(lgn)时间复杂度实现查找和去重操作。字段含义：</p><ul><li>encoding：整数表示类型，根据集合内最长整数值确定类型，整数类型划分为int-16，int-32，int-64</li><li>length：表示集合元素个数</li><li>contents：整数数组，按从小到达顺序排列</li></ul><p>尽量保证整数范围一致，防止个别大整数触发集合升级操作，产生内存浪费。</p><h3 id="skiplist"><a href="#skiplist" class="headerlink" title="skiplist"></a>skiplist</h3><p>过在每个节点中维持多个指向其他节点的指针， 从而达到快速访问节点的目的。跳跃表支持平均 O(log N) 最坏 O(N) 复杂度的节点查找， 还可以通过顺序性操作来批量处理节点。</p><h3 id="Object"><a href="#Object" class="headerlink" title="Object"></a>Object</h3><p>Redis 中的每个对象都由一个 redisObject 结构表示， 该结构中和保存数据有关的三个属性分别是 type 属性、 encoding 属性和 ptr 属性。对象的 type 属性记录了对象的类型。对象的 ptr 指针指向对象的底层实现数据结构， 而这些数据结构由对象的 encoding 属性决定。</p><p>因为 C 语言并不具备自动的内存回收功能， 所以 Redis 在自己的对象系统中构建了一个引用计数（reference counting）技术实现的内存回收机制， 通过这一机制， 程序可以通过跟踪对象的引用计数信息， 在适当的时候自动释放对象并进行内存回收。由redisObject 结构的 refcount 属性记录：</p><ul><li>在创建一个新对象时， 引用计数的值会被初始化为 1 ；</li><li>当对象被一个新程序使用时， 它的引用计数值会被增一；</li><li>当对象不再被一个程序使用时， 它的引用计数值会被减一；</li><li>当对象的引用计数值变为 0 时， 对象所占用的内存会被释放。</li></ul><p>redisObject 结构包含的最后一个属性为 lru 属性， 该属性记录了对象最后一次被命令程序访问的时间。OBJECT IDLETIME 命令可以打印出给定键的空转时长， 这一空转时长就是通过将当前时间减去键的值对象的 lru 时间计算得出的。</p>]]></content>
    
    
    <summary type="html">&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;center&quot;&gt;类型&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;编码方式&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;数据结构&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;string&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;raw&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;动态字符串编码&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;embstr&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;优化内存分配的字符串编码&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;int&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;整数编码&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;hash&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;hashtable&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;散列表编码&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;ziplist&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;压缩列表编码&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;list&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;linkedlist&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;双向链表编码&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;ziplist&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;压缩列表编码&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;quicklist&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;3.2版本新的列表编码&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;set&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;hashtable&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;散列表编码&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;intset&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;整数集合编码&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;zset&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;skiplist&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;跳跃表编码&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;ziplist&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;压缩列表编码&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;</summary>
    
    
    
    <category term="开发" scheme="https://juniousy.github.io/categories/%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="Redis" scheme="https://juniousy.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>【本科时期文章】从Redis I/O多路复用到Java NIO Selector</title>
    <link href="https://juniousy.github.io/2019/06/04/%E4%BB%8ERedis-I-O%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E5%88%B0Java-NIO-Selector/"/>
    <id>https://juniousy.github.io/2019/06/04/%E4%BB%8ERedis-I-O%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E5%88%B0Java-NIO-Selector/</id>
    <published>2019-06-04T07:19:21.000Z</published>
    <updated>2022-05-30T09:06:50.983Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Redis的I-O多路复用架构"><a href="#Redis的I-O多路复用架构" class="headerlink" title="Redis的I/O多路复用架构"></a>Redis的I/O多路复用架构</h3><p>Redis的一大特点就是单线程架构。单线程架构既避免了多线程可能产生的竞争问题，又避免了多线程的频繁上下文切换问题，是Redis高效率的保证。</p><a id="more"></a><p>对于网络I/O操作，Redis基于 Reactor 模式可以用单个线程处理多个Socket。内部实现为使用文件事件处理器(file event handler)进行网络事件处理器，这个文件事件处理器是单线程的。文件事件处理器采用<code> I/O 多路复用机制(multiplexing)</code>同时监听多个 socket。产生事件的 socket 压入内存队列中，事件分派器根据 socket 上的事件类型来选择对应的事件处理器进行处理。操作包括应答（accept）、读取（read）、写入（write）、关闭（close）等。文件事件处理器的结构包含 4 个部分：</p><ul><li>多个 socket</li><li>I/O 多路复用程序</li><li>文件事件分派器</li><li>事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）<br>连接应答处理器会创建一个能与客户端通信的 socket01，通过这个返回结果给客户端。Redis单线程的核心就是I/O 多路复用程序。</li></ul><p>I/O多路复用（IO Multiplexing）有时也称为异步阻塞IO，是一种事件驱动的I/O模型。单个I/O操作在一般情况下往往不能直接返回，传统的阻塞 I/O 模型会阻塞直到系统内核返回数据。而在 I/O 多路复用模型中，系统调用select/poll/epoll 函数会不断的查询所监测的 socket 文件描述符，查看其中是否有 socket 准备好读写了，如果有，那么系统就会通知用户进程。</p><p>Redis 的 I/O 多路复用程序的所有功能都是通过包装常见的 select 、 epoll 、 evport 和 kqueue 这些 I/O 多路复用函数库来实现的， 每个 I/O 多路复用函数库在 Redis 源码中都对应一个单独的文件。</p><p>以ae_select.c实现的封装select方法为例。<code>select</code>方法定义如下所示，检测是否可读、可写、异常，返回准备完毕的descriptors个数。</p><pre><code class="c">extern int select (int __nfds, fd_set *__restrict __readfds,           fd_set *__restrict __writefds,           fd_set *__restrict __exceptfds,           struct timeval *__restrict __timeout);</code></pre><p>Redis封装首先通过<code>aeApiCreate</code>初始化 rfds 和 wfds，注册到aeEventLoop中去。</p><pre><code class="c">static int aeApiCreate(aeEventLoop *eventLoop) &#123;    aeApiState *state = zmalloc(sizeof(aeApiState));    if (!state) return -1;    FD_ZERO(&amp;state-&gt;rfds);    FD_ZERO(&amp;state-&gt;wfds);    eventLoop-&gt;apidata = state;    return 0;&#125;</code></pre><p>而 <code>aeApiAddEvent</code> 和 <code>aeApiDelEvent</code> 会通过 FD_SET 和 FD_CLR 修改 fd_set 中对应 FD 的标志位。</p><pre><code class="c">static int aeApiAddEvent(aeEventLoop *eventLoop, int fd, int mask) &#123;    aeApiState *state = eventLoop-&gt;apidata;    if (mask &amp; AE_READABLE) FD_SET(fd,&amp;state-&gt;rfds);    if (mask &amp; AE_WRITABLE) FD_SET(fd,&amp;state-&gt;wfds);    return 0;&#125;static void aeApiDelEvent(aeEventLoop *eventLoop, int fd, int mask) &#123;    aeApiState *state = eventLoop-&gt;apidata;    if (mask &amp; AE_READABLE) FD_CLR(fd,&amp;state-&gt;rfds);    if (mask &amp; AE_WRITABLE) FD_CLR(fd,&amp;state-&gt;wfds);&#125;</code></pre><p><code>aeApiPoll</code>是实际调用 select 函数的部分，其作用就是在 I/O 多路复用函数返回时，将对应的 FD 加入 aeEventLoop 的 fired 数组中，并返回事件的个数：</p><pre><code class="c">static int aeApiPoll(aeEventLoop *eventLoop, struct timeval *tvp) &#123;    aeApiState *state = eventLoop-&gt;apidata;    int retval, j, numevents = 0;    memcpy(&amp;state-&gt;_rfds,&amp;state-&gt;rfds,sizeof(fd_set));    memcpy(&amp;state-&gt;_wfds,&amp;state-&gt;wfds,sizeof(fd_set));    retval = select(eventLoop-&gt;maxfd+1,                &amp;state-&gt;_rfds,&amp;state-&gt;_wfds,NULL,tvp);    if (retval &gt; 0) &#123;        for (j = 0; j &lt;= eventLoop-&gt;maxfd; j++) &#123;            int mask = 0;            aeFileEvent *fe = &amp;eventLoop-&gt;events[j];            if (fe-&gt;mask == AE_NONE) continue;            if (fe-&gt;mask &amp; AE_READABLE &amp;&amp; FD_ISSET(j,&amp;state-&gt;_rfds))                mask |= AE_READABLE;            if (fe-&gt;mask &amp; AE_WRITABLE &amp;&amp; FD_ISSET(j,&amp;state-&gt;_wfds))                mask |= AE_WRITABLE;            eventLoop-&gt;fired[numevents].fd = j;            eventLoop-&gt;fired[numevents].mask = mask;            numevents++;        &#125;    &#125;    return numevents;&#125;</code></pre><p>epoll函数的封装类似。区别在于 epoll_wait 函数返回时并不需要遍历所有的 FD 查看读写情况；在  epoll_wait 函数返回时会提供一个 epoll_event 数组，其中保存了发生的 epoll 事件（EPOLLIN、EPOLLOUT、EPOLLERR 和 EPOLLHUP）以及发生该事件的 FD。Redis封装的调用只需要将<code>epoll_event</code>数组中存储的信息加入eventLoop的 fired 数组中，将信息传递给上层模块：</p><pre><code class="c">static int aeApiPoll(aeEventLoop *eventLoop, struct timeval *tvp) &#123;    aeApiState *state = eventLoop-&gt;apidata;    int retval, numevents = 0;    retval = epoll_wait(state-&gt;epfd,state-&gt;events,eventLoop-&gt;setsize,            tvp ? (tvp-&gt;tv_sec*1000 + tvp-&gt;tv_usec/1000) : -1);    if (retval &gt; 0) &#123;        int j;        numevents = retval;        for (j = 0; j &lt; numevents; j++) &#123;            int mask = 0;            struct epoll_event *e = state-&gt;events+j;            if (e-&gt;events &amp; EPOLLIN) mask |= AE_READABLE;            if (e-&gt;events &amp; EPOLLOUT) mask |= AE_WRITABLE;            if (e-&gt;events &amp; EPOLLERR) mask |= AE_WRITABLE;            if (e-&gt;events &amp; EPOLLHUP) mask |= AE_WRITABLE;            eventLoop-&gt;fired[j].fd = e-&gt;data.fd;            eventLoop-&gt;fired[j].mask = mask;        &#125;    &#125;    return numevents;&#125;</code></pre><p>当Socket变得可读时（客户端对Socket执行 write 操作，或者执行 close 操作）， 或者有新的可应答（acceptable）Socket出现时（客户端对服务器的监听Socket执行 connect 操作），Socket产生 AE_READABLE 事件。而当Socket变得可写时（客户端对Socket执行 read 操作）， Socket产生 AE_WRITABLE 事件。<br>I/O 多路复用程序允许服务器同时监听Socket的 AE_READABLE 事件和 AE_WRITABLE 事件， 如果一个Socket同时产生了这两种事件， 那么文件事件分派器会优先处理 AE_READABLE 事件， 等到 AE_READABLE 事件处理完之后， 才处理 AE_WRITABLE 事件。换句话说， 如果一个Socket又可读又可写的话， 那么服务器将先读Socket， 后写Socket。</p><h3 id="Java-NIO-Selector"><a href="#Java-NIO-Selector" class="headerlink" title="Java NIO Selector"></a>Java NIO Selector</h3><p>Java中也有I/O多路复用的方式，例子为NIO的<code>Selector</code>。<br><code>selector</code>的创建方式为调用<code>Selector</code>类的静态方法，由<code>SelectorProvider</code>提供：<code>Selector selector = Selector.open();</code></p><pre><code class="java">public static Selector open() throws IOException &#123;    return SelectorProvider.provider().openSelector();&#125;</code></pre><p><code>SelectorProvider</code>是单例模式，Linux默认提供<code>EPollSelectorProvider</code>，即提供的Selector为<code>EPollSelectorImpl</code>。</p><pre><code class="java">public static SelectorProvider provider() &#123;    synchronized (lock) &#123;        if (provider != null)            return provider;        return AccessController.doPrivileged(            new PrivilegedAction&lt;SelectorProvider&gt;() &#123;                public SelectorProvider run() &#123;                    if (loadProviderFromProperty())                        return provider;                    if (loadProviderAsService())                        return provider;                    provider = sun.nio.ch.DefaultSelectorProvider.create();                    return provider;                &#125;            &#125;);    &#125;&#125;//...../**     * Returns the default SelectorProvider.     */public static SelectorProvider create() &#123;    String osname = AccessController        .doPrivileged(new GetPropertyAction(&quot;os.name&quot;));    if (osname.equals(&quot;SunOS&quot;))        return createProvider(&quot;sun.nio.ch.DevPollSelectorProvider&quot;);    if (osname.equals(&quot;Linux&quot;))        return createProvider(&quot;sun.nio.ch.EPollSelectorProvider&quot;);    return new sun.nio.ch.PollSelectorProvider();&#125;</code></pre><p>调用系统Epoll方法的地方在<code>EPollArrayWrapper</code>类的<code>poll</code>方法中，该类由<code>EPollSelectorImpl</code>持有：</p><pre><code class="java">int poll(long timeout) throws IOException &#123;    updateRegistrations();    updated = epollWait(pollArrayAddress, NUM_EPOLLEVENTS, timeout, epfd);    for (int i=0; i&lt;updated; i++) &#123;        if (getDescriptor(i) == incomingInterruptFD) &#123;            interruptedIndex = i;            interrupted = true;            break;        &#125;    &#125;    return updated;&#125;</code></pre><p><code>Selector</code>使用中需要绑定<code>Channel</code>。以<code>ServerSocketChannel</code>为例：</p><pre><code class="java">ServerSocketChannel serverSocket = ServerSocketChannel.open();serverSocket.bind(new InetSocketAddress(&quot;localhost&quot;, 5454));serverSocket.configureBlocking(false);serverSocket.register(selector, SelectionKey.OP_ACCEPT);</code></pre><p>注册时会调用<code>Selector</code>的回调方法<code>register</code>，生成<code>SelectionKey</code>。</p><pre><code class="java">protected final SelectionKey register(AbstractSelectableChannel ch,                                      int ops,                                      Object attachment)&#123;    if (!(ch instanceof SelChImpl))        throw new IllegalSelectorException();    SelectionKeyImpl k = new SelectionKeyImpl((SelChImpl)ch, this);    k.attach(attachment);    synchronized (publicKeys) &#123;        implRegister(k);    &#125;    k.interestOps(ops);    return k;&#125;</code></pre><p>最后在使用时根据<code>SelectionKeys</code>遍历查看状态。可以通过监听的事件有：</p><ul><li>Connect – OP_CONNECT client尝试连接</li><li>Accept – OP_ACCEPT server端接受连接</li><li>Read – OP_READ server端可以开始从channel里读取</li><li>Write – OP_WRITE server端可以向channel里写</li></ul><p>使用方式类似：</p><pre><code class="java">while (true) &#123;    selector.select();    Set&lt;SelectionKey&gt; selectedKeys = selector.selectedKeys();    Iterator&lt;SelectionKey&gt; iter = selectedKeys.iterator();    while (iter.hasNext()) &#123;        SelectionKey key = iter.next();        if (key.isAcceptable()) &#123;            register(selector, serverSocket);        &#125;        if (key.isReadable()) &#123;            answerWithEcho(buffer, key);        &#125;        iter.remove();    &#125;&#125;</code></pre><p><code>Selector</code>的wakeup()方法主要作用是解除阻塞在Selector.select()/select(long)上的线程，立即返回，调用了本地的中断方法。可以在注册了新的channel或者事件、channel关闭，取消注册时使用，或者优先级更高的事件触发（如定时器事件），希望及时处理。</p><p>通过NIO的I/O多路复用方式可以节约线程资源，提高网络I/O效率。</p><h4 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h4><ul><li><a href="http://redisbook.com/preview/event/file_event.html">Redis 设计与实现-文件事件</a></li><li><a href="https://draveness.me/redis-io-multiplexing">Redis 和 I/O 多路复用</a></li><li><a href="https://www.baeldung.com/java-nio-selector">Introduction to the Java NIO Selector</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;h3 id=&quot;Redis的I-O多路复用架构&quot;&gt;&lt;a href=&quot;#Redis的I-O多路复用架构&quot; class=&quot;headerlink&quot; title=&quot;Redis的I/O多路复用架构&quot;&gt;&lt;/a&gt;Redis的I/O多路复用架构&lt;/h3&gt;&lt;p&gt;Redis的一大特点就是单线程架构。单线程架构既避免了多线程可能产生的竞争问题，又避免了多线程的频繁上下文切换问题，是Redis高效率的保证。&lt;/p&gt;</summary>
    
    
    
    <category term="开发" scheme="https://juniousy.github.io/categories/%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="Java" scheme="https://juniousy.github.io/tags/Java/"/>
    
    <category term="Redis" scheme="https://juniousy.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>【本科时期文章】LeetCode 23. Merge k Sorted Lists</title>
    <link href="https://juniousy.github.io/2019/05/17/LeetCode-23-Merge-k-Sorted-Lists/"/>
    <id>https://juniousy.github.io/2019/05/17/LeetCode-23-Merge-k-Sorted-Lists/</id>
    <published>2019-05-17T08:53:24.000Z</published>
    <updated>2022-05-30T09:06:50.981Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a>Problem</h2><p>Merge <em>k</em> sorted linked lists and return it as one sorted list. Analyze and describe its complexity.</p><p><strong>Example:</strong></p><pre><code>Input:[  1-&gt;4-&gt;5,  1-&gt;3-&gt;4,  2-&gt;6]Output: 1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4-&gt;5-&gt;6</code></pre><a id="more"></a><h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><p>使用priority queue</p><pre><code class="java">/* * @lc app=leetcode id=23 lang=java * * [23] Merge k Sorted Lists *//** * Definition for singly-linked list. * public class ListNode &#123; *     int val; *     ListNode next; *     ListNode(int x) &#123; val = x; &#125; * &#125; */class Solution &#123;    public ListNode mergeKLists(ListNode[] lists) &#123;        if (lists == null || lists.length == 0) return null;        PriorityQueue&lt;ListNode&gt; pQueue = new PriorityQueue&lt;&gt;((a, b) -&gt; a.val - b.val);        ListNode dummy = new ListNode(0);        ListNode cur = dummy;        for (ListNode node:lists) &#123;            if (node == null) continue;            pQueue.offer(node);        &#125;        while(!pQueue.isEmpty()) &#123;            cur.next = pQueue.poll();            cur = cur.next;            if (cur.next != null) pQueue.offer(cur.next);        &#125;        return dummy.next;    &#125;&#125;</code></pre><p>Time complexity: O(nlogk)</p><p>Space complexity: O(k)</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;Problem&quot;&gt;&lt;a href=&quot;#Problem&quot; class=&quot;headerlink&quot; title=&quot;Problem&quot;&gt;&lt;/a&gt;Problem&lt;/h2&gt;&lt;p&gt;Merge &lt;em&gt;k&lt;/em&gt; sorted linked lists and return it as one sorted list. Analyze and describe its complexity.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Input:
[
  1-&amp;gt;4-&amp;gt;5,
  1-&amp;gt;3-&amp;gt;4,
  2-&amp;gt;6
]
Output: 1-&amp;gt;1-&amp;gt;2-&amp;gt;3-&amp;gt;4-&amp;gt;4-&amp;gt;5-&amp;gt;6&lt;/code&gt;&lt;/pre&gt;</summary>
    
    
    
    <category term="刷题" scheme="https://juniousy.github.io/categories/%E5%88%B7%E9%A2%98/"/>
    
    
    <category term="算法" scheme="https://juniousy.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>【本科时期文章】ThreadLocal</title>
    <link href="https://juniousy.github.io/2019/03/24/ThreadLocal/"/>
    <id>https://juniousy.github.io/2019/03/24/ThreadLocal/</id>
    <published>2019-03-24T14:12:30.000Z</published>
    <updated>2022-05-30T09:06:50.983Z</updated>
    
    <content type="html"><![CDATA[<p>ThreadLocal的作用并不是解决多线程共享变量的问题，而是存储那些线程间隔离，但在不同方法间共享的变量。这是线程安全的一种无同步方案，另一种是无同步方案是幂等的可重入代码。</p><p>下面先模拟一个基本的ThreadLocal存储User id的模型，然后解析原理。</p><a id="more"></a><hr><h4 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h4><pre><code class="java">import java.util.concurrent.atomic.AtomicInteger;public class ThreadLocalTest &#123;  //工作线程  class Worker implements Runnable &#123;    ThreadLocal&lt;Integer&gt; userId = ThreadLocal.withInitial(() -&gt; 1);    UserRepo userRepo;    Worker(UserRepo userRepo) &#123;      this.userRepo = userRepo;    &#125;    @Override    public void run() &#123;      for (int i = 0; i &lt; 10; i++) &#123;        handler();        try &#123;          Thread.sleep(30);        &#125; catch (InterruptedException e) &#123;          e.printStackTrace();        &#125;      &#125;    &#125;    private void handler() &#123;      userId.set(userRepo.getUserId());      System.out.println(Thread.currentThread().getName() + &quot; userId: &quot; + userId.get());    &#125;  &#125;  //模拟拿自增user id  class UserRepo &#123;    private AtomicInteger incrUserId = new AtomicInteger(1);    private Integer getUserId() &#123;      return incrUserId.getAndIncrement();    &#125;  &#125;  private void test() &#123;    UserRepo userRepo = new UserRepo();    for (int i = 0; i &lt; 15; i++) &#123;      new Thread(new Worker(userRepo)).start();    &#125;  &#125;  public static void main(String[] args) &#123;    ThreadLocalTest test = new ThreadLocalTest();    test.test();  &#125;&#125;</code></pre><p>结果如下</p><pre><code>........(上略)Thread-13 userId: 135Thread-0 userId: 136Thread-2 userId: 137Thread-1 userId: 138Thread-4 userId: 139Thread-5 userId: 140Thread-3 userId: 141Thread-6 userId: 142Thread-7 userId: 143Thread-9 userId: 144Thread-10 userId: 145Thread-11 userId: 146Thread-8 userId: 147Thread-12 userId: 149Thread-14 userId: 148Thread-13 userId: 150</code></pre><hr><h4 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h4><p>核心是ThreadLocal的内部静态类ThreadLocalMap。map的key是ThreadLocal对象，value是和ThreadLocal对象有关联的值。</p><pre><code class="java">static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123;    /** The value associated with this ThreadLocal. */    Object value;    Entry(ThreadLocal&lt;?&gt; k, Object v) &#123;        super(k);        value = v;    &#125;&#125;</code></pre><p>注意内部Entry是WeakReference的，原因是出于性能考虑。由于不是强联系，所以其他正在使用ThreadLocal的线程，不会妨碍gc那些来自同一个ThreadLocal的终止后的线程的变量，简单来讲就是待gc的变量会被正确gc。</p><p>在ThreadLocalMap 的 remove 方法中，除了讲entry的引用设为null以外，还调用了一个expungeStaleEntry方法：</p><pre><code class="java">if (e.get() == key) &#123;    e.clear();    expungeStaleEntry(i);    return;&#125;</code></pre><p>其中会将所有键为 null 的 Entry 的值设置为 null，这样可以防止内存泄露，已经不再被使用且已被回收的 ThreadLocal 对象对应的Entry也会被gc清除：</p><pre><code class="java">if (k == null) &#123;    e.value = null;    tab[i] = null;    size--;&#125;</code></pre><p>在同样的还有rehash, resize方法方法中，也有类似的设置value为null的操作。</p><p>在创建线程时，该线程持有threadLocals。这个引用是在ThreadLocal的createMap方法中设定的，否则为null。</p><pre><code class="java">void createMap(Thread t, T firstValue) &#123;    t.threadLocals = new ThreadLocalMap(this, firstValue);&#125;</code></pre><p>调用ThreadLocalMap的构造方法：</p><pre><code class="java">ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) &#123;    table = new Entry[INITIAL_CAPACITY];    int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1);    table[i] = new Entry(firstKey, firstValue);    size = 1;    setThreshold(INITIAL_CAPACITY);&#125;</code></pre><p>再返回来看ThreadLocal就很好理解了<br>get方法：</p><pre><code class="java">public T get() &#123;    Thread t = Thread.currentThread();    ThreadLocalMap map = getMap(t); //获取当前线程的ThreadLocalMap    if (map != null) &#123;        ThreadLocalMap.Entry e = map.getEntry(this); //从map中取值，key就是当前ThreadLocal对象        if (e != null) &#123;            @SuppressWarnings(&quot;unchecked&quot;)            T result = (T)e.value;            return result;        &#125;    &#125;    return setInitialValue();&#125;</code></pre><p>set方法：</p><pre><code class="java">public void set(T value) &#123;    Thread t = Thread.currentThread();    ThreadLocalMap map = getMap(t); //获取当前线程的ThreadLocalMap    if (map != null)        map.set(this, value); //向map中存值，key就是当前ThreadLocal对象    else        createMap(t, value); &#125;</code></pre><hr><h4 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h4><p>很常见的应用在Session中存储数据。一个Session对应一个线程，对应一组线程内方法间的共享变量，这些变量都可以由ThreadLocal存储。</p><p>参考下<a href="https://www.cnblogs.com/youzhibing/p/6690341.html">结合ThreadLocal来看spring事务源码，感受下清泉般的洗涤！</a>，可以看到在Spring事务中，也有类似ThreadLocal的操作，将数据库connection绑定到当前线程，使用的也是一个map。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;ThreadLocal的作用并不是解决多线程共享变量的问题，而是存储那些线程间隔离，但在不同方法间共享的变量。这是线程安全的一种无同步方案，另一种是无同步方案是幂等的可重入代码。&lt;/p&gt;
&lt;p&gt;下面先模拟一个基本的ThreadLocal存储User id的模型，然后解析原理。&lt;/p&gt;</summary>
    
    
    
    <category term="开发" scheme="https://juniousy.github.io/categories/%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="Java" scheme="https://juniousy.github.io/tags/Java/"/>
    
    <category term="并发" scheme="https://juniousy.github.io/tags/%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>【本科时期文章】Java Collection笔记</title>
    <link href="https://juniousy.github.io/2019/03/20/Java-Collection%E7%AC%94%E8%AE%B0/"/>
    <id>https://juniousy.github.io/2019/03/20/Java-Collection%E7%AC%94%E8%AE%B0/</id>
    <published>2019-03-20T12:19:10.000Z</published>
    <updated>2022-05-30T09:06:50.980Z</updated>
    
    <content type="html"><![CDATA[<p>这是自己整理的一些Collection的要点笔记，比较零碎，可能可读性不是很强。有新内容时会进行补充。<br>Java Collection框架：</p><ul><li>Set  , HashSet TreeSet(实现SortedSet)<ul><li>SortedSet</li></ul></li><li>List , LinkedList ArrayList</li><li>Queue,  PriorityQueue</li><li>Dequeue</li><li>Map , HashMap TreeMap(实现SortedMap)<ul><li>SortedMap</li></ul></li></ul><a id="more"></a><p>基本方法 add(), remove(), contains(), isEmpty(), addAll()</p><hr><h5 id="hashmap"><a href="#hashmap" class="headerlink" title="hashmap"></a>hashmap</h5><p>线程不安全，允许存null。<br>实现：</p><ol><li><p>内部有一个静态类<code>Node&lt;K,V&gt;</code> ， 实现<code> Map.Entry&lt;K,V&gt;</code>，是“ Basic hash bin node”（文档原文）。而<code>TreeNode</code>也是节点的实现，适用于有冲突的情况，冲突后形成的是红黑树。</p></li><li><p>计算hash值方法：高16位和低16位hashcode异或，降低hash值范围小时的冲突：</p><pre><code class="java">static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125;</code></pre></li><li><p>用数组存Node，数组长度必须是2的幂</p><pre><code class="java">transient Node&lt;K,V&gt;[] table;</code></pre></li><li><p>缓存entrySet</p><pre><code class="java">transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet;</code></pre></li><li><p>取：按hash值作为数组下标去取Node。下标是<code>(tab.length - 1) &amp; hash</code>。 由于桶的长度是2的n次方，这么做其实是等于 一个模运算。比如hash是31(11111)，length是4(100)，-1后是11，与运算后是3(11)，就是取模。<br>如果有冲突了，则有多个Node放在一个桶里，要么顺序查找（链表），要么按TreeNode去取（红黑树）。</p><pre><code class="java">public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;</code></pre></li></ol><p>final Node&lt;K,V&gt; getNode(int hash, Object key) {<br>    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k;<br>    if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp;<br>        (first = tab[(n - 1) &amp; hash]) != null) {<br>        if (first.hash == hash &amp;&amp; // always check first node<br>            ((k = first.key) == key || (key != null &amp;&amp; key.equals(k))))<br>            return first;<br>        if ((e = first.next) != null) {<br>            if (first instanceof TreeNode)<br>                return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key);<br>            do {<br>                if (e.hash == hash &amp;&amp;<br>                    ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))<br>                    return e;<br>            } while ((e = e.next) != null);<br>        }<br>    }<br>    return null;<br>}</p><pre><code>6. 存，往数组的`(tab.length - 1) &amp; hash`处放。桶里没有的话则直接放，有的话，找有没有相同的值，有的话替换。加了后如果容量达到threshold就resize();```javapublic V put(K key, V value) &#123;    return putVal(hash(key), key, value, false, true);&#125;final V putVal(int hash, K key, V value, boolean onlyIfAbsent,               boolean evict) &#123;    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i;    if ((tab = table) == null || (n = tab.length) == 0)        n = (tab = resize()).length;    if ((p = tab[i = (n - 1) &amp; hash]) == null)        tab[i] = newNode(hash, key, value, null);    else &#123;        Node&lt;K,V&gt; e; K k;        if (p.hash == hash &amp;&amp;            ((k = p.key) == key || (key != null &amp;&amp; key.equals(k))))            e = p;        else if (p instanceof TreeNode)            e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value);        else &#123;            for (int binCount = 0; ; ++binCount) &#123;                if ((e = p.next) == null) &#123;                    p.next = newNode(hash, key, value, null);                    if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st                        treeifyBin(tab, hash);                    break;                &#125;                if (e.hash == hash &amp;&amp;                    ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))                    break;                p = e;            &#125;        &#125;        if (e != null) &#123; // existing mapping for key            V oldValue = e.value;            if (!onlyIfAbsent || oldValue == null)                e.value = value;            afterNodeAccess(e);            return oldValue;        &#125;    &#125;    ++modCount;    if (++size &gt; threshold)        resize();    afterNodeInsertion(evict);    return null;&#125;</code></pre><ol start="7"><li><strong><code>resize()</code> 方法</strong>，初始化数组或扩容。扩容时数组容量扩大到2倍然后ReHash，遍历原Entry数组，把所有的Entry重新Hash到新数组。通过<code>e.hash &amp; (newCap - 1)</code>算出新的数组下标，原因是因为数组全是2的幂，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置。然后链表和treenode重新放</li></ol><p>HashMap 在第一次 put 时初始化，类似 ArrayList 在第一次 add 时分配空间。<br>在哈希碰撞的链表长度达到TREEIFY_THRESHOLD（默认8)后，会把该链表转变成树结构</p><hr><h5 id="concurrenthashmap"><a href="#concurrenthashmap" class="headerlink" title="concurrenthashmap"></a>concurrenthashmap</h5><p>HashMap允许一个key和value为null，而ConcurrentHashMap不允许key和value为null，如果发现key或者value为null，则会抛出NPE。</p><p>和hashmap一样有Node&lt;K,V&gt;</p><p>sizeCtl：<code>private transient volatile int sizeCtl;</code>这是一个用于同步多个线程的共享变量，如果值为负数，则说明table正在被某个线程初始化或者扩容。如果某个线程想要初始化table或者对table扩容，需要去竞争sizeCtl这个共享变量，获得变量的线程才有许可去进行接下来的操作，没能获得的线程将会一直自旋来尝试获得这个共享变量。获得sizeCtl这个变量的线程在完成工作之后再设置回来，使其他的线程可以走出自旋进行接下来的操作</p><p>查询和hashmap差不多，(hashCode &amp; (length - 1))取下标。table数组是被volatile关键字修饰，解决了可见性问题</p><p>存要复杂一点。首先计算table下标，下标没数据就通过调用casTabAt方法插入数据。有的话，那么就给该下标处的Node（不管是链表的头还是树的根）加锁插入。     </p><p>扩容操作比较复杂。扩容操作的条件是如果table过小，并且没有被扩容，那么就需要进行扩容，需要使用transfer方法来将久的记录迁移到新的table中去。整个扩容操作分为两个部分，要用到内部类forwardNode。第一部分是构建一个nextTable,它的容量是原来的两倍，这个操作是单线程完成的。<br>第二个部分就是将原来table中的元素复制到nextTable中，这里允许多线程进行操作。</p><p>size()方法，结合baseCount和counterCells数组来得到，通过累计两者的数量即可获得当前ConcurrentHashMap中的记录总量。</p><hr><h5 id="HashSet"><a href="#HashSet" class="headerlink" title="HashSet"></a>HashSet</h5><p>用HashMap实现。(内部：<code>private transient HashMap&lt;E,Object&gt; map;</code>)</p><hr><h5 id="ArrayList"><a href="#ArrayList" class="headerlink" title="ArrayList"></a>ArrayList</h5><p>fail fast机制：checkForComodification()方法检查modCount，检查有无结构性的改变，变了抛<code>ConcurrentModificationException</code>。</p><p>扩容调<code>Arrays.copyOf(elementData, newCapacity);</code></p><p>内部有迭代器类 Iterator。</p><hr><h5 id="LinkedList"><a href="#LinkedList" class="headerlink" title="LinkedList"></a>LinkedList</h5><p>实现List和Deque（即可以当栈、队列、双向队列使用）</p><p>内部是一个双向链表</p><p>字段存有 size、 first Node（头节点）、last Node。通过头结点、尾节点可以很快地进行双向入队出队操作。<br>随机存储效率不如ArrayList，要遍历节点。按下标读取时，会按照size，判断是链表前半段还是后半段，根据这个从头或尾节点开始遍历。</p><p>和ArrayDeque的区别之一：LinkedList可以存null，而ArrayDeque不能存null。这点在写算法题的时候可以注意一下。</p><hr><h5 id="ArrayDeque"><a href="#ArrayDeque" class="headerlink" title="ArrayDeque"></a>ArrayDeque</h5><p>转一张表整理方法。一套接口遇到失败就会抛出异常，另一套遇到失败会返回特殊值。<br>| Queue Method | Equivalent Deque Method | 说明                                   |<br>| ———— | ———————– | ————————————– |<br>| <code>add(e)</code>     | <code>addLast(e)</code>            | 向队尾插入元素，失败则抛出异常         |<br>| <code>offer(e)</code>   | <code>offerLast(e)</code>          | 向队尾插入元素，失败则返回<code>false</code>      |<br>| <code>remove()</code>   | <code>removeFirst()</code>         | 获取并删除队首元素，失败则抛出异常     |<br>| <code>poll()</code>     | <code>pollFirst()</code>           | 获取并删除队首元素，失败则返回<code>null</code>   |<br>| <code>element()</code>  | <code>getFirst()</code>            | 获取但不删除队首元素，失败则抛出异常   |<br>| <code>peek()</code>     | <code>peekFirst()</code>           | 获取但不删除队首元素，失败则返回<code>null</code> |</p><p>内部elements数组的容量一定是2的倍数，并且不会满。存数组的head和tail下标，形成一个循环数组，当这两个下标相等时，数组为空。而在添加元素时，如果这两个下标相等，说明数组已满，将容量翻倍。扩容时重置头索引和尾索引，头索引置为0，尾索引置为原容量的值。</p><hr><h5 id="CopyOnWriteArrayList"><a href="#CopyOnWriteArrayList" class="headerlink" title="CopyOnWriteArrayList"></a>CopyOnWriteArrayList</h5><p>线程安全<br>add set之类的操作都是新建一个复制arraylist<br>适用于 读多些少, 并且数据内容变化比较少的场景</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;这是自己整理的一些Collection的要点笔记，比较零碎，可能可读性不是很强。有新内容时会进行补充。&lt;br&gt;Java Collection框架：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Set  , HashSet TreeSet(实现SortedSet)&lt;ul&gt;
&lt;li&gt;SortedSet&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;List , LinkedList ArrayList&lt;/li&gt;
&lt;li&gt;Queue,  PriorityQueue&lt;/li&gt;
&lt;li&gt;Dequeue&lt;/li&gt;
&lt;li&gt;Map , HashMap TreeMap(实现SortedMap)&lt;ul&gt;
&lt;li&gt;SortedMap&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="开发" scheme="https://juniousy.github.io/categories/%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="Java" scheme="https://juniousy.github.io/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>【本科时期文章】实现LRUCache</title>
    <link href="https://juniousy.github.io/2019/03/11/%E5%AE%9E%E7%8E%B0LRUCache/"/>
    <id>https://juniousy.github.io/2019/03/11/%E5%AE%9E%E7%8E%B0LRUCache/</id>
    <published>2019-03-11T14:57:49.000Z</published>
    <updated>2022-05-30T09:06:50.984Z</updated>
    
    <content type="html"><![CDATA[<p>LRU Cache 算法是操作系统在进行内存管理时可以采用的一种页面置换算法。LRU，就是Least Recently Used的简称，这个算法叫做最近最少使用算法。除了在页面置换中可以使用这一算法，其他需要缓存的场景也可以运用这一算法。这一算法的核心目的就是依照程序的就近原则，尽可能在有限的空间内缓存最多以后会使用到的内容。另外，实现这一算法也是一道<a href="https://leetcode.com/problems/lru-cache/">LeetCode题目</a>。本文就是演示如何使用java语言实现这一算法。</p><a id="more"></a><hr><h3 id="LinkedHashMap实现"><a href="#LinkedHashMap实现" class="headerlink" title="LinkedHashMap实现"></a>LinkedHashMap实现</h3><p>LinkedHashMap是最容易的实现方式，因为它内部的实现方式很贴合这一应用，至于为什么下面会有介绍。<br>LinkedHashMap和普通的HashMap不同的地方在于，它保存了迭代顺序，该迭代顺序可以是插入顺序或者是访问顺序。而LRU要求最近读取过得内容有最高的缓存优先度，也就是按照访问顺序来进行迭代。而通过重写removeEldestEntry方法可以让LinkedHashMap保留有限多的数据，删除缓存中不需要的数据。</p><pre><code class="java">//简易实现class LRUCache&lt;K, V&gt; &#123;  private static final float loadFactor = 0.75f;  private int capacity;  private final LinkedHashMap&lt;K, V&gt; map;  public LRUCache(int capacity) &#123;    if (capacity &lt; 0) &#123;      capacity = 0;    &#125;    this.capacity = capacity;    //构造函数参数分别是initialCapacity、loadFactor、accessOrder，accessOrder为true即按访问顺序迭代    map = new LinkedHashMap&lt;K, V&gt;(0, loadFactor, true)&#123;      @Override      protected boolean removeEldestEntry(Entry eldest) &#123;        return size() &gt; LRUCache.this.capacity;      &#125;    &#125;;  &#125;  public final V get(K key) &#123;    return map.get(key);  &#125;  public final void put(K key, V value) &#123;    map.put(key, value);  &#125;&#125;</code></pre><hr><h3 id="HashMap-双向链表实现"><a href="#HashMap-双向链表实现" class="headerlink" title="HashMap + 双向链表实现"></a>HashMap + 双向链表实现</h3><p>之所以LinkedHashMap能保有这样的性质，是因为它内部的实现是依托了HashMap和双向链表，因此不用LinkedHashMap我们也能实现LRUCache算法。</p><p>基本框架</p><pre><code class="java">public class LRUCache&lt;K, V&gt; &#123;  private int capacity;  private HashMap&lt;K, Node&lt;K, V&gt;&gt; map;  private Node&lt;K, V&gt; head;  private Node&lt;K, V&gt; tail;  public LRUCache(int capacity) &#123;    this.capacity = capacity;    map = new HashMap&lt;&gt;(capacity);    head = new Node&lt;&gt;();    tail = new Node&lt;&gt;();    head.next = tail;    tail.pre = head;  &#125;   class Node&lt;K, V&gt; &#123;    K key;    V value;    Node&lt;K, V&gt; pre;    Node&lt;K, V&gt; next;  &#125;&#125;</code></pre><p>公用方法</p><pre><code class="java">private void raiseNode(Node&lt;K, V&gt; node) &#123;    if (node.pre == head) &#123;        return;    &#125;    Node&lt;K, V&gt; pre = node.pre;    Node&lt;K, V&gt; next = node.next;    pre.next = next;    next.pre = pre;    setFirst(node);&#125;private void setFirst(Node&lt;K, V&gt; node) &#123;    Node&lt;K, V&gt; first = head.next;    head.next = node;    node.pre = head;    first.pre = node;    node.next = first;&#125;</code></pre><p>get方法，从map里拿Value，同时将它置为链表头</p><pre><code class="java">public V get(K key) &#123;    if (!map.containsKey(key)) &#123;        return null;    &#125;    Node&lt;K, V&gt; node = map.get(key);    raiseNode(node);    return node.value;&#125;</code></pre><p>save方法，如果缓存已满，删除链表尾的值，再添加新的值到链表头</p><pre><code class="java">public void save(K key, V value) &#123;    if (map.containsKey(key)) &#123;        updateNode(key, value);    &#125; else &#123;        insertNode(key, value);    &#125;&#125;private void updateNode(K key, V value) &#123;    Node node = map.get(key);    node.value = value;    raiseNode(node);&#125;private void insertNode(K key, V value) &#123;    if (isFull()) &#123;        removeLast();    &#125;    Node node = new Node();    node.key = key;    node.value = value;    setFirst(node);    map.put(key, node);&#125;private boolean isFull() &#123;    return map.size() &gt;= capacity;&#125;</code></pre><p>测试</p><pre><code class="java">import org.junit.Test;public class LRUCacheTest &#123;  LRUCache&lt;Integer, Integer&gt; cache = new LRUCache(3);  @Test  public void test() &#123;    cache.save(1, 7);    cache.save(2, 0);    cache.save(3, 1);    cache.save(4, 2);    assert 0 == cache.get(2);    assert null == cache.get(7);    cache.save(5, 3);    assert 0 == cache.get(2);    cache.save(6, 4);    assert null == cache.get(4);  &#125;&#125;//head -&gt; 7 -&gt; tail//head -&gt; 0 -&gt; 7 -&gt; tail//head -&gt; 1 -&gt; 0 -&gt; 7 -&gt; tail//head -&gt; 2 -&gt; 1 -&gt; 0 -&gt; tail//head -&gt; 3 -&gt; 2 -&gt; 1 -&gt; tail//head -&gt; 2 -&gt; 3 -&gt; 1 -&gt; tail//head -&gt; 4 -&gt; 2 -&gt; 3 -&gt; tail</code></pre>]]></content>
    
    
    <summary type="html">&lt;p&gt;LRU Cache 算法是操作系统在进行内存管理时可以采用的一种页面置换算法。LRU，就是Least Recently Used的简称，这个算法叫做最近最少使用算法。除了在页面置换中可以使用这一算法，其他需要缓存的场景也可以运用这一算法。这一算法的核心目的就是依照程序的就近原则，尽可能在有限的空间内缓存最多以后会使用到的内容。另外，实现这一算法也是一道&lt;a href=&quot;https://leetcode.com/problems/lru-cache/&quot;&gt;LeetCode题目&lt;/a&gt;。本文就是演示如何使用java语言实现这一算法。&lt;/p&gt;</summary>
    
    
    
    <category term="开发" scheme="https://juniousy.github.io/categories/%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="算法" scheme="https://juniousy.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>【本科时期文章】生产者消费者模型的一个例子</title>
    <link href="https://juniousy.github.io/2019/03/02/%E7%94%9F%E4%BA%A7%E8%80%85%E6%B6%88%E8%B4%B9%E8%80%85%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%80%E4%B8%AA%E5%8F%98%E5%9E%8B/"/>
    <id>https://juniousy.github.io/2019/03/02/%E7%94%9F%E4%BA%A7%E8%80%85%E6%B6%88%E8%B4%B9%E8%80%85%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%80%E4%B8%AA%E5%8F%98%E5%9E%8B/</id>
    <published>2019-03-02T14:08:53.000Z</published>
    <updated>2022-05-30T09:06:50.985Z</updated>
    
    <content type="html"><![CDATA[<p>一般的生产者消费者模型中，生产者和消费者都是尽可能快地处理任务。但在工作中，我遇到了一种情况，需要每个消费者尽可能多地解决一批任务，这样可以打包处理，降低I/O频次。<br>我当时用的方法是在消费者端给BlockingQueue加锁。后来想想这种方法多余了。<br>这篇文章一是讨论一下这种方法，作个反思，二来作为新博客的第一篇文章，起个开头。</p><a id="more"></a><hr><h4 id="模拟当时的解决方法"><a href="#模拟当时的解决方法" class="headerlink" title="模拟当时的解决方法"></a>模拟当时的解决方法</h4><p>用来解决生产者消费者问题的BlockingQueue：</p><pre><code class="java">private static final BlockingQueue&lt;Task&gt; taskBlockingQueue = new ArrayBlockingQueue&lt;&gt;(100);</code></pre><p>生产者部分没有什么区别，直接往队列里添加任务：</p><pre><code class="java">private void produce(int taskId) &#123;  try &#123;    taskBlockingQueue.put(new Task(taskId));    System.out.println(String.format(&quot;生产者%d\t添加任务%d&quot;, id, taskId));  &#125; catch (InterruptedException e) &#123;    e.printStackTrace();  &#125;&#125;</code></pre><p>消费者部分在打包的过程中都对阻塞队列加锁，不允许其他消费者获取任务：</p><pre><code class="java">private static final Lock packageLock = new ReentrantLock();</code></pre><p>消费者需要在指定时间内打包，超时则退出这轮消费。</p><pre><code class="java">private void consume() &#123;  try &#123;    if (packageLock.tryLock(5, TimeUnit.MILLISECONDS)) &#123;      try &#123;        doPackage();      &#125; finally &#123;        packageLock.unlock();      &#125;    &#125;  &#125; catch (InterruptedException e) &#123;    e.printStackTrace();  &#125;&#125;private void doPackage() &#123;  long start = System.currentTimeMillis();  long end;  int packageNum = 0;  for (int i = 0; i &lt; consumerPackageSize; i++) &#123;    doConsume();    packageNum++;    end = System.currentTimeMillis();    if (end - start &gt; packageTime) &#123;      break;    &#125;  &#125;  end = System.currentTimeMillis();  System.out.println(String.format(&quot;消费者%d\t打包%d个\t耗时%d&quot;, id, packageNum, end - start));&#125;private void doConsume() &#123;  Task task = null;  try &#123;    task = taskBlockingQueue.poll(100, TimeUnit.MILLISECONDS);  &#125; catch (InterruptedException e) &#123;    e.printStackTrace();  &#125;  if (task == null) &#123;    return;  &#125;  System.out.println(String.format(&quot;消费者%d\t完成任务%d&quot;, id, task.getId()));&#125;</code></pre><p>整个完整的测试类：</p><pre><code class="java">import lombok.AllArgsConstructor;import lombok.Data;import java.util.Random;import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.BlockingQueue;import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;/** * @author Junious * @date 2019/02/25 **/public class ProducerAndConsumerTest &#123;  private static final int producerNumber = 5;  private static final int consumerNumber = 5;  private static final BlockingQueue&lt;Task&gt; taskBlockingQueue = new ArrayBlockingQueue&lt;&gt;(100);  private static final Lock packageLock = new ReentrantLock();  private static final int consumerPackageSize = 20;  private static final int packageTime = 2000;  public static void main(String[] args) &#123;    Runtime.getRuntime().addShutdownHook(        new Thread(() -&gt; System.out.println            (&quot;queue size:&quot; + taskBlockingQueue.size()))    );    ProducerAndConsumerTest test = new ProducerAndConsumerTest();    test.init();  &#125;  private void init() &#123;    //add producers    for (int i = 0; i &lt; producerNumber; i++) &#123;      Thread t = new Thread(new Producer(i));      t.start();    &#125;    //add consumers    for (int i = 0; i &lt; consumerNumber; i++) &#123;      Thread t = new Thread(new Consumer(i));      t.start();    &#125;  &#125;  @AllArgsConstructor  @Data  class Producer implements Runnable &#123;    private int id;    @Override    public void run() &#123;      Random random = new Random();      while (true) &#123;        int taskId = random.nextInt(1000) + 1;        produce(taskId);        try &#123;          Thread.sleep(random.nextInt(300) + 400);        &#125; catch (InterruptedException e) &#123;          e.printStackTrace();          break;        &#125;      &#125;    &#125;    private void produce(int taskId) &#123;      try &#123;        taskBlockingQueue.put(new Task(taskId));        System.out.println(String.format(&quot;生产者%d\t添加任务%d&quot;, id, taskId));      &#125; catch (InterruptedException e) &#123;        e.printStackTrace();      &#125;    &#125;  &#125;  @AllArgsConstructor  @Data  class Consumer implements Runnable &#123;    private int id;    @Override    public void run() &#123;      Random random = new Random();      while (true) &#123;        consume();        try &#123;          Thread.sleep(random.nextInt(300) + 400);        &#125; catch (InterruptedException e) &#123;          e.printStackTrace();          break;        &#125;      &#125;    &#125;    private void consume() &#123;      try &#123;        if (packageLock.tryLock(5, TimeUnit.MILLISECONDS)) &#123;          try &#123;            doPackage();          &#125; finally &#123;            packageLock.unlock();          &#125;        &#125;      &#125; catch (InterruptedException e) &#123;        e.printStackTrace();      &#125;    &#125;    private void doPackage() &#123;      long start = System.currentTimeMillis();      long end;      int packageNum = 0;      for (int i = 0; i &lt; consumerPackageSize; i++) &#123;        doConsume();        packageNum++;        end = System.currentTimeMillis();        if (end - start &gt; packageTime) &#123;          break;        &#125;      &#125;      end = System.currentTimeMillis();      System.out.println(String.format(&quot;消费者%d\t打包%d个\t耗时%d&quot;, id, packageNum, end - start));    &#125;    private void doConsume() &#123;      Task task = null;      try &#123;        task = taskBlockingQueue.poll(100, TimeUnit.MILLISECONDS);      &#125; catch (InterruptedException e) &#123;        e.printStackTrace();      &#125;      if (task == null) &#123;        return;      &#125;      System.out.println(String.format(&quot;消费者%d\t完成任务%d&quot;, id, task.getId()));    &#125;  &#125;&#125;@AllArgsConstructor@Dataclass Task &#123;  private int id;&#125;</code></pre><p>截取一段测试结果：</p><pre><code>生产者0    添加任务545生产者2    添加任务943生产者1    添加任务359生产者3    添加任务97生产者4    添加任务705消费者2    完成任务545消费者2    完成任务359消费者2    完成任务943消费者2    完成任务97消费者2    完成任务705生产者2    添加任务32消费者2    完成任务32生产者4    添加任务488消费者2    完成任务488生产者1    添加任务691消费者2    完成任务691消费者2    完成任务3生产者3    添加任务3生产者0    添加任务815消费者2    完成任务815消费者2    完成任务290生产者1    添加任务290消费者2    完成任务408生产者2    添加任务408消费者2    完成任务873生产者3    添加任务873消费者2    打包20个    耗时1165生产者0    添加任务852消费者1    完成任务852消费者1    完成任务743生产者4    添加任务743生产者0    添加任务114消费者1    完成任务114生产者1    添加任务454消费者1    完成任务454消费者1    完成任务920生产者2    添加任务920生产者3    添加任务847消费者1    完成任务847生产者4    添加任务905消费者1    完成任务905生产者3    添加任务698消费者1    完成任务698生产者1    添加任务372消费者1    完成任务372生产者0    添加任务568消费者1    完成任务568生产者2    添加任务419消费者1    完成任务419生产者4    添加任务417消费者1    完成任务417消费者1    打包20个    耗时1295生产者3    添加任务888消费者0    完成任务888生产者1    添加任务189消费者0    完成任务189生产者2    添加任务892消费者0    完成任务892生产者4    添加任务375消费者0    完成任务375生产者0    添加任务723消费者0    完成任务723生产者3    添加任务543消费者0    完成任务543消费者0    完成任务205生产者1    添加任务205生产者2    添加任务657消费者0    完成任务657生产者0    添加任务549消费者0    完成任务549生产者4    添加任务812消费者0    完成任务812生产者3    添加任务737消费者0    完成任务737消费者0    打包20个    耗时1208生产者2    添加任务784消费者4    完成任务784生产者1    添加任务252消费者4    完成任务252生产者0    添加任务622消费者4    完成任务622生产者4    添加任务524消费者4    完成任务524生产者3    添加任务73消费者4    完成任务73生产者2    添加任务491消费者4    完成任务491生产者0    添加任务225消费者4    完成任务225生产者1    添加任务207消费者4    完成任务207生产者4    添加任务326消费者4    完成任务326生产者2    添加任务983消费者4    完成任务983生产者0    添加任务865消费者4    完成任务865生产者3    添加任务347消费者4    完成任务347消费者4    打包20个    耗时1318</code></pre><p>可以看到每次打包只有一个消费者在进行消费，其实相当于只有一个消费者线程，等于没有使用并发。<br>当消费者任务很耗时时：</p><pre><code class="java">private void doConsume() &#123;  Task task = null;  try &#123;    task = taskBlockingQueue.poll(100, TimeUnit.MILLISECONDS);    //模拟耗时    Thread.sleep(200);  &#125; catch (InterruptedException e) &#123;    e.printStackTrace();  &#125;  if (task == null) &#123;    return;  &#125;  System.out.println(String.format(&quot;消费者%d\t完成任务%d&quot;, id, task.getId()));&#125;</code></pre><p>这时候在中止时可以看到队列有10到30不等的Task暂留。模拟耗时越长，暂留的越多，也就是相当于性能越差。</p><hr><h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><p>实际上不需要加锁，设定一个超时时间即可。</p><pre><code class="java">@AllArgsConstructor@Dataclass Consumer2 implements Runnable &#123;  private int id;  @Override  public void run() &#123;    Random random = new Random();    while (true) &#123;      try &#123;        consume();        Thread.sleep(random.nextInt(300) + 400);      &#125; catch (InterruptedException e) &#123;        e.printStackTrace();        break;      &#125;    &#125;  &#125;  private void consume() throws InterruptedException &#123;    long start = System.currentTimeMillis();    ArrayList&lt;Task&gt; tasks = new ArrayList&lt;&gt;();    long end;    int packageNum = 0;    for (int i = 0; i &lt; consumerPackageSize; i++) &#123;      //模拟打包任务      Task task = taskBlockingQueue.poll(packageTime, TimeUnit.MILLISECONDS);      if (task == null) &#123;        continue;      &#125;      Thread.sleep(200);      tasks.add(task);      packageNum++;      end = System.currentTimeMillis();      if (end - start &gt; packageTime) &#123;        break;      &#125;    &#125;    end = System.currentTimeMillis();    System.out.println(String.format(&quot;消费者%d\t打包%d个\t耗时%d\t%s&quot;, id, packageNum, end - start, tasks));  &#125;&#125;</code></pre><pre><code>生产者2    添加任务539生产者0    添加任务319生产者1    添加任务655生产者4    添加任务843生产者3    添加任务788生产者0    添加任务716生产者3    添加任务176生产者4    添加任务735生产者2    添加任务7生产者1    添加任务283生产者4    添加任务466生产者3    添加任务486生产者0    添加任务649生产者2    添加任务373生产者1    添加任务158生产者0    添加任务532生产者4    添加任务914生产者1    添加任务734生产者3    添加任务571生产者2    添加任务114生产者1    添加任务340生产者3    添加任务670生产者0    添加任务482生产者2    添加任务298生产者4    添加任务598消费者0    打包5个    耗时2213    [Task(id=655), Task(id=716), Task(id=466), Task(id=532), Task(id=340)]消费者4    打包5个    耗时2280    [Task(id=319), Task(id=176), Task(id=486), Task(id=914), Task(id=670)]消费者1    打包5个    耗时2328    [Task(id=788), Task(id=735), Task(id=649), Task(id=734), Task(id=482)]消费者3    打包5个    耗时2351    [Task(id=843), Task(id=7), Task(id=373), Task(id=571), Task(id=298)]消费者2    打包5个    耗时2400    [Task(id=539), Task(id=283), Task(id=158), Task(id=114), Task(id=598)]生产者3    添加任务928生产者0    添加任务360生产者1    添加任务724生产者2    添加任务539生产者4    添加任务926生产者3    添加任务206生产者0    添加任务596生产者1    添加任务841生产者4    添加任务834生产者2    添加任务340生产者3    添加任务585生产者1    添加任务500生产者4    添加任务532生产者0    添加任务800生产者2    添加任务914生产者3    添加任务202生产者1    添加任务850生产者0    添加任务506生产者1    添加任务785生产者2    添加任务633生产者4    添加任务182生产者3    添加任务154生产者0    添加任务13生产者2    添加任务880消费者3    打包5个    耗时2199    [Task(id=724), Task(id=841), Task(id=532), Task(id=506), Task(id=13)]生产者4    添加任务214消费者0    打包5个    耗时2217    [Task(id=539), Task(id=834), Task(id=800), Task(id=785), Task(id=880)]生产者1    添加任务789生产者3    添加任务786消费者4    打包6个    耗时2583    [Task(id=928), Task(id=926), Task(id=340), Task(id=914), Task(id=633), Task(id=214)]生产者0    添加任务468生产者2    添加任务189消费者1    打包6个    耗时2597    [Task(id=360), Task(id=206), Task(id=585), Task(id=202), Task(id=182), Task(id=789)]消费者2    打包5个    耗时2465    [Task(id=596), Task(id=500), Task(id=850), Task(id=154), Task(id=786)]生产者4    添加任务812生产者0    添加任务239生产者3    添加任务671生产者1    添加任务730生产者2    添加任务124生产者4    添加任务679生产者0    添加任务320生产者2    添加任务917生产者1    添加任务986生产者3    添加任务557生产者0    添加任务415生产者4    添加任务559生产者2    添加任务880生产者1    添加任务920生产者3    添加任务502生产者0    添加任务679生产者4    添加任务823生产者2    添加任务594生产者1    添加任务336生产者3    添加任务502生产者0    添加任务453生产者4    添加任务360消费者0    打包6个    耗时2249    [Task(id=468), Task(id=239), Task(id=679), Task(id=415), Task(id=679), Task(id=453)]消费者3    打包6个    耗时2320    [Task(id=189), Task(id=671), Task(id=320), Task(id=559), Task(id=823), Task(id=360)]生产者2    添加任务823生产者3    添加任务857生产者1    添加任务395生产者0    添加任务937生产者4    添加任务817消费者2    打包4个    耗时2264    [Task(id=917), Task(id=880), Task(id=594), Task(id=823)]消费者4    打包6个    耗时2622    [Task(id=812), Task(id=730), Task(id=986), Task(id=920), Task(id=336), Task(id=857)]消费者1    打包5个    耗时2408    [Task(id=124), Task(id=557), Task(id=502), Task(id=502), Task(id=395)]</code></pre><p>这时候中止可以看到队列几乎没有Task暂留</p><p>当设置消费者消费时间为1000ms时，运行一段时间队列就满了，这时候是当增加消费者线程数即可让任务处理跟上生产者的生产速度。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;一般的生产者消费者模型中，生产者和消费者都是尽可能快地处理任务。但在工作中，我遇到了一种情况，需要每个消费者尽可能多地解决一批任务，这样可以打包处理，降低I/O频次。&lt;br&gt;我当时用的方法是在消费者端给BlockingQueue加锁。后来想想这种方法多余了。&lt;br&gt;这篇文章一是讨论一下这种方法，作个反思，二来作为新博客的第一篇文章，起个开头。&lt;/p&gt;</summary>
    
    
    
    <category term="开发" scheme="https://juniousy.github.io/categories/%E5%BC%80%E5%8F%91/"/>
    
    
    <category term="Java" scheme="https://juniousy.github.io/tags/Java/"/>
    
    <category term="并发" scheme="https://juniousy.github.io/tags/%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
</feed>
