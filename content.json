{"meta":{"title":"JuniousY的博客","subtitle":"倾听Ghost的低语","description":"后端开发,请多多指教","author":"JuniousY","url":"https://juniousy.github.io","root":"/"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2022-05-30T09:06:50.975Z","updated":"2022-05-30T09:06:50.975Z","comments":false,"path":"/404.html","permalink":"https://juniousy.github.io/404.html","excerpt":"","text":""},{"title":"分类","date":"2022-05-30T09:06:50.989Z","updated":"2022-05-30T09:06:50.989Z","comments":false,"path":"categories/index.html","permalink":"https://juniousy.github.io/categories/index.html","excerpt":"","text":""},{"title":"关于","date":"2022-05-30T09:06:50.987Z","updated":"2022-05-30T09:06:50.987Z","comments":false,"path":"about/index.html","permalink":"https://juniousy.github.io/about/index.html","excerpt":"","text":"个人详细介绍"},{"title":"标签","date":"2022-05-30T09:06:50.993Z","updated":"2022-05-30T09:06:50.993Z","comments":false,"path":"tags/index.html","permalink":"https://juniousy.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"6.824 Lab2 - Raft - Lab前准备","slug":"2022/6.824Lab2-Lab前准备","date":"2022-06-12T06:58:41.090Z","updated":"2022-06-12T07:58:50.996Z","comments":true,"path":"2022/06/12/2022/6.824Lab2-Lab前准备/","link":"","permalink":"https://juniousy.github.io/2022/06/12/2022/6.824Lab2-Lab%E5%89%8D%E5%87%86%E5%A4%87/","excerpt":"","text":"做lab前先整理一下要点和课前提醒，做一个笔记记录，在实现时对照着看。 Raft概述Raft是一个用来实现分布式一致的协议。Raft is a protocol for implementing distributed consensus. Raft is a consensus algorithm that is designed to be easy to understand. It’s equivalent to Paxos in fault-tolerance and performance. The difference is that it’s decomposed into relatively independent subproblems, and it cleanly addresses all major pieces needed for practical systems. We hope Raft will make consensus available to a wider audience, and that this wider audience will be able to develop a variety of higher quality consensus-based systems than are available today. 主要分为Lead Election和Log Replication阶段 Log Replication 阶段流程概述： 为了commit the log entry，leader node首先向follower nodes复制自己 leader等待大部分node写入entry entry 提交，leader status改变 leader 通知followers entry已经提交了 cluster 的系统状态成为一致(consensus) Lead Election 阶段流程概述： election timeout：时间结束后，follower变为candidate，发起election，发送request vote candidate 被大部分note vote后，变为leader leader向followers发送Append Entries，按 heartbeat timeout 间歇发送 follower也向leaderAppend Entries，作为心跳检测 同时有两个candidate，就重新进入election timeout等待，重新发起election Raft精要内容是论文中的Figure 2。 1. State关于服务器状态的实现 所有服务器 - 持久化状态在进行RPC回复前进行持久化 currentTerm 最近server看到的term （0开始，单调增） voteFor 当前term下被推举的candidate Id log[] log entries （记录条目）。每个entry包含状态机指令，和收到leader发出的entry时的term（起始值为1） 所有服务器 - 可变状态 commitIndex 最近一次被提交的log entry序号（0开始，单调增） lastApplied 最近一次被应用的log entry序号（0开始，单调增） leaders - 可变状态选举后重新初始化 nextIndex[] 对每个server，最近发送的log entry序号（原index+1） matchIndex[] 对每个server，最近知晓的复制成功的log entry序号 2. AppendEntries RPC功能为复制log entries和心跳检测 参数 term leader的term leaderId prevLogIndex preLogTerm entries 要存的log entries （空为心跳；可能一次传多个） leaderCommit leader的commitIndex 结果 term currentTerm，leader用来更新自己 success 成功时，表示follower包含符合prevLogIndex和preLogTerm的entry Receiver实现 如果 term &lt; currentTerm , 返回false 如果 prevLogIndex处的entry不匹配preLogTerm，返回false 如果现有的entry和新的冲突（index一样但是term不一样），从这个entry开始删除到最新。 插入新的entries 如果 leaderCommit &gt; commitIndex，设置 commitIndex = min(leaderCommit, 最新entry的序号) 3. RequestVote RPCcandidate收集选票时触发 参数 term candidate的term candidateId lastLogIndex candidate最后一个log entry的序号 lastLogTerm candidate最后一个log entry的term 结果 term 当前term voteGranted true表示投一票 Receiver实现 如果term &lt; currentTerm 返回false 如果votedFor是空或者是candidateId，然后candidate的log和receiver的log比不滞后，就投票同意 4. Servers的实现规则所有servers 如果 commitIndex &gt; lastApplied：lastApplied+1，将log[lastApplied]应用到状态机中 如果RPC请求或返回包含 term T &gt; currentTerm：将currentTerm设为T，自己转为follower Followers 向candidates和leaders的RPC回复 如果election timeout到了之后，没有收到leader的AppendEntries RPC或收到candidate的投票请求，就自己转为candidate Candidates 转变成candidate，发起选举 currentTerm + 1 投自己一票 重设election timer 向所有其他服务发送RequestVote RPC 如果得到大部分服务的投票，成为leader 如果收到新leader的AppendEntries RPC，成为follower 如果election timeout到了，开始新选举 Leaders 选举一旦完成，向各服务发送新的初始化空AppendEntries RPC（心跳），空闲时也重复发送 如果收到client的命令：在本地log中新增entry，在状态机上应用entry后返回 如果最近的log序号 &gt;= nextIndex，发送AppendExtries RPC时用nextIndex 如果成功：为follower更新nextIndex和matchIndex 如果失败，那么原因为log不一致，降低nextIndex重试 如果存在 N，N &gt; commitIndex，大部分matchIndex[i] &gt;= N，log[N].term == currentTerm，那么，就设置commitIndex = N 注意要点课程提醒的实现中需要注意的点，一个是Figure 2上的要点要逐一实现，如接受非heart beat AppendEntries 时也要进行相应的检查等；第二个是归纳了四种常见的bug。 Bugs1. live locks - 活锁 需要妥善处理好重设election timer。如果AppendEntries已经过时了，就不要重设计时器。开始发起选举时要重设。给其他节点投票时要重设，而不是每次收到投票请求时重设(这样有更多最近记录的节点更有可能选上)。 如果是candidate正在发起选举，但是自己的election timer到时间了，那么就应该开始新的一次选举 如果已经给出投票，然后有新的RequestVote RPC有更高的term，那应该启用这个term，然后处理RPC 2. Incorrect RPC handlers - 错误的PRC处理 Figure 2要点中说的“返回false”，意思是立即返回 如果一个AppendEntries RPC的prevLogIndex比最近的log index要早，那该当做有这个entry但是term不匹配来处理（如返回false） 对prevLogIndex的检查处理，在leader没有送出entries时也要处理 leader的commit index大过自身commit index时，要更新为min(leaderCommit, 最新entry的序号)。如果直接改为leaderCommit，会遇到应用错误的entries的情况。 严格按照要求处理“up-to-date log”。Raft判断的两个log哪个最up-to-date，是通过比较Index和logs中最后的entries的term。如果term最新，那么有最新term的log最up-to-date。如果term一样，那么哪个log的长度（entries的数量）最长就算最up-to-date。 3. Failure to follow The Rules - 没有正确遵守规则Figure 2. 外补充的要点 任何时候发现commitIndex &gt; lastApplied，应该应用一条log entry到状态机。apply要保证只有一个地方去执行。具体来说，要么有一个专门的applier，要么在apply时加锁。 检查commitIndex &gt; lastApplied要么周期性，要么在commitIndex更新之后。 如果leader发出AppendEntries RPC被拒绝时，如果不是因为log不一致，那么应该立即退出，不更新nextIndex。 leader 不能让其他节点在过时的term中更新commitIndex。因此要判断log[N].term == currentTerm。 matchIndex和nextIndex的关系不单纯是matchIndex = nextIndex - 1。nextIndex只是一种乐观的猜测。matchIndex是安全保障，用来做判断。 4. Term Confusion - term混乱在收到旧term的RPC返回时，只在当前term和请求时的term一致时，处理该PRC返回。 更新matchIndex正确的操作是设置为prevLogIndex + len(entries[])，这里面的参数是发起请求时的值。 额外的功能这门课除了核心功能，还要求实现log压缩（section 7），快速log回溯（第8页左上方）。 log压缩主要看Figure 13。 leader发送表示一个snapshot的多个chunk的方式 参数 term leader的term leaderId lastIncludedIndex lastIncludedTerm offset chunk在snapshot文件中的byte位置偏移量 data[] snapshot chunk 的原始数据，从offset开始 done true表示为最后一个chunk 结果 term 当前term Receiver Implementation 如果 term &lt; currentTerm，立即返回 第一个chunk时新建snapshot文件 在给的offset处写入文件 如果done是false，返回并等待更多chunk 保存snapshot文件，其他snapshot文件如果有更小的index，就丢弃 如果已有的log entry和snapshot的最后一个entry有同样的index和term，保留这之后的log entries 丢弃整个log 用snapshot内容重设状态机 注意事项： 在做snapshot时，应用的状态应该对设计raft log中已经有index应用过的状态。也就是说，要么知道snapshot对应的index，要么raft在完成snapshot前不应用新的log entries。 状态和snapshot提交是分开的，所以在此两者之间的崩溃会导致问题，因为此时被snapshot覆盖的log已经丢弃了。解决办法是记录真实的Raft持久化日志第一条内容的index。 快速log回溯 如果follower在log中没有prevLogIndex，那么应该返回conflictIndex = len(log)和conflictTerm = None 如果follower在log中有prevLogIndex，但是term对不上，那么返回值conflictTerm = log[prevLogIndex].Term，然后找第一个entry的term等于conflictTerm，回溯到这个index 收到冲突返回时，leader应该在log中搜索conflictTerm。如果找到了，就把nextIndex设为这个term最后的index之前的那个index。（这句话没看懂，原文If it finds an entry in its log with that term, it should set nextIndex to be the one beyond the index of the last entry in that term in its log.） 接上条，如果没有找到，设置nextIndex = conflictIndex 应用Raft时的注意点Applying client operations - 应用操作服务应该被设计为一个状态机。需要有一个循环去接受用户的操作，和将用户的操作按顺序应用到状态机。这个循环是唯一一处能接触到状态机的地方。 如何知道用户的请求已经完成？在用户操作时，记录当前log的index，一旦在那个index处的操作被标记为已应用，看该处的操作是不是当时的操作，是表示操作成功，否表示操作失败。 Duplicate detection - 重复检测防止应用两次：每个client有一个id，每次请求有一个单调增id。如果相同clinet的相同请求id已经处理过了，就忽略。 其他问题重复Index，死锁 附录： In Search of an Understandable Consensus Algorithm(Extended Version) Students’ Guide to Raft","categories":[{"name":"Lab","slug":"Lab","permalink":"https://juniousy.github.io/categories/Lab/"}],"tags":[{"name":"distributed system","slug":"distributed-system","permalink":"https://juniousy.github.io/tags/distributed-system/"}]},{"title":"6.824 Lab1 - Map Reduce","slug":"2022/6.824Lab1","date":"2022-05-30T12:00:00.000Z","updated":"2022-05-31T17:03:46.845Z","comments":true,"path":"2022/05/30/2022/6.824Lab1/","link":"","permalink":"https://juniousy.github.io/2022/05/30/2022/6.824Lab1/","excerpt":"","text":"--- wc test: PASS *** Starting indexer test. --- indexer test: PASS *** Starting map parallelism test. --- map parallelism test: PASS *** Starting reduce parallelism test. --- reduce parallelism test: PASS *** Starting crash test. --- crash test: PASS *** PASSED ALL TESTS 课程要求是不公开自己的代码的，遵守一下规则。这里简单讲讲思路和遇到的问题 实现首先思考一下“要做什么”，所以做了一下功能点的拆分 1. master收到任务（文件名）后负责拆分任务 2. worker向master申请任务（可能是map也可能是reduce） 3. worker map操作，存入中间文件 4. worker reduce操作，读取中间文件，写入文件 5. crash worker 的处理 6. master判断任务是否已经全部完成；worker结束进程 我的实现用了两个rpc func (m *Master) AskForTask(args struct&#123;&#125;, reply *AskForTaskReply) error func (m *Master) ReportTask(args ReportTaskArgs, replay *struct&#123;&#125;) error 方法AskForTask就是一个worker向master申请任务的过程，对应功能点1、2和6。1和2好理解，为什么会有6是因为考虑到worker持续循环调用AskForTask，所以把判断任务全部完成的状态也加在这个方法里，AskForTaskReply会告知worker任务全部完成 功能点3、4在worker.go下实现。map操作的核心思想是读取待处理的文件，调用mapf，写入intermedia file，通过rpc告知master任务已完成。master会维护一个文件完成情况的map，key是待处理map任务的id，value是任务状态（未开始、进行中、已完成）。reduce操作的核心思想是根据master指定的intermedia filename去读取中间文件，然后调用reducef，然后通知任务完成。我这样实现的话，有个关键的点是，map在通知任务完成时，要把中间文件的filename也告诉master，因为这个reduce任务的来源。同样master也会有类似的map去维护reduce任务的状态。 任务5我的做法比较简单，在每次分发任务时都新建一个线程延时等待，如果等待时间结束，任务还未完成，就把任务从进行中改为未开始。这个做法还是比较粗糙的，不过在这个lab里能够处理。 问题点环境我在wsl2环境下实现，而golang版本不是Go1.13，而是Go1.18.2。这里还是不建议更改版本，不过因为module相关的一些问题，哪怕我用了go1.13也会触发同样的问题，所以最后我改了下测试文件的编译命令，直接用1.18去跑（逃 ... (cd .. &amp;&amp; GO111MODULE=off go build $RACE mrmaster.go) || exit 1 (cd .. &amp;&amp; GO111MODULE=off go build $RACE mrworker.go) || exit 1 (cd .. &amp;&amp; GO111MODULE=off go build $RACE mrsequential.go) || exit 1 ... 这个改动应该是不影响在要求的环境下的测试结果的 race加-race被提醒有地方会有问题 WARNING: DATA RACE Write at 0x00c000100220 by goroutine 78: _/home/...../MIT6.824/src/mr.(*Master).AskForTask() /home/...../MIT6.824/src/mr/master.go:75 +0x885 Previous read at 0x00c000100220 by main goroutine: _/home/.....g/MIT6.824/src/mr.(*Master).Done() /home/...../MIT6.824/src/mr/master.go:134 +0xef parallelism测试卡死 只能手动Kill这个问题一开始很困惑，后来发现单跑这个测试是能通过的。然后我发现这个测试会读当前文件夹。而我一开始没有手动删除intermedia file，这个test也不会删之前的intermedia file，我猜测问题点出在这里。事实证明在加入了任务完成后删除intermedia file后，就能通过了。 其他小bug比如重复问题，debug发现是没有等map全部结束就发出去了reduce任务。 ADLER 1 ADVENTURE 12 ADVENTURES 7 AFTER 2 AGREE 16 AGREEMENT 8 ... ADLER 1 ADVENTURE 12 ADVENTURES 7 AFTER 2 AFTER 2 AGREE 16 AGREEMENT 8 还有crash test超时问题，打了日志后再稍微看下代码就发现是小bug，不多赘述。","categories":[{"name":"Lab","slug":"Lab","permalink":"https://juniousy.github.io/categories/Lab/"}],"tags":[{"name":"distributed system","slug":"distributed-system","permalink":"https://juniousy.github.io/tags/distributed-system/"}]},{"title":"【本科时期文章】Java 同步器核心AQS","slug":"存档/Java-同步器核心AQS","date":"2019-06-14T03:27:12.000Z","updated":"2022-05-30T09:06:50.980Z","comments":true,"path":"2019/06/14/存档/Java-同步器核心AQS/","link":"","permalink":"https://juniousy.github.io/2019/06/14/%E5%AD%98%E6%A1%A3/Java-%E5%90%8C%E6%AD%A5%E5%99%A8%E6%A0%B8%E5%BF%83AQS/","excerpt":"juc(java.util.concurrent) 基于 AQS （ AbstractQueuedSynchronizer ）框架构建锁机制。本文将介绍AQS是如何实现共享状态同步功能，并在此基础上如何实现同步锁机制。","text":"juc(java.util.concurrent) 基于 AQS （ AbstractQueuedSynchronizer ）框架构建锁机制。本文将介绍AQS是如何实现共享状态同步功能，并在此基础上如何实现同步锁机制。 AbstractQueuedSynchronizerCLH同步队列AQS如其名所示，使用了队列。当共享资源（即多个线程竞争的资源）被某个线程占有时，其他请求该资源的线程将会阻塞，进入CLH同步队列。 队列的节点为AQS内部类Node。Node持有前驱和后继，因此队列为双向队列。有如下状态： SIGNAL 后继节点阻塞(park)或即将阻塞。当前节点完成任务后要唤醒(unpark)后继节点。 CANCELLED 节点从同步队列中取消 CONDITION 当前节点进入等待队列中 PROPAGATE 表示下一次共享式同步状态获取将会无条件传播下去 0 其他 AQS通过头尾指针来管理同步队列，同时实现包括获取锁失败的线程进行入队，释放锁时唤醒对同步队列中的线程。未获取到锁的线程会创建节点线程安全（compareAndSetTail）的加入队列尾部。同步队列遵循FIFO，首节点是获取同步状态成功的节点。 获取锁未获取到锁（tryAcquire失败）的线程将创建一个节点，设置到尾节点。 public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &#125; //创建节点至尾节点 private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; // 如果compareAndSetTail失败或者队列里没有节点 enq(node); return node; &#125; enq是一个CAS的入队方法： private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125; acquireQueued方法的作用是获取锁。 final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); // 获取锁成功 if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; // 获取失败则阻塞 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; 释放锁首节点的线程在释放锁时，将会唤醒后继节点。而后继节点将会在获取锁成功时将自己设置为首节点。 public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) // 唤醒后继节点 unparkSuccessor(h); return true; &#125; return false; &#125; 响应中断式获取锁可响应中断式锁可调用方法lock.lockInterruptibly();而该方法其底层会调用AQS的acquireInterruptibly方法。 public final void acquireInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); if (!tryAcquire(arg)) doAcquireInterruptibly(arg); &#125; private void doAcquireInterruptibly(int arg) throws InterruptedException &#123; final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) // 唯一的区别是当parkAndCheckInterrupt返回true时即线程阻塞时该线程被中断，代码抛出被中断异常。 throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; 超时等待获取锁通过调用lock.tryLock(timeout,TimeUnit)方式达到超时等待获取锁的效果，调用AQS的方法tryAcquireNanos()。 public final boolean tryAcquireNanos(int arg, long nanosTimeout) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); return tryAcquire(arg) || doAcquireNanos(arg, nanosTimeout); &#125; tongbuqi private boolean doAcquireNanos(int arg, long nanosTimeout) throws InterruptedException &#123; if (nanosTimeout &lt;= 0L) return false; final long deadline = System.nanoTime() + nanosTimeout; final Node node = addWaiter(Node.EXCLUSIVE); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return true; &#125; // 计算等待时间 nanosTimeout = deadline - System.nanoTime(); if (nanosTimeout &lt;= 0L) return false; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; nanosTimeout &gt; spinForTimeoutThreshold) LockSupport.parkNanos(this, nanosTimeout); if (Thread.interrupted()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; 共享锁的获取最后看下共享锁的获取。 public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) //获取锁失败时调用 doAcquireShared(arg); &#125; private void doAcquireShared(int arg) &#123; final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head) &#123; int r = tryAcquireShared(arg); // 当tryAcquireShared返回值&gt;=0时取得锁 if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); p.next = null; // help GC if (interrupted) selfInterrupt(); failed = false; return; &#125; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; 队列外成员变量AQ还有state成员变量，volatile int类型，用于同步线程之间的共享状态。当state&gt;0时表示已经获取了锁，对于重入锁来说state值即重入数，当state = 0时表示释放了锁。具体说明见下面各同步器的实现。 实现同步器每一种同步器都通过实现tryacquire（包括如tryAcquireShared之类的方法）、tryRelease来实现同步功能。 ReentrantLock主要看获取锁的过程非公平锁获取锁： final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); //如果当前重进入数为0,说明有机会取得锁 if (c == 0) &#123; //抢占式获取锁 compareAndSetState是原子方法 if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; //如果当前线程本身就持有锁，那么叠加重进入数，并且继续获得锁 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; //以上条件都不满足，那么线程进入等待队列。 return false; &#125; 公平锁获取锁类似： protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; // 区别之处，非抢占式 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false; &#125; Semaphore以state作为信号量使用，例子： final int nonfairTryAcquireShared(int acquires) &#123; for (;;) &#123; int available = getState(); int remaining = available - acquires; //剩下多少许可资源 if (remaining &lt; 0 || compareAndSetState(available, remaining)) return remaining; &#125; &#125; CountDownLatch以state作为计数器，state为0时等待结束： public void await() throws InterruptedException &#123; //阻塞直到state为0 sync.acquireSharedInterruptibly(1); &#125; 用同步器方法减少state public void countDown() &#123; sync.releaseShared(1); &#125; protected boolean tryReleaseShared(int releases) &#123; // Decrement count; signal when transition to zero for (;;) &#123; int c = getState(); if (c == 0) return false; int nextc = c-1; if (compareAndSetState(c, nextc)) return nextc == 0; &#125; &#125;","categories":[{"name":"开发","slug":"开发","permalink":"https://juniousy.github.io/categories/%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://juniousy.github.io/tags/Java/"},{"name":"并发","slug":"并发","permalink":"https://juniousy.github.io/tags/%E5%B9%B6%E5%8F%91/"}]},{"title":"【本科时期文章】Redis的数据结构与编码","slug":"存档/Redis的数据结构与编码","date":"2019-06-05T07:42:40.000Z","updated":"2022-05-30T09:06:50.982Z","comments":true,"path":"2019/06/05/存档/Redis的数据结构与编码/","link":"","permalink":"https://juniousy.github.io/2019/06/05/%E5%AD%98%E6%A1%A3/Redis%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%BC%96%E7%A0%81/","excerpt":"类型 编码方式 数据结构 string raw 动态字符串编码 embstr 优化内存分配的字符串编码 int 整数编码 hash hashtable 散列表编码 ziplist 压缩列表编码 list linkedlist 双向链表编码 ziplist 压缩列表编码 quicklist 3.2版本新的列表编码 set hashtable 散列表编码 intset 整数集合编码 zset skiplist 跳跃表编码 ziplist 压缩列表编码","text":"类型 编码方式 数据结构 string raw 动态字符串编码 embstr 优化内存分配的字符串编码 int 整数编码 hash hashtable 散列表编码 ziplist 压缩列表编码 list linkedlist 双向链表编码 ziplist 压缩列表编码 quicklist 3.2版本新的列表编码 set hashtable 散列表编码 intset 整数集合编码 zset skiplist 跳跃表编码 ziplist 压缩列表编码 字符串结构Redis没有采用原生C语言的字符串类型，而是自己实现了字符串结构，内部简单动态字符串(simple dynamic string，SDS)。特点如下： O(1)时间复杂度获取字符串长度、已用长度、未用长度 可用于保存字节数组，支持安全的二进制数据存储 内部实现空间预分配机制，降低内存内存再分配次数 惰性删除机制，字符串缩减后的空间不释放，作为预分配空间保留 对于string， int：8个字节的长整型 embstr：小于等于39个字节的字符串 raw：大于39个字节的字符串，即用简单动态字符串（SDS）存储 embstr 编码的优化之处在于将创建字符串对象所需的内存分配次数从 raw 编码的两次降低为一次，mbstr 编码的字符串对象的所有数据都保存在一块连续的内存里面，redisObject 结构(type, encoding…)和 sdshdr 结构(free, len, buf)都放在一起embstr 编码的字符串对象实际上是只读的： 当我们对 embstr 编码的字符串对象执行任何修改命令时， 程序会先将对象的编码从 embstr 转换成 raw ， 然后再执行修改命令； 因为这个原因， embstr 编码的字符串对象在执行修改命令之后， 总会变成一个 raw 编码的字符串对象。 ziplist 压缩列表hash、list、zset中，如果所有值小于hash_max_ziplist_value （默认值为 64 ），且元素个数小于 hash_max_ziplist_entries （默认值为 512 ）时使用ziplist编码。 ziplist编码的主要目的是为了节约内存，因此所有数据都是采用线性连续的内存结构。结构字段含义： zlbytes：整个压缩列表所占字节长度。int-32，长度4字节。 zltail：距离尾节点的偏移量。int-32，长度4字节。 zllen：int-16，长度2字节。 entry：具体的节点： prev_entry_bytes_length：记录前一个节点所占空间 encoding：标示当前节点编码和长度 contents：保存节点的值 zlend：记录列表结尾，占一个字节 从上可以看出存在双向链表结构，以O(1)时间复杂度入队和出队。而新增删除操作涉及内存重新分配和释放。 hashtableRedis 使用的hash算法是 MurmurHash2 ，解决冲突的方式是链地址法。程序总是将新节点添加到链表的表头位置（复杂度为 O(1)）， 排在其他已有节点的前面。按2的幂rehash。 linkedlistRedis 的链表实现的特性可以总结如下： 双端： langfei链表节点带有 prev 和 next 指针， 获取某个节点的前置节点和后置节点的复杂度都是 O(1) 。 无环： 表头节点的 prev 指针和表尾节点的 next 指针都指向 NULL ， 对链表的访问以 NULL 为终点。 带表头指针和表尾指针： 通过 list 结构的 head 指针和 tail 指针， 程序获取链表的表头节点和表尾节点的复杂度为 O(1) 。 带链表长度计数器： 程序使用 list 结构的 len 属性来对 list 持有的链表节点进行计数， 程序获取链表中节点数量的复杂度为 O(1) 。 多态： 链表节点使用 void* 指针来保存节点值， 并且可以通过 list 结构的 dup 、 free 、 match 三个属性为节点值设置类型特定函数， 所以链表可以用于保存各种不同类型的值。 intset存储有序、不重复的整数集。集合只包含整数且长度不超过set-max-intset-entries intset对写入整数进行排序，通过O(lgn)时间复杂度实现查找和去重操作。字段含义： encoding：整数表示类型，根据集合内最长整数值确定类型，整数类型划分为int-16，int-32，int-64 length：表示集合元素个数 contents：整数数组，按从小到达顺序排列 尽量保证整数范围一致，防止个别大整数触发集合升级操作，产生内存浪费。 skiplist过在每个节点中维持多个指向其他节点的指针， 从而达到快速访问节点的目的。跳跃表支持平均 O(log N) 最坏 O(N) 复杂度的节点查找， 还可以通过顺序性操作来批量处理节点。 ObjectRedis 中的每个对象都由一个 redisObject 结构表示， 该结构中和保存数据有关的三个属性分别是 type 属性、 encoding 属性和 ptr 属性。对象的 type 属性记录了对象的类型。对象的 ptr 指针指向对象的底层实现数据结构， 而这些数据结构由对象的 encoding 属性决定。 因为 C 语言并不具备自动的内存回收功能， 所以 Redis 在自己的对象系统中构建了一个引用计数（reference counting）技术实现的内存回收机制， 通过这一机制， 程序可以通过跟踪对象的引用计数信息， 在适当的时候自动释放对象并进行内存回收。由redisObject 结构的 refcount 属性记录： 在创建一个新对象时， 引用计数的值会被初始化为 1 ； 当对象被一个新程序使用时， 它的引用计数值会被增一； 当对象不再被一个程序使用时， 它的引用计数值会被减一； 当对象的引用计数值变为 0 时， 对象所占用的内存会被释放。 redisObject 结构包含的最后一个属性为 lru 属性， 该属性记录了对象最后一次被命令程序访问的时间。OBJECT IDLETIME 命令可以打印出给定键的空转时长， 这一空转时长就是通过将当前时间减去键的值对象的 lru 时间计算得出的。","categories":[{"name":"开发","slug":"开发","permalink":"https://juniousy.github.io/categories/%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://juniousy.github.io/tags/Redis/"}]},{"title":"【本科时期文章】从Redis I/O多路复用到Java NIO Selector","slug":"存档/从Redis-I-O多路复用到Java-NIO-Selector","date":"2019-06-04T07:19:21.000Z","updated":"2022-05-30T09:06:50.983Z","comments":true,"path":"2019/06/04/存档/从Redis-I-O多路复用到Java-NIO-Selector/","link":"","permalink":"https://juniousy.github.io/2019/06/04/%E5%AD%98%E6%A1%A3/%E4%BB%8ERedis-I-O%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E5%88%B0Java-NIO-Selector/","excerpt":"Redis的I/O多路复用架构Redis的一大特点就是单线程架构。单线程架构既避免了多线程可能产生的竞争问题，又避免了多线程的频繁上下文切换问题，是Redis高效率的保证。","text":"Redis的I/O多路复用架构Redis的一大特点就是单线程架构。单线程架构既避免了多线程可能产生的竞争问题，又避免了多线程的频繁上下文切换问题，是Redis高效率的保证。 对于网络I/O操作，Redis基于 Reactor 模式可以用单个线程处理多个Socket。内部实现为使用文件事件处理器(file event handler)进行网络事件处理器，这个文件事件处理器是单线程的。文件事件处理器采用 I/O 多路复用机制(multiplexing)同时监听多个 socket。产生事件的 socket 压入内存队列中，事件分派器根据 socket 上的事件类型来选择对应的事件处理器进行处理。操作包括应答（accept）、读取（read）、写入（write）、关闭（close）等。文件事件处理器的结构包含 4 个部分： 多个 socket I/O 多路复用程序 文件事件分派器 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）连接应答处理器会创建一个能与客户端通信的 socket01，通过这个返回结果给客户端。Redis单线程的核心就是I/O 多路复用程序。 I/O多路复用（IO Multiplexing）有时也称为异步阻塞IO，是一种事件驱动的I/O模型。单个I/O操作在一般情况下往往不能直接返回，传统的阻塞 I/O 模型会阻塞直到系统内核返回数据。而在 I/O 多路复用模型中，系统调用select/poll/epoll 函数会不断的查询所监测的 socket 文件描述符，查看其中是否有 socket 准备好读写了，如果有，那么系统就会通知用户进程。 Redis 的 I/O 多路复用程序的所有功能都是通过包装常见的 select 、 epoll 、 evport 和 kqueue 这些 I/O 多路复用函数库来实现的， 每个 I/O 多路复用函数库在 Redis 源码中都对应一个单独的文件。 以ae_select.c实现的封装select方法为例。select方法定义如下所示，检测是否可读、可写、异常，返回准备完毕的descriptors个数。 extern int select (int __nfds, fd_set *__restrict __readfds, fd_set *__restrict __writefds, fd_set *__restrict __exceptfds, struct timeval *__restrict __timeout); Redis封装首先通过aeApiCreate初始化 rfds 和 wfds，注册到aeEventLoop中去。 static int aeApiCreate(aeEventLoop *eventLoop) &#123; aeApiState *state = zmalloc(sizeof(aeApiState)); if (!state) return -1; FD_ZERO(&amp;state-&gt;rfds); FD_ZERO(&amp;state-&gt;wfds); eventLoop-&gt;apidata = state; return 0; &#125; 而 aeApiAddEvent 和 aeApiDelEvent 会通过 FD_SET 和 FD_CLR 修改 fd_set 中对应 FD 的标志位。 static int aeApiAddEvent(aeEventLoop *eventLoop, int fd, int mask) &#123; aeApiState *state = eventLoop-&gt;apidata; if (mask &amp; AE_READABLE) FD_SET(fd,&amp;state-&gt;rfds); if (mask &amp; AE_WRITABLE) FD_SET(fd,&amp;state-&gt;wfds); return 0; &#125; static void aeApiDelEvent(aeEventLoop *eventLoop, int fd, int mask) &#123; aeApiState *state = eventLoop-&gt;apidata; if (mask &amp; AE_READABLE) FD_CLR(fd,&amp;state-&gt;rfds); if (mask &amp; AE_WRITABLE) FD_CLR(fd,&amp;state-&gt;wfds); &#125; aeApiPoll是实际调用 select 函数的部分，其作用就是在 I/O 多路复用函数返回时，将对应的 FD 加入 aeEventLoop 的 fired 数组中，并返回事件的个数： static int aeApiPoll(aeEventLoop *eventLoop, struct timeval *tvp) &#123; aeApiState *state = eventLoop-&gt;apidata; int retval, j, numevents = 0; memcpy(&amp;state-&gt;_rfds,&amp;state-&gt;rfds,sizeof(fd_set)); memcpy(&amp;state-&gt;_wfds,&amp;state-&gt;wfds,sizeof(fd_set)); retval = select(eventLoop-&gt;maxfd+1, &amp;state-&gt;_rfds,&amp;state-&gt;_wfds,NULL,tvp); if (retval &gt; 0) &#123; for (j = 0; j &lt;= eventLoop-&gt;maxfd; j++) &#123; int mask = 0; aeFileEvent *fe = &amp;eventLoop-&gt;events[j]; if (fe-&gt;mask == AE_NONE) continue; if (fe-&gt;mask &amp; AE_READABLE &amp;&amp; FD_ISSET(j,&amp;state-&gt;_rfds)) mask |= AE_READABLE; if (fe-&gt;mask &amp; AE_WRITABLE &amp;&amp; FD_ISSET(j,&amp;state-&gt;_wfds)) mask |= AE_WRITABLE; eventLoop-&gt;fired[numevents].fd = j; eventLoop-&gt;fired[numevents].mask = mask; numevents++; &#125; &#125; return numevents; &#125; epoll函数的封装类似。区别在于 epoll_wait 函数返回时并不需要遍历所有的 FD 查看读写情况；在 epoll_wait 函数返回时会提供一个 epoll_event 数组，其中保存了发生的 epoll 事件（EPOLLIN、EPOLLOUT、EPOLLERR 和 EPOLLHUP）以及发生该事件的 FD。Redis封装的调用只需要将epoll_event数组中存储的信息加入eventLoop的 fired 数组中，将信息传递给上层模块： static int aeApiPoll(aeEventLoop *eventLoop, struct timeval *tvp) &#123; aeApiState *state = eventLoop-&gt;apidata; int retval, numevents = 0; retval = epoll_wait(state-&gt;epfd,state-&gt;events,eventLoop-&gt;setsize, tvp ? (tvp-&gt;tv_sec*1000 + tvp-&gt;tv_usec/1000) : -1); if (retval &gt; 0) &#123; int j; numevents = retval; for (j = 0; j &lt; numevents; j++) &#123; int mask = 0; struct epoll_event *e = state-&gt;events+j; if (e-&gt;events &amp; EPOLLIN) mask |= AE_READABLE; if (e-&gt;events &amp; EPOLLOUT) mask |= AE_WRITABLE; if (e-&gt;events &amp; EPOLLERR) mask |= AE_WRITABLE; if (e-&gt;events &amp; EPOLLHUP) mask |= AE_WRITABLE; eventLoop-&gt;fired[j].fd = e-&gt;data.fd; eventLoop-&gt;fired[j].mask = mask; &#125; &#125; return numevents; &#125; 当Socket变得可读时（客户端对Socket执行 write 操作，或者执行 close 操作）， 或者有新的可应答（acceptable）Socket出现时（客户端对服务器的监听Socket执行 connect 操作），Socket产生 AE_READABLE 事件。而当Socket变得可写时（客户端对Socket执行 read 操作）， Socket产生 AE_WRITABLE 事件。I/O 多路复用程序允许服务器同时监听Socket的 AE_READABLE 事件和 AE_WRITABLE 事件， 如果一个Socket同时产生了这两种事件， 那么文件事件分派器会优先处理 AE_READABLE 事件， 等到 AE_READABLE 事件处理完之后， 才处理 AE_WRITABLE 事件。换句话说， 如果一个Socket又可读又可写的话， 那么服务器将先读Socket， 后写Socket。 Java NIO SelectorJava中也有I/O多路复用的方式，例子为NIO的Selector。selector的创建方式为调用Selector类的静态方法，由SelectorProvider提供：Selector selector = Selector.open(); public static Selector open() throws IOException &#123; return SelectorProvider.provider().openSelector(); &#125; SelectorProvider是单例模式，Linux默认提供EPollSelectorProvider，即提供的Selector为EPollSelectorImpl。 public static SelectorProvider provider() &#123; synchronized (lock) &#123; if (provider != null) return provider; return AccessController.doPrivileged( new PrivilegedAction&lt;SelectorProvider&gt;() &#123; public SelectorProvider run() &#123; if (loadProviderFromProperty()) return provider; if (loadProviderAsService()) return provider; provider = sun.nio.ch.DefaultSelectorProvider.create(); return provider; &#125; &#125;); &#125; &#125; //..... /** * Returns the default SelectorProvider. */ public static SelectorProvider create() &#123; String osname = AccessController .doPrivileged(new GetPropertyAction(&quot;os.name&quot;)); if (osname.equals(&quot;SunOS&quot;)) return createProvider(&quot;sun.nio.ch.DevPollSelectorProvider&quot;); if (osname.equals(&quot;Linux&quot;)) return createProvider(&quot;sun.nio.ch.EPollSelectorProvider&quot;); return new sun.nio.ch.PollSelectorProvider(); &#125; 调用系统Epoll方法的地方在EPollArrayWrapper类的poll方法中，该类由EPollSelectorImpl持有： int poll(long timeout) throws IOException &#123; updateRegistrations(); updated = epollWait(pollArrayAddress, NUM_EPOLLEVENTS, timeout, epfd); for (int i=0; i&lt;updated; i++) &#123; if (getDescriptor(i) == incomingInterruptFD) &#123; interruptedIndex = i; interrupted = true; break; &#125; &#125; return updated; &#125; Selector使用中需要绑定Channel。以ServerSocketChannel为例： ServerSocketChannel serverSocket = ServerSocketChannel.open(); serverSocket.bind(new InetSocketAddress(&quot;localhost&quot;, 5454)); serverSocket.configureBlocking(false); serverSocket.register(selector, SelectionKey.OP_ACCEPT); 注册时会调用Selector的回调方法register，生成SelectionKey。 protected final SelectionKey register(AbstractSelectableChannel ch, int ops, Object attachment) &#123; if (!(ch instanceof SelChImpl)) throw new IllegalSelectorException(); SelectionKeyImpl k = new SelectionKeyImpl((SelChImpl)ch, this); k.attach(attachment); synchronized (publicKeys) &#123; implRegister(k); &#125; k.interestOps(ops); return k; &#125; 最后在使用时根据SelectionKeys遍历查看状态。可以通过监听的事件有： Connect – OP_CONNECT client尝试连接 Accept – OP_ACCEPT server端接受连接 Read – OP_READ server端可以开始从channel里读取 Write – OP_WRITE server端可以向channel里写 使用方式类似： while (true) &#123; selector.select(); Set&lt;SelectionKey&gt; selectedKeys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; iter = selectedKeys.iterator(); while (iter.hasNext()) &#123; SelectionKey key = iter.next(); if (key.isAcceptable()) &#123; register(selector, serverSocket); &#125; if (key.isReadable()) &#123; answerWithEcho(buffer, key); &#125; iter.remove(); &#125; &#125; Selector的wakeup()方法主要作用是解除阻塞在Selector.select()/select(long)上的线程，立即返回，调用了本地的中断方法。可以在注册了新的channel或者事件、channel关闭，取消注册时使用，或者优先级更高的事件触发（如定时器事件），希望及时处理。 通过NIO的I/O多路复用方式可以节约线程资源，提高网络I/O效率。 参考 Redis 设计与实现-文件事件 Redis 和 I/O 多路复用 Introduction to the Java NIO Selector","categories":[{"name":"开发","slug":"开发","permalink":"https://juniousy.github.io/categories/%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://juniousy.github.io/tags/Java/"},{"name":"Redis","slug":"Redis","permalink":"https://juniousy.github.io/tags/Redis/"}]},{"title":"【本科时期文章】LeetCode 23. Merge k Sorted Lists","slug":"存档/LeetCode-23-Merge-k-Sorted-Lists","date":"2019-05-17T08:53:24.000Z","updated":"2022-05-30T12:37:14.956Z","comments":true,"path":"2019/05/17/存档/LeetCode-23-Merge-k-Sorted-Lists/","link":"","permalink":"https://juniousy.github.io/2019/05/17/%E5%AD%98%E6%A1%A3/LeetCode-23-Merge-k-Sorted-Lists/","excerpt":"ProblemMerge k sorted linked lists and return it as one sorted list. Analyze and describe its complexity. Example: Input: [ 1-&gt;4-&gt;5, 1-&gt;3-&gt;4, 2-&gt;6 ] Output: 1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4-&gt;5-&gt;6","text":"ProblemMerge k sorted linked lists and return it as one sorted list. Analyze and describe its complexity. Example: Input: [ 1-&gt;4-&gt;5, 1-&gt;3-&gt;4, 2-&gt;6 ] Output: 1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4-&gt;5-&gt;6 Solution使用priority queue /* * @lc app=leetcode id=23 lang=java * * [23] Merge k Sorted Lists */ /** * Definition for singly-linked list. * public class ListNode &#123; * int val; * ListNode next; * ListNode(int x) &#123; val = x; &#125; * &#125; */ class Solution &#123; public ListNode mergeKLists(ListNode[] lists) &#123; if (lists == null || lists.length == 0) return null; PriorityQueue&lt;ListNode&gt; pQueue = new PriorityQueue&lt;&gt;((a, b) -&gt; a.val - b.val); ListNode dummy = new ListNode(0); ListNode cur = dummy; for (ListNode node:lists) &#123; if (node == null) continue; pQueue.offer(node); &#125; while(!pQueue.isEmpty()) &#123; cur.next = pQueue.poll(); cur = cur.next; if (cur.next != null) pQueue.offer(cur.next); &#125; return dummy.next; &#125; &#125; Time complexity: O(nlogk) Space complexity: O(k)","categories":[{"name":"刷题","slug":"刷题","permalink":"https://juniousy.github.io/categories/%E5%88%B7%E9%A2%98/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://juniousy.github.io/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"【本科时期文章】ThreadLocal","slug":"存档/ThreadLocal","date":"2019-03-24T14:12:30.000Z","updated":"2022-05-30T09:06:50.983Z","comments":true,"path":"2019/03/24/存档/ThreadLocal/","link":"","permalink":"https://juniousy.github.io/2019/03/24/%E5%AD%98%E6%A1%A3/ThreadLocal/","excerpt":"ThreadLocal的作用并不是解决多线程共享变量的问题，而是存储那些线程间隔离，但在不同方法间共享的变量。这是线程安全的一种无同步方案，另一种是无同步方案是幂等的可重入代码。 下面先模拟一个基本的ThreadLocal存储User id的模型，然后解析原理。","text":"ThreadLocal的作用并不是解决多线程共享变量的问题，而是存储那些线程间隔离，但在不同方法间共享的变量。这是线程安全的一种无同步方案，另一种是无同步方案是幂等的可重入代码。 下面先模拟一个基本的ThreadLocal存储User id的模型，然后解析原理。 示例import java.util.concurrent.atomic.AtomicInteger; public class ThreadLocalTest &#123; //工作线程 class Worker implements Runnable &#123; ThreadLocal&lt;Integer&gt; userId = ThreadLocal.withInitial(() -&gt; 1); UserRepo userRepo; Worker(UserRepo userRepo) &#123; this.userRepo = userRepo; &#125; @Override public void run() &#123; for (int i = 0; i &lt; 10; i++) &#123; handler(); try &#123; Thread.sleep(30); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; private void handler() &#123; userId.set(userRepo.getUserId()); System.out.println(Thread.currentThread().getName() + &quot; userId: &quot; + userId.get()); &#125; &#125; //模拟拿自增user id class UserRepo &#123; private AtomicInteger incrUserId = new AtomicInteger(1); private Integer getUserId() &#123; return incrUserId.getAndIncrement(); &#125; &#125; private void test() &#123; UserRepo userRepo = new UserRepo(); for (int i = 0; i &lt; 15; i++) &#123; new Thread(new Worker(userRepo)).start(); &#125; &#125; public static void main(String[] args) &#123; ThreadLocalTest test = new ThreadLocalTest(); test.test(); &#125; &#125; 结果如下 ........(上略) Thread-13 userId: 135 Thread-0 userId: 136 Thread-2 userId: 137 Thread-1 userId: 138 Thread-4 userId: 139 Thread-5 userId: 140 Thread-3 userId: 141 Thread-6 userId: 142 Thread-7 userId: 143 Thread-9 userId: 144 Thread-10 userId: 145 Thread-11 userId: 146 Thread-8 userId: 147 Thread-12 userId: 149 Thread-14 userId: 148 Thread-13 userId: 150 原理核心是ThreadLocal的内部静态类ThreadLocalMap。map的key是ThreadLocal对象，value是和ThreadLocal对象有关联的值。 static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125; &#125; 注意内部Entry是WeakReference的，原因是出于性能考虑。由于不是强联系，所以其他正在使用ThreadLocal的线程，不会妨碍gc那些来自同一个ThreadLocal的终止后的线程的变量，简单来讲就是待gc的变量会被正确gc。 在ThreadLocalMap 的 remove 方法中，除了讲entry的引用设为null以外，还调用了一个expungeStaleEntry方法： if (e.get() == key) &#123; e.clear(); expungeStaleEntry(i); return; &#125; 其中会将所有键为 null 的 Entry 的值设置为 null，这样可以防止内存泄露，已经不再被使用且已被回收的 ThreadLocal 对象对应的Entry也会被gc清除： if (k == null) &#123; e.value = null; tab[i] = null; size--; &#125; 在同样的还有rehash, resize方法方法中，也有类似的设置value为null的操作。 在创建线程时，该线程持有threadLocals。这个引用是在ThreadLocal的createMap方法中设定的，否则为null。 void createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue); &#125; 调用ThreadLocalMap的构造方法： ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) &#123; table = new Entry[INITIAL_CAPACITY]; int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1); table[i] = new Entry(firstKey, firstValue); size = 1; setThreshold(INITIAL_CAPACITY); &#125; 再返回来看ThreadLocal就很好理解了get方法： public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); //获取当前线程的ThreadLocalMap if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); //从map中取值，key就是当前ThreadLocal对象 if (e != null) &#123; @SuppressWarnings(&quot;unchecked&quot;) T result = (T)e.value; return result; &#125; &#125; return setInitialValue(); &#125; set方法： public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); //获取当前线程的ThreadLocalMap if (map != null) map.set(this, value); //向map中存值，key就是当前ThreadLocal对象 else createMap(t, value); &#125; 应用很常见的应用在Session中存储数据。一个Session对应一个线程，对应一组线程内方法间的共享变量，这些变量都可以由ThreadLocal存储。 参考下结合ThreadLocal来看spring事务源码，感受下清泉般的洗涤！，可以看到在Spring事务中，也有类似ThreadLocal的操作，将数据库connection绑定到当前线程，使用的也是一个map。","categories":[{"name":"开发","slug":"开发","permalink":"https://juniousy.github.io/categories/%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://juniousy.github.io/tags/Java/"},{"name":"并发","slug":"并发","permalink":"https://juniousy.github.io/tags/%E5%B9%B6%E5%8F%91/"}]},{"title":"【本科时期文章】Java Collection笔记","slug":"存档/Java-Collection笔记","date":"2019-03-20T12:19:10.000Z","updated":"2022-05-30T09:06:50.980Z","comments":true,"path":"2019/03/20/存档/Java-Collection笔记/","link":"","permalink":"https://juniousy.github.io/2019/03/20/%E5%AD%98%E6%A1%A3/Java-Collection%E7%AC%94%E8%AE%B0/","excerpt":"这是自己整理的一些Collection的要点笔记，比较零碎，可能可读性不是很强。有新内容时会进行补充。Java Collection框架： Set , HashSet TreeSet(实现SortedSet) SortedSet List , LinkedList ArrayList Queue, PriorityQueue Dequeue Map , HashMap TreeMap(实现SortedMap) SortedMap","text":"这是自己整理的一些Collection的要点笔记，比较零碎，可能可读性不是很强。有新内容时会进行补充。Java Collection框架： Set , HashSet TreeSet(实现SortedSet) SortedSet List , LinkedList ArrayList Queue, PriorityQueue Dequeue Map , HashMap TreeMap(实现SortedMap) SortedMap 基本方法 add(), remove(), contains(), isEmpty(), addAll() hashmap线程不安全，允许存null。实现： 内部有一个静态类Node&lt;K,V&gt; ， 实现 Map.Entry&lt;K,V&gt;，是“ Basic hash bin node”（文档原文）。而TreeNode也是节点的实现，适用于有冲突的情况，冲突后形成的是红黑树。 计算hash值方法：高16位和低16位hashcode异或，降低hash值范围小时的冲突： static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); &#125; 用数组存Node，数组长度必须是2的幂 transient Node&lt;K,V&gt;[] table; 缓存entrySet transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet; 取：按hash值作为数组下标去取Node。下标是(tab.length - 1) &amp; hash。 由于桶的长度是2的n次方，这么做其实是等于 一个模运算。比如hash是31(11111)，length是4(100)，-1后是11，与运算后是3(11)，就是取模。如果有冲突了，则有多个Node放在一个桶里，要么顺序查找（链表），要么按TreeNode去取（红黑树）。 public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; &#125; final Node&lt;K,V&gt; getNode(int hash, Object key) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) { if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) { if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do { if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; } while ((e = e.next) != null); } } return null;} 6. 存，往数组的`(tab.length - 1) &amp; hash`处放。桶里没有的话则直接放，有的话，找有没有相同的值，有的话替换。加了后如果容量达到threshold就resize(); ```java public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true); &#125; final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; &#125; resize() 方法，初始化数组或扩容。扩容时数组容量扩大到2倍然后ReHash，遍历原Entry数组，把所有的Entry重新Hash到新数组。通过e.hash &amp; (newCap - 1)算出新的数组下标，原因是因为数组全是2的幂，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置。然后链表和treenode重新放 HashMap 在第一次 put 时初始化，类似 ArrayList 在第一次 add 时分配空间。在哈希碰撞的链表长度达到TREEIFY_THRESHOLD（默认8)后，会把该链表转变成树结构 concurrenthashmapHashMap允许一个key和value为null，而ConcurrentHashMap不允许key和value为null，如果发现key或者value为null，则会抛出NPE。 和hashmap一样有Node&lt;K,V&gt; sizeCtl：private transient volatile int sizeCtl;这是一个用于同步多个线程的共享变量，如果值为负数，则说明table正在被某个线程初始化或者扩容。如果某个线程想要初始化table或者对table扩容，需要去竞争sizeCtl这个共享变量，获得变量的线程才有许可去进行接下来的操作，没能获得的线程将会一直自旋来尝试获得这个共享变量。获得sizeCtl这个变量的线程在完成工作之后再设置回来，使其他的线程可以走出自旋进行接下来的操作 查询和hashmap差不多，(hashCode &amp; (length - 1))取下标。table数组是被volatile关键字修饰，解决了可见性问题 存要复杂一点。首先计算table下标，下标没数据就通过调用casTabAt方法插入数据。有的话，那么就给该下标处的Node（不管是链表的头还是树的根）加锁插入。 扩容操作比较复杂。扩容操作的条件是如果table过小，并且没有被扩容，那么就需要进行扩容，需要使用transfer方法来将久的记录迁移到新的table中去。整个扩容操作分为两个部分，要用到内部类forwardNode。第一部分是构建一个nextTable,它的容量是原来的两倍，这个操作是单线程完成的。第二个部分就是将原来table中的元素复制到nextTable中，这里允许多线程进行操作。 size()方法，结合baseCount和counterCells数组来得到，通过累计两者的数量即可获得当前ConcurrentHashMap中的记录总量。 HashSet用HashMap实现。(内部：private transient HashMap&lt;E,Object&gt; map;) ArrayListfail fast机制：checkForComodification()方法检查modCount，检查有无结构性的改变，变了抛ConcurrentModificationException。 扩容调Arrays.copyOf(elementData, newCapacity); 内部有迭代器类 Iterator。 LinkedList实现List和Deque（即可以当栈、队列、双向队列使用） 内部是一个双向链表 字段存有 size、 first Node（头节点）、last Node。通过头结点、尾节点可以很快地进行双向入队出队操作。随机存储效率不如ArrayList，要遍历节点。按下标读取时，会按照size，判断是链表前半段还是后半段，根据这个从头或尾节点开始遍历。 和ArrayDeque的区别之一：LinkedList可以存null，而ArrayDeque不能存null。这点在写算法题的时候可以注意一下。 ArrayDeque转一张表整理方法。一套接口遇到失败就会抛出异常，另一套遇到失败会返回特殊值。| Queue Method | Equivalent Deque Method | 说明 || ———— | ———————– | ————————————– || add(e) | addLast(e) | 向队尾插入元素，失败则抛出异常 || offer(e) | offerLast(e) | 向队尾插入元素，失败则返回false || remove() | removeFirst() | 获取并删除队首元素，失败则抛出异常 || poll() | pollFirst() | 获取并删除队首元素，失败则返回null || element() | getFirst() | 获取但不删除队首元素，失败则抛出异常 || peek() | peekFirst() | 获取但不删除队首元素，失败则返回null | 内部elements数组的容量一定是2的倍数，并且不会满。存数组的head和tail下标，形成一个循环数组，当这两个下标相等时，数组为空。而在添加元素时，如果这两个下标相等，说明数组已满，将容量翻倍。扩容时重置头索引和尾索引，头索引置为0，尾索引置为原容量的值。 CopyOnWriteArrayList线程安全add set之类的操作都是新建一个复制arraylist适用于 读多些少, 并且数据内容变化比较少的场景","categories":[{"name":"开发","slug":"开发","permalink":"https://juniousy.github.io/categories/%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://juniousy.github.io/tags/Java/"}]},{"title":"【本科时期文章】实现LRUCache","slug":"存档/实现LRUCache","date":"2019-03-11T14:57:49.000Z","updated":"2022-05-30T09:06:50.984Z","comments":true,"path":"2019/03/11/存档/实现LRUCache/","link":"","permalink":"https://juniousy.github.io/2019/03/11/%E5%AD%98%E6%A1%A3/%E5%AE%9E%E7%8E%B0LRUCache/","excerpt":"LRU Cache 算法是操作系统在进行内存管理时可以采用的一种页面置换算法。LRU，就是Least Recently Used的简称，这个算法叫做最近最少使用算法。除了在页面置换中可以使用这一算法，其他需要缓存的场景也可以运用这一算法。这一算法的核心目的就是依照程序的就近原则，尽可能在有限的空间内缓存最多以后会使用到的内容。另外，实现这一算法也是一道LeetCode题目。本文就是演示如何使用java语言实现这一算法。","text":"LRU Cache 算法是操作系统在进行内存管理时可以采用的一种页面置换算法。LRU，就是Least Recently Used的简称，这个算法叫做最近最少使用算法。除了在页面置换中可以使用这一算法，其他需要缓存的场景也可以运用这一算法。这一算法的核心目的就是依照程序的就近原则，尽可能在有限的空间内缓存最多以后会使用到的内容。另外，实现这一算法也是一道LeetCode题目。本文就是演示如何使用java语言实现这一算法。 LinkedHashMap实现LinkedHashMap是最容易的实现方式，因为它内部的实现方式很贴合这一应用，至于为什么下面会有介绍。LinkedHashMap和普通的HashMap不同的地方在于，它保存了迭代顺序，该迭代顺序可以是插入顺序或者是访问顺序。而LRU要求最近读取过得内容有最高的缓存优先度，也就是按照访问顺序来进行迭代。而通过重写removeEldestEntry方法可以让LinkedHashMap保留有限多的数据，删除缓存中不需要的数据。 //简易实现 class LRUCache&lt;K, V&gt; &#123; private static final float loadFactor = 0.75f; private int capacity; private final LinkedHashMap&lt;K, V&gt; map; public LRUCache(int capacity) &#123; if (capacity &lt; 0) &#123; capacity = 0; &#125; this.capacity = capacity; //构造函数参数分别是initialCapacity、loadFactor、accessOrder，accessOrder为true即按访问顺序迭代 map = new LinkedHashMap&lt;K, V&gt;(0, loadFactor, true)&#123; @Override protected boolean removeEldestEntry(Entry eldest) &#123; return size() &gt; LRUCache.this.capacity; &#125; &#125;; &#125; public final V get(K key) &#123; return map.get(key); &#125; public final void put(K key, V value) &#123; map.put(key, value); &#125; &#125; HashMap + 双向链表实现之所以LinkedHashMap能保有这样的性质，是因为它内部的实现是依托了HashMap和双向链表，因此不用LinkedHashMap我们也能实现LRUCache算法。 基本框架 public class LRUCache&lt;K, V&gt; &#123; private int capacity; private HashMap&lt;K, Node&lt;K, V&gt;&gt; map; private Node&lt;K, V&gt; head; private Node&lt;K, V&gt; tail; public LRUCache(int capacity) &#123; this.capacity = capacity; map = new HashMap&lt;&gt;(capacity); head = new Node&lt;&gt;(); tail = new Node&lt;&gt;(); head.next = tail; tail.pre = head; &#125; class Node&lt;K, V&gt; &#123; K key; V value; Node&lt;K, V&gt; pre; Node&lt;K, V&gt; next; &#125; &#125; 公用方法 private void raiseNode(Node&lt;K, V&gt; node) &#123; if (node.pre == head) &#123; return; &#125; Node&lt;K, V&gt; pre = node.pre; Node&lt;K, V&gt; next = node.next; pre.next = next; next.pre = pre; setFirst(node); &#125; private void setFirst(Node&lt;K, V&gt; node) &#123; Node&lt;K, V&gt; first = head.next; head.next = node; node.pre = head; first.pre = node; node.next = first; &#125; get方法，从map里拿Value，同时将它置为链表头 public V get(K key) &#123; if (!map.containsKey(key)) &#123; return null; &#125; Node&lt;K, V&gt; node = map.get(key); raiseNode(node); return node.value; &#125; save方法，如果缓存已满，删除链表尾的值，再添加新的值到链表头 public void save(K key, V value) &#123; if (map.containsKey(key)) &#123; updateNode(key, value); &#125; else &#123; insertNode(key, value); &#125; &#125; private void updateNode(K key, V value) &#123; Node node = map.get(key); node.value = value; raiseNode(node); &#125; private void insertNode(K key, V value) &#123; if (isFull()) &#123; removeLast(); &#125; Node node = new Node(); node.key = key; node.value = value; setFirst(node); map.put(key, node); &#125; private boolean isFull() &#123; return map.size() &gt;= capacity; &#125; 测试 import org.junit.Test; public class LRUCacheTest &#123; LRUCache&lt;Integer, Integer&gt; cache = new LRUCache(3); @Test public void test() &#123; cache.save(1, 7); cache.save(2, 0); cache.save(3, 1); cache.save(4, 2); assert 0 == cache.get(2); assert null == cache.get(7); cache.save(5, 3); assert 0 == cache.get(2); cache.save(6, 4); assert null == cache.get(4); &#125; &#125; //head -&gt; 7 -&gt; tail //head -&gt; 0 -&gt; 7 -&gt; tail //head -&gt; 1 -&gt; 0 -&gt; 7 -&gt; tail //head -&gt; 2 -&gt; 1 -&gt; 0 -&gt; tail //head -&gt; 3 -&gt; 2 -&gt; 1 -&gt; tail //head -&gt; 2 -&gt; 3 -&gt; 1 -&gt; tail //head -&gt; 4 -&gt; 2 -&gt; 3 -&gt; tail","categories":[{"name":"开发","slug":"开发","permalink":"https://juniousy.github.io/categories/%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://juniousy.github.io/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"【本科时期文章】生产者消费者模型的一个例子","slug":"存档/生产者消费者模型的一个变型","date":"2019-03-02T14:08:53.000Z","updated":"2022-05-30T09:06:50.985Z","comments":true,"path":"2019/03/02/存档/生产者消费者模型的一个变型/","link":"","permalink":"https://juniousy.github.io/2019/03/02/%E5%AD%98%E6%A1%A3/%E7%94%9F%E4%BA%A7%E8%80%85%E6%B6%88%E8%B4%B9%E8%80%85%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%80%E4%B8%AA%E5%8F%98%E5%9E%8B/","excerpt":"一般的生产者消费者模型中，生产者和消费者都是尽可能快地处理任务。但在工作中，我遇到了一种情况，需要每个消费者尽可能多地解决一批任务，这样可以打包处理，降低I/O频次。我当时用的方法是在消费者端给BlockingQueue加锁。后来想想这种方法多余了。这篇文章一是讨论一下这种方法，作个反思，二来作为新博客的第一篇文章，起个开头。","text":"一般的生产者消费者模型中，生产者和消费者都是尽可能快地处理任务。但在工作中，我遇到了一种情况，需要每个消费者尽可能多地解决一批任务，这样可以打包处理，降低I/O频次。我当时用的方法是在消费者端给BlockingQueue加锁。后来想想这种方法多余了。这篇文章一是讨论一下这种方法，作个反思，二来作为新博客的第一篇文章，起个开头。 模拟当时的解决方法用来解决生产者消费者问题的BlockingQueue： private static final BlockingQueue&lt;Task&gt; taskBlockingQueue = new ArrayBlockingQueue&lt;&gt;(100); 生产者部分没有什么区别，直接往队列里添加任务： private void produce(int taskId) &#123; try &#123; taskBlockingQueue.put(new Task(taskId)); System.out.println(String.format(&quot;生产者%d\\t添加任务%d&quot;, id, taskId)); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; 消费者部分在打包的过程中都对阻塞队列加锁，不允许其他消费者获取任务： private static final Lock packageLock = new ReentrantLock(); 消费者需要在指定时间内打包，超时则退出这轮消费。 private void consume() &#123; try &#123; if (packageLock.tryLock(5, TimeUnit.MILLISECONDS)) &#123; try &#123; doPackage(); &#125; finally &#123; packageLock.unlock(); &#125; &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; private void doPackage() &#123; long start = System.currentTimeMillis(); long end; int packageNum = 0; for (int i = 0; i &lt; consumerPackageSize; i++) &#123; doConsume(); packageNum++; end = System.currentTimeMillis(); if (end - start &gt; packageTime) &#123; break; &#125; &#125; end = System.currentTimeMillis(); System.out.println(String.format(&quot;消费者%d\\t打包%d个\\t耗时%d&quot;, id, packageNum, end - start)); &#125; private void doConsume() &#123; Task task = null; try &#123; task = taskBlockingQueue.poll(100, TimeUnit.MILLISECONDS); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; if (task == null) &#123; return; &#125; System.out.println(String.format(&quot;消费者%d\\t完成任务%d&quot;, id, task.getId())); &#125; 整个完整的测试类： import lombok.AllArgsConstructor; import lombok.Data; import java.util.Random; import java.util.concurrent.ArrayBlockingQueue; import java.util.concurrent.BlockingQueue; import java.util.concurrent.TimeUnit; import java.util.concurrent.locks.Lock; import java.util.concurrent.locks.ReentrantLock; /** * @author Junious * @date 2019/02/25 **/ public class ProducerAndConsumerTest &#123; private static final int producerNumber = 5; private static final int consumerNumber = 5; private static final BlockingQueue&lt;Task&gt; taskBlockingQueue = new ArrayBlockingQueue&lt;&gt;(100); private static final Lock packageLock = new ReentrantLock(); private static final int consumerPackageSize = 20; private static final int packageTime = 2000; public static void main(String[] args) &#123; Runtime.getRuntime().addShutdownHook( new Thread(() -&gt; System.out.println (&quot;queue size:&quot; + taskBlockingQueue.size())) ); ProducerAndConsumerTest test = new ProducerAndConsumerTest(); test.init(); &#125; private void init() &#123; //add producers for (int i = 0; i &lt; producerNumber; i++) &#123; Thread t = new Thread(new Producer(i)); t.start(); &#125; //add consumers for (int i = 0; i &lt; consumerNumber; i++) &#123; Thread t = new Thread(new Consumer(i)); t.start(); &#125; &#125; @AllArgsConstructor @Data class Producer implements Runnable &#123; private int id; @Override public void run() &#123; Random random = new Random(); while (true) &#123; int taskId = random.nextInt(1000) + 1; produce(taskId); try &#123; Thread.sleep(random.nextInt(300) + 400); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); break; &#125; &#125; &#125; private void produce(int taskId) &#123; try &#123; taskBlockingQueue.put(new Task(taskId)); System.out.println(String.format(&quot;生产者%d\\t添加任务%d&quot;, id, taskId)); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; @AllArgsConstructor @Data class Consumer implements Runnable &#123; private int id; @Override public void run() &#123; Random random = new Random(); while (true) &#123; consume(); try &#123; Thread.sleep(random.nextInt(300) + 400); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); break; &#125; &#125; &#125; private void consume() &#123; try &#123; if (packageLock.tryLock(5, TimeUnit.MILLISECONDS)) &#123; try &#123; doPackage(); &#125; finally &#123; packageLock.unlock(); &#125; &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; private void doPackage() &#123; long start = System.currentTimeMillis(); long end; int packageNum = 0; for (int i = 0; i &lt; consumerPackageSize; i++) &#123; doConsume(); packageNum++; end = System.currentTimeMillis(); if (end - start &gt; packageTime) &#123; break; &#125; &#125; end = System.currentTimeMillis(); System.out.println(String.format(&quot;消费者%d\\t打包%d个\\t耗时%d&quot;, id, packageNum, end - start)); &#125; private void doConsume() &#123; Task task = null; try &#123; task = taskBlockingQueue.poll(100, TimeUnit.MILLISECONDS); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; if (task == null) &#123; return; &#125; System.out.println(String.format(&quot;消费者%d\\t完成任务%d&quot;, id, task.getId())); &#125; &#125; &#125; @AllArgsConstructor @Data class Task &#123; private int id; &#125; 截取一段测试结果： 生产者0 添加任务545 生产者2 添加任务943 生产者1 添加任务359 生产者3 添加任务97 生产者4 添加任务705 消费者2 完成任务545 消费者2 完成任务359 消费者2 完成任务943 消费者2 完成任务97 消费者2 完成任务705 生产者2 添加任务32 消费者2 完成任务32 生产者4 添加任务488 消费者2 完成任务488 生产者1 添加任务691 消费者2 完成任务691 消费者2 完成任务3 生产者3 添加任务3 生产者0 添加任务815 消费者2 完成任务815 消费者2 完成任务290 生产者1 添加任务290 消费者2 完成任务408 生产者2 添加任务408 消费者2 完成任务873 生产者3 添加任务873 消费者2 打包20个 耗时1165 生产者0 添加任务852 消费者1 完成任务852 消费者1 完成任务743 生产者4 添加任务743 生产者0 添加任务114 消费者1 完成任务114 生产者1 添加任务454 消费者1 完成任务454 消费者1 完成任务920 生产者2 添加任务920 生产者3 添加任务847 消费者1 完成任务847 生产者4 添加任务905 消费者1 完成任务905 生产者3 添加任务698 消费者1 完成任务698 生产者1 添加任务372 消费者1 完成任务372 生产者0 添加任务568 消费者1 完成任务568 生产者2 添加任务419 消费者1 完成任务419 生产者4 添加任务417 消费者1 完成任务417 消费者1 打包20个 耗时1295 生产者3 添加任务888 消费者0 完成任务888 生产者1 添加任务189 消费者0 完成任务189 生产者2 添加任务892 消费者0 完成任务892 生产者4 添加任务375 消费者0 完成任务375 生产者0 添加任务723 消费者0 完成任务723 生产者3 添加任务543 消费者0 完成任务543 消费者0 完成任务205 生产者1 添加任务205 生产者2 添加任务657 消费者0 完成任务657 生产者0 添加任务549 消费者0 完成任务549 生产者4 添加任务812 消费者0 完成任务812 生产者3 添加任务737 消费者0 完成任务737 消费者0 打包20个 耗时1208 生产者2 添加任务784 消费者4 完成任务784 生产者1 添加任务252 消费者4 完成任务252 生产者0 添加任务622 消费者4 完成任务622 生产者4 添加任务524 消费者4 完成任务524 生产者3 添加任务73 消费者4 完成任务73 生产者2 添加任务491 消费者4 完成任务491 生产者0 添加任务225 消费者4 完成任务225 生产者1 添加任务207 消费者4 完成任务207 生产者4 添加任务326 消费者4 完成任务326 生产者2 添加任务983 消费者4 完成任务983 生产者0 添加任务865 消费者4 完成任务865 生产者3 添加任务347 消费者4 完成任务347 消费者4 打包20个 耗时1318 可以看到每次打包只有一个消费者在进行消费，其实相当于只有一个消费者线程，等于没有使用并发。当消费者任务很耗时时： private void doConsume() &#123; Task task = null; try &#123; task = taskBlockingQueue.poll(100, TimeUnit.MILLISECONDS); //模拟耗时 Thread.sleep(200); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; if (task == null) &#123; return; &#125; System.out.println(String.format(&quot;消费者%d\\t完成任务%d&quot;, id, task.getId())); &#125; 这时候在中止时可以看到队列有10到30不等的Task暂留。模拟耗时越长，暂留的越多，也就是相当于性能越差。 解决方案实际上不需要加锁，设定一个超时时间即可。 @AllArgsConstructor @Data class Consumer2 implements Runnable &#123; private int id; @Override public void run() &#123; Random random = new Random(); while (true) &#123; try &#123; consume(); Thread.sleep(random.nextInt(300) + 400); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); break; &#125; &#125; &#125; private void consume() throws InterruptedException &#123; long start = System.currentTimeMillis(); ArrayList&lt;Task&gt; tasks = new ArrayList&lt;&gt;(); long end; int packageNum = 0; for (int i = 0; i &lt; consumerPackageSize; i++) &#123; //模拟打包任务 Task task = taskBlockingQueue.poll(packageTime, TimeUnit.MILLISECONDS); if (task == null) &#123; continue; &#125; Thread.sleep(200); tasks.add(task); packageNum++; end = System.currentTimeMillis(); if (end - start &gt; packageTime) &#123; break; &#125; &#125; end = System.currentTimeMillis(); System.out.println(String.format(&quot;消费者%d\\t打包%d个\\t耗时%d\\t%s&quot;, id, packageNum, end - start, tasks)); &#125; &#125; 生产者2 添加任务539 生产者0 添加任务319 生产者1 添加任务655 生产者4 添加任务843 生产者3 添加任务788 生产者0 添加任务716 生产者3 添加任务176 生产者4 添加任务735 生产者2 添加任务7 生产者1 添加任务283 生产者4 添加任务466 生产者3 添加任务486 生产者0 添加任务649 生产者2 添加任务373 生产者1 添加任务158 生产者0 添加任务532 生产者4 添加任务914 生产者1 添加任务734 生产者3 添加任务571 生产者2 添加任务114 生产者1 添加任务340 生产者3 添加任务670 生产者0 添加任务482 生产者2 添加任务298 生产者4 添加任务598 消费者0 打包5个 耗时2213 [Task(id=655), Task(id=716), Task(id=466), Task(id=532), Task(id=340)] 消费者4 打包5个 耗时2280 [Task(id=319), Task(id=176), Task(id=486), Task(id=914), Task(id=670)] 消费者1 打包5个 耗时2328 [Task(id=788), Task(id=735), Task(id=649), Task(id=734), Task(id=482)] 消费者3 打包5个 耗时2351 [Task(id=843), Task(id=7), Task(id=373), Task(id=571), Task(id=298)] 消费者2 打包5个 耗时2400 [Task(id=539), Task(id=283), Task(id=158), Task(id=114), Task(id=598)] 生产者3 添加任务928 生产者0 添加任务360 生产者1 添加任务724 生产者2 添加任务539 生产者4 添加任务926 生产者3 添加任务206 生产者0 添加任务596 生产者1 添加任务841 生产者4 添加任务834 生产者2 添加任务340 生产者3 添加任务585 生产者1 添加任务500 生产者4 添加任务532 生产者0 添加任务800 生产者2 添加任务914 生产者3 添加任务202 生产者1 添加任务850 生产者0 添加任务506 生产者1 添加任务785 生产者2 添加任务633 生产者4 添加任务182 生产者3 添加任务154 生产者0 添加任务13 生产者2 添加任务880 消费者3 打包5个 耗时2199 [Task(id=724), Task(id=841), Task(id=532), Task(id=506), Task(id=13)] 生产者4 添加任务214 消费者0 打包5个 耗时2217 [Task(id=539), Task(id=834), Task(id=800), Task(id=785), Task(id=880)] 生产者1 添加任务789 生产者3 添加任务786 消费者4 打包6个 耗时2583 [Task(id=928), Task(id=926), Task(id=340), Task(id=914), Task(id=633), Task(id=214)] 生产者0 添加任务468 生产者2 添加任务189 消费者1 打包6个 耗时2597 [Task(id=360), Task(id=206), Task(id=585), Task(id=202), Task(id=182), Task(id=789)] 消费者2 打包5个 耗时2465 [Task(id=596), Task(id=500), Task(id=850), Task(id=154), Task(id=786)] 生产者4 添加任务812 生产者0 添加任务239 生产者3 添加任务671 生产者1 添加任务730 生产者2 添加任务124 生产者4 添加任务679 生产者0 添加任务320 生产者2 添加任务917 生产者1 添加任务986 生产者3 添加任务557 生产者0 添加任务415 生产者4 添加任务559 生产者2 添加任务880 生产者1 添加任务920 生产者3 添加任务502 生产者0 添加任务679 生产者4 添加任务823 生产者2 添加任务594 生产者1 添加任务336 生产者3 添加任务502 生产者0 添加任务453 生产者4 添加任务360 消费者0 打包6个 耗时2249 [Task(id=468), Task(id=239), Task(id=679), Task(id=415), Task(id=679), Task(id=453)] 消费者3 打包6个 耗时2320 [Task(id=189), Task(id=671), Task(id=320), Task(id=559), Task(id=823), Task(id=360)] 生产者2 添加任务823 生产者3 添加任务857 生产者1 添加任务395 生产者0 添加任务937 生产者4 添加任务817 消费者2 打包4个 耗时2264 [Task(id=917), Task(id=880), Task(id=594), Task(id=823)] 消费者4 打包6个 耗时2622 [Task(id=812), Task(id=730), Task(id=986), Task(id=920), Task(id=336), Task(id=857)] 消费者1 打包5个 耗时2408 [Task(id=124), Task(id=557), Task(id=502), Task(id=502), Task(id=395)] 这时候中止可以看到队列几乎没有Task暂留 当设置消费者消费时间为1000ms时，运行一段时间队列就满了，这时候是当增加消费者线程数即可让任务处理跟上生产者的生产速度。","categories":[{"name":"开发","slug":"开发","permalink":"https://juniousy.github.io/categories/%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://juniousy.github.io/tags/Java/"},{"name":"并发","slug":"并发","permalink":"https://juniousy.github.io/tags/%E5%B9%B6%E5%8F%91/"}]}],"categories":[{"name":"Lab","slug":"Lab","permalink":"https://juniousy.github.io/categories/Lab/"},{"name":"开发","slug":"开发","permalink":"https://juniousy.github.io/categories/%E5%BC%80%E5%8F%91/"},{"name":"刷题","slug":"刷题","permalink":"https://juniousy.github.io/categories/%E5%88%B7%E9%A2%98/"}],"tags":[{"name":"distributed system","slug":"distributed-system","permalink":"https://juniousy.github.io/tags/distributed-system/"},{"name":"Java","slug":"Java","permalink":"https://juniousy.github.io/tags/Java/"},{"name":"并发","slug":"并发","permalink":"https://juniousy.github.io/tags/%E5%B9%B6%E5%8F%91/"},{"name":"Redis","slug":"Redis","permalink":"https://juniousy.github.io/tags/Redis/"},{"name":"算法","slug":"算法","permalink":"https://juniousy.github.io/tags/%E7%AE%97%E6%B3%95/"}]}